{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5b73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04490c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainig set과 test set의 모든 이미지 앞이 대해서,\n",
    "# jpg image header가 포함되지 않은 (jpg의 파일 구조에 어긋나는) 파일들을 삭제\n",
    "\n",
    "data_path = '/aiffel/aiffel/model-fit/data/30vnfoods/'\n",
    "train_path = data_path + 'Train/'\n",
    "test_path = data_path + 'Test/'\n",
    "\n",
    "for path in [train_path, test_path]:\n",
    "    classes = os.listdir(path)\n",
    "    \n",
    "    for food in classes:\n",
    "        food_path = os.path.join(path, food)\n",
    "        images = os.listdir(food_path)\n",
    "        \n",
    "        for image in images:\n",
    "            with open(os.path.join(food_path, image), 'rb') as f:\n",
    "                bytes = f.read()\n",
    "            if bytes[:3] != b'\\xff\\xd8\\xff':\n",
    "                print(os.path.join(food_path, image))\n",
    "                os.remove(os.path.join(food_path, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ad60cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig data의 개수: 9775\n"
     ]
    }
   ],
   "source": [
    "# 개수 확인\n",
    "classes = os.listdir(train_path)\n",
    "train_length = 0\n",
    "\n",
    "for food in classes:\n",
    "    food_path = os.path.join(train_path, food)\n",
    "    images = os.listdir(food_path)\n",
    "    \n",
    "    train_length += len(images)\n",
    "    \n",
    "print('trainig data의 개수: ' +str(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542aa57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제1: dataloader 구현하기\n",
    "\n",
    "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
    "    '''\n",
    "    file_path로부터 class label을 만들고, 이미지를 읽는 함수\n",
    "    '''\n",
    "    label = tf.strings.split(file_path, os.path.sep)\n",
    "    label = label[-2] == class_names\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, img_shape)\n",
    "    return img, label\n",
    "\n",
    "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
    "    '''\n",
    "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
    "    '''\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.repeat(5)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def load_data(data_path, batch_size=32):\n",
    "    '''\n",
    "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
    "    '''\n",
    "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
    "    data_path = pathlib.Path(data_path)\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
    "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
    "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220f1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 multiple                  12810     \n",
      "=================================================================\n",
      "Total params: 4,067,501\n",
      "Trainable params: 15,370\n",
      "Non-trainable params: 4,052,131\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 문제2: 모델 구현하기\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    '''\n",
    "    EfficientNetB0을 백본으로 사용하는 모델을 구성합니다.\n",
    "    Classification 문제로 접근할 것이기 때문에 맨 마지막 Dense 레이어에 \n",
    "    우리가 원하는 클래스 개수만큼을 지정해주어야 합니다.\n",
    "    '''\n",
    "    def __init__(self, num_classes=10, freeze=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
    "        if freeze:\n",
    "            self.base_model.trainable = False\n",
    "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
    "                                       tf.keras.layers.BatchNormalization(),\n",
    "                                       tf.keras.layers.Dropout(0.5, name=\"top_dropout\")])\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # [[YOUR CODE]]\n",
    "        x = self.base_model(inputs)\n",
    "        x = self.top(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "if __name__ =='__main__':\n",
    "    model = Model(num_classes=10, freeze=True)\n",
    "    model.build(input_shape=(None, 224, 224, 3))\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42abff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제3: custom trainer 구현하기\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model,ds_length, epochs, batch, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "    def train(self, train_dataset, train_metric):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
    "            # [[YOUR CODE]]\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = model(x_batch_train)\n",
    "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
    "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "                # train metric 업데이트\n",
    "                train_metric.update_state(y_batch_train, logits)\n",
    "                # 5 배치마다 로깅\n",
    "                if step % 5 == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(loss_value))\n",
    "                    )\n",
    "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
    "                    print(train_metric.result().numpy())\n",
    "            # 마지막 epoch 학습이 끝나면 train 결과를 보여줌\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2021a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 4.0665\n",
      "Seen so far: 64 samples\n",
      "0.0625\n",
      "Training loss (for one batch) at step 5: 2.5827\n",
      "Seen so far: 384 samples\n",
      "0.22395833\n",
      "Training loss (for one batch) at step 10: 1.8439\n",
      "Seen so far: 704 samples\n",
      "0.3224432\n",
      "Training loss (for one batch) at step 15: 1.4730\n",
      "Seen so far: 1024 samples\n",
      "0.40527344\n",
      "Training loss (for one batch) at step 20: 1.1852\n",
      "Seen so far: 1344 samples\n",
      "0.45386904\n",
      "Training loss (for one batch) at step 25: 1.1217\n",
      "Seen so far: 1664 samples\n",
      "0.49278846\n",
      "Training loss (for one batch) at step 30: 0.9645\n",
      "Seen so far: 1984 samples\n",
      "0.5267137\n",
      "Training loss (for one batch) at step 35: 0.6311\n",
      "Seen so far: 2304 samples\n",
      "0.55772567\n",
      "Training loss (for one batch) at step 40: 0.8912\n",
      "Seen so far: 2624 samples\n",
      "0.5788872\n",
      "Training loss (for one batch) at step 45: 0.6177\n",
      "Seen so far: 2944 samples\n",
      "0.59748644\n",
      "Training loss (for one batch) at step 50: 0.7697\n",
      "Seen so far: 3264 samples\n",
      "0.6136642\n",
      "Training loss (for one batch) at step 55: 0.5843\n",
      "Seen so far: 3584 samples\n",
      "0.62890625\n",
      "Training loss (for one batch) at step 60: 0.6474\n",
      "Seen so far: 3904 samples\n",
      "0.6411373\n",
      "Training loss (for one batch) at step 65: 0.5702\n",
      "Seen so far: 4224 samples\n",
      "0.6531724\n",
      "Training loss (for one batch) at step 70: 0.5898\n",
      "Seen so far: 4544 samples\n",
      "0.66263205\n",
      "Training loss (for one batch) at step 75: 0.8166\n",
      "Seen so far: 4864 samples\n",
      "0.66981906\n",
      "Training loss (for one batch) at step 80: 0.7916\n",
      "Seen so far: 5184 samples\n",
      "0.67901236\n",
      "Training loss (for one batch) at step 85: 0.5440\n",
      "Seen so far: 5504 samples\n",
      "0.6887718\n",
      "Training loss (for one batch) at step 90: 0.6791\n",
      "Seen so far: 5824 samples\n",
      "0.6964286\n",
      "Training loss (for one batch) at step 95: 0.7322\n",
      "Seen so far: 6144 samples\n",
      "0.7032878\n",
      "Training loss (for one batch) at step 100: 0.7381\n",
      "Seen so far: 6464 samples\n",
      "0.7096225\n",
      "Training loss (for one batch) at step 105: 0.5345\n",
      "Seen so far: 6784 samples\n",
      "0.7138856\n",
      "Training loss (for one batch) at step 110: 0.5601\n",
      "Seen so far: 7104 samples\n",
      "0.7193131\n",
      "Training loss (for one batch) at step 115: 0.3302\n",
      "Seen so far: 7424 samples\n",
      "0.723195\n",
      "Training loss (for one batch) at step 120: 0.3531\n",
      "Seen so far: 7744 samples\n",
      "0.7268853\n",
      "Training loss (for one batch) at step 125: 0.6142\n",
      "Seen so far: 8064 samples\n",
      "0.7300347\n",
      "Training loss (for one batch) at step 130: 0.7253\n",
      "Seen so far: 8384 samples\n",
      "0.7333015\n",
      "Training loss (for one batch) at step 135: 0.5195\n",
      "Seen so far: 8704 samples\n",
      "0.7363281\n",
      "Training loss (for one batch) at step 140: 0.6991\n",
      "Seen so far: 9024 samples\n",
      "0.7393617\n",
      "Training loss (for one batch) at step 145: 0.7245\n",
      "Seen so far: 9344 samples\n",
      "0.74165237\n",
      "Training loss (for one batch) at step 150: 0.4005\n",
      "Seen so far: 9664 samples\n",
      "0.74399835\n",
      "Training loss (for one batch) at step 155: 0.4436\n",
      "Seen so far: 9984 samples\n",
      "0.74759614\n",
      "Training loss (for one batch) at step 160: 0.2465\n",
      "Seen so far: 10304 samples\n",
      "0.7515528\n",
      "Training loss (for one batch) at step 165: 0.4519\n",
      "Seen so far: 10624 samples\n",
      "0.75489455\n",
      "Training loss (for one batch) at step 170: 0.5149\n",
      "Seen so far: 10944 samples\n",
      "0.75877196\n",
      "Training loss (for one batch) at step 175: 0.4431\n",
      "Seen so far: 11264 samples\n",
      "0.76198506\n",
      "Training loss (for one batch) at step 180: 0.3463\n",
      "Seen so far: 11584 samples\n",
      "0.765625\n",
      "Training loss (for one batch) at step 185: 0.3752\n",
      "Seen so far: 11904 samples\n",
      "0.7692372\n",
      "Training loss (for one batch) at step 190: 0.3450\n",
      "Seen so far: 12224 samples\n",
      "0.7726603\n",
      "Training loss (for one batch) at step 195: 0.3508\n",
      "Seen so far: 12544 samples\n",
      "0.77527106\n",
      "Training loss (for one batch) at step 200: 0.4845\n",
      "Seen so far: 12864 samples\n",
      "0.7778296\n",
      "Training loss (for one batch) at step 205: 0.2130\n",
      "Seen so far: 13184 samples\n",
      "0.7809466\n",
      "Training loss (for one batch) at step 210: 0.1502\n",
      "Seen so far: 13504 samples\n",
      "0.784064\n",
      "Training loss (for one batch) at step 215: 0.3856\n",
      "Seen so far: 13824 samples\n",
      "0.78718174\n",
      "Training loss (for one batch) at step 220: 0.1183\n",
      "Seen so far: 14144 samples\n",
      "0.7905826\n",
      "Training loss (for one batch) at step 225: 0.2781\n",
      "Seen so far: 14464 samples\n",
      "0.79286504\n",
      "Training loss (for one batch) at step 230: 0.3110\n",
      "Seen so far: 14784 samples\n",
      "0.79545456\n",
      "Training loss (for one batch) at step 235: 0.2014\n",
      "Seen so far: 15104 samples\n",
      "0.79813296\n",
      "Training loss (for one batch) at step 240: 0.4092\n",
      "Seen so far: 15424 samples\n",
      "0.8007002\n",
      "Training loss (for one batch) at step 245: 0.1876\n",
      "Seen so far: 15744 samples\n",
      "0.8030361\n",
      "Training loss (for one batch) at step 250: 0.4629\n",
      "Seen so far: 16064 samples\n",
      "0.8051544\n",
      "Training loss (for one batch) at step 255: 0.2217\n",
      "Seen so far: 16384 samples\n",
      "0.8078003\n",
      "Training loss (for one batch) at step 260: 0.3768\n",
      "Seen so far: 16704 samples\n",
      "0.8092074\n",
      "Training loss (for one batch) at step 265: 0.3757\n",
      "Seen so far: 17024 samples\n",
      "0.8114427\n",
      "Training loss (for one batch) at step 270: 0.1547\n",
      "Seen so far: 17344 samples\n",
      "0.8132495\n",
      "Training loss (for one batch) at step 275: 0.4345\n",
      "Seen so far: 17664 samples\n",
      "0.81402856\n",
      "Training loss (for one batch) at step 280: 0.3206\n",
      "Seen so far: 17984 samples\n",
      "0.81528026\n",
      "Training loss (for one batch) at step 285: 0.2204\n",
      "Seen so far: 18304 samples\n",
      "0.8167067\n",
      "Training loss (for one batch) at step 290: 0.2759\n",
      "Seen so far: 18624 samples\n",
      "0.81846005\n",
      "Training loss (for one batch) at step 295: 0.1978\n",
      "Seen so far: 18944 samples\n",
      "0.82020694\n",
      "Training loss (for one batch) at step 300: 0.3055\n",
      "Seen so far: 19264 samples\n",
      "0.82231104\n",
      "Training loss (for one batch) at step 305: 0.1274\n",
      "Seen so far: 19584 samples\n",
      "0.82404006\n",
      "Training loss (for one batch) at step 310: 0.0884\n",
      "Seen so far: 19904 samples\n",
      "0.82611537\n",
      "Training loss (for one batch) at step 315: 0.0956\n",
      "Seen so far: 20224 samples\n",
      "0.828125\n",
      "Training loss (for one batch) at step 320: 0.3086\n",
      "Seen so far: 20544 samples\n",
      "0.8297313\n",
      "Training loss (for one batch) at step 325: 0.1508\n",
      "Seen so far: 20864 samples\n",
      "0.83162385\n",
      "Training loss (for one batch) at step 330: 0.2507\n",
      "Seen so far: 21184 samples\n",
      "0.83317596\n",
      "Training loss (for one batch) at step 335: 0.3863\n",
      "Seen so far: 21504 samples\n",
      "0.8346819\n",
      "Training loss (for one batch) at step 340: 0.3393\n",
      "Seen so far: 21824 samples\n",
      "0.8359146\n",
      "Training loss (for one batch) at step 345: 0.1956\n",
      "Seen so far: 22144 samples\n",
      "0.83742774\n",
      "Training loss (for one batch) at step 350: 0.2411\n",
      "Seen so far: 22464 samples\n",
      "0.83876425\n",
      "Training loss (for one batch) at step 355: 0.0966\n",
      "Seen so far: 22784 samples\n",
      "0.84023875\n",
      "Training loss (for one batch) at step 360: 0.1604\n",
      "Seen so far: 23104 samples\n",
      "0.8417157\n",
      "Training loss (for one batch) at step 365: 0.0530\n",
      "Seen so far: 23424 samples\n",
      "0.8433658\n",
      "Training loss (for one batch) at step 370: 0.2901\n",
      "Seen so far: 23744 samples\n",
      "0.84497136\n",
      "Training loss (for one batch) at step 375: 0.0862\n",
      "Seen so far: 24064 samples\n",
      "0.8462849\n",
      "Training loss (for one batch) at step 380: 0.1019\n",
      "Seen so far: 24384 samples\n",
      "0.847687\n",
      "Training loss (for one batch) at step 385: 0.1594\n",
      "Seen so far: 24704 samples\n",
      "0.84913373\n",
      "Training loss (for one batch) at step 390: 0.1025\n",
      "Seen so far: 25024 samples\n",
      "0.85046357\n",
      "Training loss (for one batch) at step 395: 0.0906\n",
      "Seen so far: 25344 samples\n",
      "0.8517598\n",
      "Training loss (for one batch) at step 400: 0.1148\n",
      "Seen so far: 25664 samples\n",
      "0.8529068\n",
      "Training loss (for one batch) at step 405: 0.2189\n",
      "Seen so far: 25984 samples\n",
      "0.8539871\n",
      "Training loss (for one batch) at step 410: 0.0941\n",
      "Seen so far: 26304 samples\n",
      "0.8551551\n",
      "Training loss (for one batch) at step 415: 0.3476\n",
      "Seen so far: 26624 samples\n",
      "0.85595703\n",
      "Training loss (for one batch) at step 420: 0.4118\n",
      "Seen so far: 26944 samples\n",
      "0.85662854\n",
      "Training loss (for one batch) at step 425: 0.2270\n",
      "Seen so far: 27264 samples\n",
      "0.857321\n",
      "Training loss (for one batch) at step 430: 0.2970\n",
      "Seen so far: 27584 samples\n",
      "0.85825115\n",
      "Training loss (for one batch) at step 435: 0.1377\n",
      "Seen so far: 27904 samples\n",
      "0.8591958\n",
      "Training loss (for one batch) at step 440: 0.1838\n",
      "Seen so far: 28224 samples\n",
      "0.86001277\n",
      "Training loss (for one batch) at step 445: 0.1927\n",
      "Seen so far: 28544 samples\n",
      "0.86098653\n",
      "Training loss (for one batch) at step 450: 0.2013\n",
      "Seen so far: 28864 samples\n",
      "0.8619388\n",
      "Training loss (for one batch) at step 455: 0.1592\n",
      "Seen so far: 29184 samples\n",
      "0.86252743\n",
      "Training loss (for one batch) at step 460: 0.1853\n",
      "Seen so far: 29504 samples\n",
      "0.8632728\n",
      "Training loss (for one batch) at step 465: 0.0443\n",
      "Seen so far: 29824 samples\n",
      "0.8642704\n",
      "Training loss (for one batch) at step 470: 0.2749\n",
      "Seen so far: 30144 samples\n",
      "0.8650146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 475: 0.2608\n",
      "Seen so far: 30464 samples\n",
      "0.86580884\n",
      "Training loss (for one batch) at step 480: 0.1719\n",
      "Seen so far: 30784 samples\n",
      "0.8664566\n",
      "Training loss (for one batch) at step 485: 0.0671\n",
      "Seen so far: 31104 samples\n",
      "0.86741257\n",
      "Training loss (for one batch) at step 490: 0.3120\n",
      "Seen so far: 31424 samples\n",
      "0.86799896\n",
      "Training loss (for one batch) at step 495: 0.1690\n",
      "Seen so far: 31744 samples\n",
      "0.8687941\n",
      "Training loss (for one batch) at step 500: 0.1823\n",
      "Seen so far: 32064 samples\n",
      "0.8696981\n",
      "Training loss (for one batch) at step 505: 0.2542\n",
      "Seen so far: 32384 samples\n",
      "0.8703063\n",
      "Training loss (for one batch) at step 510: 0.0630\n",
      "Seen so far: 32704 samples\n",
      "0.87102497\n",
      "Training loss (for one batch) at step 515: 0.0843\n",
      "Seen so far: 33024 samples\n",
      "0.8718508\n",
      "Training loss (for one batch) at step 520: 0.1437\n",
      "Seen so far: 33344 samples\n",
      "0.8725108\n",
      "Training loss (for one batch) at step 525: 0.0751\n",
      "Seen so far: 33664 samples\n",
      "0.8733068\n",
      "Training loss (for one batch) at step 530: 0.0550\n",
      "Seen so far: 33984 samples\n",
      "0.87426436\n",
      "Training loss (for one batch) at step 535: 0.0192\n",
      "Seen so far: 34304 samples\n",
      "0.8752624\n",
      "Training loss (for one batch) at step 540: 0.0905\n",
      "Seen so far: 34624 samples\n",
      "0.8758665\n",
      "Training loss (for one batch) at step 545: 0.0487\n",
      "Seen so far: 34944 samples\n",
      "0.8766026\n",
      "Training loss (for one batch) at step 550: 0.1321\n",
      "Seen so far: 35264 samples\n",
      "0.87738204\n",
      "Training loss (for one batch) at step 555: 0.0933\n",
      "Seen so far: 35584 samples\n",
      "0.87797886\n",
      "Training loss (for one batch) at step 560: 0.1279\n",
      "Seen so far: 35904 samples\n",
      "0.8785651\n",
      "Training loss (for one batch) at step 565: 0.2043\n",
      "Seen so far: 36224 samples\n",
      "0.8791685\n",
      "Training loss (for one batch) at step 570: 0.1300\n",
      "Seen so far: 36544 samples\n",
      "0.8798982\n",
      "Training loss (for one batch) at step 575: 0.0554\n",
      "Seen so far: 36864 samples\n",
      "0.880344\n",
      "Training loss (for one batch) at step 580: 0.2444\n",
      "Seen so far: 37184 samples\n",
      "0.881051\n",
      "Training loss (for one batch) at step 585: 0.1519\n",
      "Seen so far: 37504 samples\n",
      "0.8817993\n",
      "Training loss (for one batch) at step 590: 0.1077\n",
      "Seen so far: 37824 samples\n",
      "0.88234985\n",
      "Training loss (for one batch) at step 595: 0.1231\n",
      "Seen so far: 38144 samples\n",
      "0.8831533\n",
      "Training loss (for one batch) at step 600: 0.1395\n",
      "Seen so far: 38464 samples\n",
      "0.88370943\n",
      "Training loss (for one batch) at step 605: 0.1516\n",
      "Seen so far: 38784 samples\n",
      "0.88417906\n",
      "Training loss (for one batch) at step 610: 0.4728\n",
      "Seen so far: 39104 samples\n",
      "0.8846665\n",
      "Training loss (for one batch) at step 615: 0.0542\n",
      "Seen so far: 39424 samples\n",
      "0.88534904\n",
      "Training loss (for one batch) at step 620: 0.1549\n",
      "Seen so far: 39744 samples\n",
      "0.88574374\n",
      "Training loss (for one batch) at step 625: 0.1425\n",
      "Seen so far: 40064 samples\n",
      "0.8861821\n",
      "Training loss (for one batch) at step 630: 0.0744\n",
      "Seen so far: 40384 samples\n",
      "0.8867868\n",
      "Training loss (for one batch) at step 635: 0.0452\n",
      "Seen so far: 40704 samples\n",
      "0.8873821\n",
      "Training loss (for one batch) at step 640: 0.3083\n",
      "Seen so far: 41024 samples\n",
      "0.8878461\n",
      "Training loss (for one batch) at step 645: 0.1497\n",
      "Seen so far: 41344 samples\n",
      "0.8883514\n",
      "Training loss (for one batch) at step 650: 0.2398\n",
      "Seen so far: 41664 samples\n",
      "0.8886809\n",
      "Training loss (for one batch) at step 655: 0.0562\n",
      "Seen so far: 41984 samples\n",
      "0.88929117\n",
      "Training loss (for one batch) at step 660: 0.0329\n",
      "Seen so far: 42304 samples\n",
      "0.8898213\n",
      "Training loss (for one batch) at step 665: 0.2602\n",
      "Seen so far: 42624 samples\n",
      "0.8903435\n",
      "Training loss (for one batch) at step 670: 0.0993\n",
      "Seen so far: 42944 samples\n",
      "0.8908811\n",
      "Training loss (for one batch) at step 675: 0.0338\n",
      "Seen so far: 43264 samples\n",
      "0.8912722\n",
      "Training loss (for one batch) at step 680: 0.0954\n",
      "Seen so far: 43584 samples\n",
      "0.891864\n",
      "Training loss (for one batch) at step 685: 0.1259\n",
      "Seen so far: 43904 samples\n",
      "0.89235604\n",
      "Training loss (for one batch) at step 690: 0.0295\n",
      "Seen so far: 44224 samples\n",
      "0.8928184\n",
      "Training loss (for one batch) at step 695: 0.0518\n",
      "Seen so far: 44544 samples\n",
      "0.8933863\n",
      "Training loss (for one batch) at step 700: 0.0558\n",
      "Seen so far: 44864 samples\n",
      "0.8939016\n",
      "Training loss (for one batch) at step 705: 0.2105\n",
      "Seen so far: 45184 samples\n",
      "0.89440954\n",
      "Training loss (for one batch) at step 710: 0.1666\n",
      "Seen so far: 45504 samples\n",
      "0.8948005\n",
      "Training loss (for one batch) at step 715: 0.1101\n",
      "Seen so far: 45824 samples\n",
      "0.895295\n",
      "Training loss (for one batch) at step 720: 0.0957\n",
      "Seen so far: 46144 samples\n",
      "0.8958478\n",
      "Training loss (for one batch) at step 725: 0.1425\n",
      "Seen so far: 46464 samples\n",
      "0.89632833\n",
      "Training loss (for one batch) at step 730: 0.0446\n",
      "Seen so far: 46784 samples\n",
      "0.8968237\n",
      "Training loss (for one batch) at step 735: 0.1173\n",
      "Seen so far: 47104 samples\n",
      "0.8972486\n",
      "Training loss (for one batch) at step 740: 0.2814\n",
      "Seen so far: 47424 samples\n",
      "0.8976257\n",
      "Training loss (for one batch) at step 745: 0.1913\n",
      "Seen so far: 47744 samples\n",
      "0.8980605\n",
      "Training loss (for one batch) at step 750: 0.0308\n",
      "Seen so far: 48064 samples\n",
      "0.89855194\n",
      "Training loss (for one batch) at step 755: 0.1052\n",
      "Seen so far: 48384 samples\n",
      "0.8989542\n",
      "Training loss (for one batch) at step 760: 0.0433\n",
      "Seen so far: 48704 samples\n",
      "0.8993512\n",
      "Training acc over epoch: 0.8995\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.0729\n",
      "Seen so far: 64 samples\n",
      "0.8995484\n",
      "Training loss (for one batch) at step 5: 0.1744\n",
      "Seen so far: 384 samples\n",
      "0.8998762\n",
      "Training loss (for one batch) at step 10: 0.0492\n",
      "Seen so far: 704 samples\n",
      "0.9003005\n",
      "Training loss (for one batch) at step 15: 0.0599\n",
      "Seen so far: 1024 samples\n",
      "0.90077955\n",
      "Training loss (for one batch) at step 20: 0.1686\n",
      "Seen so far: 1344 samples\n",
      "0.9011729\n",
      "Training loss (for one batch) at step 25: 0.1638\n",
      "Seen so far: 1664 samples\n",
      "0.9015809\n",
      "Training loss (for one batch) at step 30: 0.1059\n",
      "Seen so far: 1984 samples\n",
      "0.9020036\n",
      "Training loss (for one batch) at step 35: 0.0333\n",
      "Seen so far: 2304 samples\n",
      "0.9024014\n",
      "Training loss (for one batch) at step 40: 0.1004\n",
      "Seen so far: 2624 samples\n",
      "0.9028525\n",
      "Training loss (for one batch) at step 45: 0.2123\n",
      "Seen so far: 2944 samples\n",
      "0.90316296\n",
      "Training loss (for one batch) at step 50: 0.1664\n",
      "Seen so far: 3264 samples\n",
      "0.90348876\n",
      "Training loss (for one batch) at step 55: 0.1004\n",
      "Seen so far: 3584 samples\n",
      "0.9039631\n",
      "Training loss (for one batch) at step 60: 0.1548\n",
      "Seen so far: 3904 samples\n",
      "0.90431803\n",
      "Training loss (for one batch) at step 65: 0.0346\n",
      "Seen so far: 4224 samples\n",
      "0.9047063\n",
      "Training loss (for one batch) at step 70: 0.0242\n",
      "Seen so far: 4544 samples\n",
      "0.90516484\n",
      "Training loss (for one batch) at step 75: 0.1502\n",
      "Seen so far: 4864 samples\n",
      "0.90550625\n",
      "Training loss (for one batch) at step 80: 0.0361\n",
      "Seen so far: 5184 samples\n",
      "0.9058991\n",
      "Training loss (for one batch) at step 85: 0.1449\n",
      "Seen so far: 5504 samples\n",
      "0.9062138\n",
      "Training loss (for one batch) at step 90: 0.0862\n",
      "Seen so far: 5824 samples\n",
      "0.9064151\n",
      "Training loss (for one batch) at step 95: 0.0334\n",
      "Seen so far: 6144 samples\n",
      "0.9067777\n",
      "Training loss (for one batch) at step 100: 0.0677\n",
      "Seen so far: 6464 samples\n",
      "0.9070818\n",
      "Training loss (for one batch) at step 105: 0.1469\n",
      "Seen so far: 6784 samples\n",
      "0.9073824\n",
      "Training loss (for one batch) at step 110: 0.0281\n",
      "Seen so far: 7104 samples\n",
      "0.9077154\n",
      "Training loss (for one batch) at step 115: 0.0440\n",
      "Seen so far: 7424 samples\n",
      "0.9080801\n",
      "Training loss (for one batch) at step 120: 0.1457\n",
      "Seen so far: 7744 samples\n",
      "0.9084053\n",
      "Training loss (for one batch) at step 125: 0.0141\n",
      "Seen so far: 8064 samples\n",
      "0.90865666\n",
      "Training loss (for one batch) at step 130: 0.0594\n",
      "Seen so far: 8384 samples\n",
      "0.90895754\n",
      "Training loss (for one batch) at step 135: 0.1135\n",
      "Seen so far: 8704 samples\n",
      "0.90928984\n",
      "Training loss (for one batch) at step 140: 0.0513\n",
      "Seen so far: 9024 samples\n",
      "0.9096703\n",
      "Training loss (for one batch) at step 145: 0.1417\n",
      "Seen so far: 9344 samples\n",
      "0.90989196\n",
      "Training loss (for one batch) at step 150: 0.0882\n",
      "Seen so far: 9664 samples\n",
      "0.91026497\n",
      "Training loss (for one batch) at step 155: 0.1234\n",
      "Seen so far: 9984 samples\n",
      "0.91043\n",
      "Training loss (for one batch) at step 160: 0.1366\n",
      "Seen so far: 10304 samples\n",
      "0.91082984\n",
      "Training loss (for one batch) at step 165: 0.0267\n",
      "Seen so far: 10624 samples\n",
      "0.91114134\n",
      "Training loss (for one batch) at step 170: 0.2769\n",
      "Seen so far: 10944 samples\n",
      "0.91146624\n",
      "Training loss (for one batch) at step 175: 0.0283\n",
      "Seen so far: 11264 samples\n",
      "0.9117378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 180: 0.1469\n",
      "Seen so far: 11584 samples\n",
      "0.9120396\n",
      "Training loss (for one batch) at step 185: 0.0496\n",
      "Seen so far: 11904 samples\n",
      "0.9123217\n",
      "Training loss (for one batch) at step 190: 0.0623\n",
      "Seen so far: 12224 samples\n",
      "0.91265\n",
      "Training loss (for one batch) at step 195: 0.0531\n",
      "Seen so far: 12544 samples\n",
      "0.91302365\n",
      "Training loss (for one batch) at step 200: 0.0280\n",
      "Seen so far: 12864 samples\n",
      "0.9133773\n",
      "Training loss (for one batch) at step 205: 0.0724\n",
      "Seen so far: 13184 samples\n",
      "0.91371113\n",
      "Training loss (for one batch) at step 210: 0.2110\n",
      "Seen so far: 13504 samples\n",
      "0.9139935\n",
      "Training loss (for one batch) at step 215: 0.0347\n",
      "Seen so far: 13824 samples\n",
      "0.9143208\n",
      "Training loss (for one batch) at step 220: 0.0793\n",
      "Seen so far: 14144 samples\n",
      "0.9145972\n",
      "Training loss (for one batch) at step 225: 0.0080\n",
      "Seen so far: 14464 samples\n",
      "0.9149497\n",
      "Training loss (for one batch) at step 230: 0.1451\n",
      "Seen so far: 14784 samples\n",
      "0.91520447\n",
      "Training loss (for one batch) at step 235: 0.0369\n",
      "Seen so far: 15104 samples\n",
      "0.9155192\n",
      "Training loss (for one batch) at step 240: 0.0560\n",
      "Seen so far: 15424 samples\n",
      "0.91572183\n",
      "Training loss (for one batch) at step 245: 0.1246\n",
      "Seen so far: 15744 samples\n",
      "0.91598445\n",
      "Training loss (for one batch) at step 250: 0.1511\n",
      "Seen so far: 16064 samples\n",
      "0.9163061\n",
      "Training loss (for one batch) at step 255: 0.0739\n",
      "Seen so far: 16384 samples\n",
      "0.9165479\n",
      "Training loss (for one batch) at step 260: 0.0137\n",
      "Seen so far: 16704 samples\n",
      "0.9168179\n",
      "Training loss (for one batch) at step 265: 0.2603\n",
      "Seen so far: 17024 samples\n",
      "0.9170549\n",
      "Training loss (for one batch) at step 270: 0.0730\n",
      "Seen so far: 17344 samples\n",
      "0.9173198\n",
      "Training loss (for one batch) at step 275: 0.0417\n",
      "Seen so far: 17664 samples\n",
      "0.9176273\n",
      "Training loss (for one batch) at step 280: 0.4244\n",
      "Seen so far: 17984 samples\n",
      "0.9177822\n",
      "Training loss (for one batch) at step 285: 0.0958\n",
      "Seen so far: 18304 samples\n",
      "0.9179952\n",
      "Training loss (for one batch) at step 290: 0.1138\n",
      "Seen so far: 18624 samples\n",
      "0.91826546\n",
      "Training loss (for one batch) at step 295: 0.1044\n",
      "Seen so far: 18944 samples\n",
      "0.9184889\n",
      "Training loss (for one batch) at step 300: 0.0240\n",
      "Seen so far: 19264 samples\n",
      "0.9187103\n",
      "Training loss (for one batch) at step 305: 0.1787\n",
      "Seen so far: 19584 samples\n",
      "0.918915\n",
      "Training loss (for one batch) at step 310: 0.2077\n",
      "Seen so far: 19904 samples\n",
      "0.91908866\n",
      "Training loss (for one batch) at step 315: 0.1798\n",
      "Seen so far: 20224 samples\n",
      "0.91921735\n",
      "Training loss (for one batch) at step 320: 0.0571\n",
      "Seen so far: 20544 samples\n",
      "0.9194745\n",
      "Training loss (for one batch) at step 325: 0.1000\n",
      "Seen so far: 20864 samples\n",
      "0.9196432\n",
      "Training loss (for one batch) at step 330: 0.0563\n",
      "Seen so far: 21184 samples\n",
      "0.9198247\n",
      "Training loss (for one batch) at step 335: 0.2271\n",
      "Seen so far: 21504 samples\n",
      "0.92000455\n",
      "Training loss (for one batch) at step 340: 0.0480\n",
      "Seen so far: 21824 samples\n",
      "0.92026764\n",
      "Training loss (for one batch) at step 345: 0.0560\n",
      "Seen so far: 22144 samples\n",
      "0.92047197\n",
      "Training loss (for one batch) at step 350: 0.0499\n",
      "Seen so far: 22464 samples\n",
      "0.9207446\n",
      "Training loss (for one batch) at step 355: 0.0958\n",
      "Seen so far: 22784 samples\n",
      "0.9209311\n",
      "Training loss (for one batch) at step 360: 0.1618\n",
      "Seen so far: 23104 samples\n",
      "0.92115754\n",
      "Training loss (for one batch) at step 365: 0.0665\n",
      "Seen so far: 23424 samples\n",
      "0.9213959\n",
      "Training loss (for one batch) at step 370: 0.1463\n",
      "Seen so far: 23744 samples\n",
      "0.9215219\n",
      "Training loss (for one batch) at step 375: 0.0508\n",
      "Seen so far: 24064 samples\n",
      "0.9216194\n",
      "Training loss (for one batch) at step 380: 0.0908\n",
      "Seen so far: 24384 samples\n",
      "0.92186624\n",
      "Training loss (for one batch) at step 385: 0.1057\n",
      "Seen so far: 24704 samples\n",
      "0.92208374\n",
      "Training loss (for one batch) at step 390: 0.1820\n",
      "Seen so far: 25024 samples\n",
      "0.92227226\n",
      "Training loss (for one batch) at step 395: 0.2590\n",
      "Seen so far: 25344 samples\n",
      "0.9224188\n",
      "Training loss (for one batch) at step 400: 0.0533\n",
      "Seen so far: 25664 samples\n",
      "0.92260426\n",
      "Training loss (for one batch) at step 405: 0.1633\n",
      "Seen so far: 25984 samples\n",
      "0.9227748\n",
      "Training loss (for one batch) at step 410: 0.0812\n",
      "Seen so far: 26304 samples\n",
      "0.92306364\n",
      "Training loss (for one batch) at step 415: 0.1783\n",
      "Seen so far: 26624 samples\n",
      "0.92323077\n",
      "Training loss (for one batch) at step 420: 0.1446\n",
      "Seen so far: 26944 samples\n",
      "0.9234361\n",
      "Training loss (for one batch) at step 425: 0.0770\n",
      "Seen so far: 27264 samples\n",
      "0.923574\n",
      "Training loss (for one batch) at step 430: 0.0550\n",
      "Seen so far: 27584 samples\n",
      "0.9238023\n",
      "Training loss (for one batch) at step 435: 0.0441\n",
      "Seen so far: 27904 samples\n",
      "0.9240157\n",
      "Training loss (for one batch) at step 440: 0.2063\n",
      "Seen so far: 28224 samples\n",
      "0.92420137\n",
      "Training loss (for one batch) at step 445: 0.0441\n",
      "Seen so far: 28544 samples\n",
      "0.9244501\n",
      "Training loss (for one batch) at step 450: 0.0305\n",
      "Seen so far: 28864 samples\n",
      "0.9246453\n",
      "Training loss (for one batch) at step 455: 0.0596\n",
      "Seen so far: 29184 samples\n",
      "0.9248133\n",
      "Training loss (for one batch) at step 460: 0.1369\n",
      "Seen so far: 29504 samples\n",
      "0.92492884\n",
      "Training loss (for one batch) at step 465: 0.0895\n",
      "Seen so far: 29824 samples\n",
      "0.9251579\n",
      "Training loss (for one batch) at step 470: 0.0501\n",
      "Seen so far: 30144 samples\n",
      "0.92537236\n",
      "Training loss (for one batch) at step 475: 0.1049\n",
      "Seen so far: 30464 samples\n",
      "0.92558515\n",
      "Training loss (for one batch) at step 480: 0.1399\n",
      "Seen so far: 30784 samples\n",
      "0.92573345\n",
      "Training loss (for one batch) at step 485: 0.0154\n",
      "Seen so far: 31104 samples\n",
      "0.92593056\n",
      "Training loss (for one batch) at step 490: 0.0899\n",
      "Seen so far: 31424 samples\n",
      "0.9261012\n",
      "Training loss (for one batch) at step 495: 0.0152\n",
      "Seen so far: 31744 samples\n",
      "0.9263573\n",
      "Training loss (for one batch) at step 500: 0.3562\n",
      "Seen so far: 32064 samples\n",
      "0.92657435\n",
      "Training loss (for one batch) at step 505: 0.0787\n",
      "Seen so far: 32384 samples\n",
      "0.92677736\n",
      "Training loss (for one batch) at step 510: 0.0456\n",
      "Seen so far: 32704 samples\n",
      "0.92695427\n",
      "Training loss (for one batch) at step 515: 0.0205\n",
      "Seen so far: 33024 samples\n",
      "0.92712975\n",
      "Training loss (for one batch) at step 520: 0.0259\n",
      "Seen so far: 33344 samples\n",
      "0.9273404\n",
      "Training loss (for one batch) at step 525: 0.0794\n",
      "Seen so far: 33664 samples\n",
      "0.92751306\n",
      "Training loss (for one batch) at step 530: 0.0671\n",
      "Seen so far: 33984 samples\n",
      "0.92768437\n",
      "Training loss (for one batch) at step 535: 0.0442\n",
      "Seen so far: 34304 samples\n",
      "0.92785436\n",
      "Training loss (for one batch) at step 540: 0.0549\n",
      "Seen so far: 34624 samples\n",
      "0.9280231\n",
      "Training loss (for one batch) at step 545: 0.1613\n",
      "Seen so far: 34944 samples\n",
      "0.9281666\n",
      "Training loss (for one batch) at step 550: 0.0301\n",
      "Seen so far: 35264 samples\n",
      "0.92835665\n",
      "Training loss (for one batch) at step 555: 0.1521\n",
      "Seen so far: 35584 samples\n",
      "0.9285097\n",
      "Training loss (for one batch) at step 560: 0.1384\n",
      "Seen so far: 35904 samples\n",
      "0.9286498\n",
      "Training loss (for one batch) at step 565: 0.2167\n",
      "Seen so far: 36224 samples\n",
      "0.9287653\n",
      "Training loss (for one batch) at step 570: 0.0445\n",
      "Seen so far: 36544 samples\n",
      "0.9288917\n",
      "Training loss (for one batch) at step 575: 0.0873\n",
      "Seen so far: 36864 samples\n",
      "0.9290638\n",
      "Training loss (for one batch) at step 580: 0.1100\n",
      "Seen so far: 37184 samples\n",
      "0.9291765\n",
      "Training loss (for one batch) at step 585: 0.1375\n",
      "Seen so far: 37504 samples\n",
      "0.9293231\n",
      "Training loss (for one batch) at step 590: 0.1064\n",
      "Seen so far: 37824 samples\n",
      "0.92948014\n",
      "Training loss (for one batch) at step 595: 0.0125\n",
      "Seen so far: 38144 samples\n",
      "0.9296705\n",
      "Training loss (for one batch) at step 600: 0.0878\n",
      "Seen so far: 38464 samples\n",
      "0.9298252\n",
      "Training loss (for one batch) at step 605: 0.0201\n",
      "Seen so far: 38784 samples\n",
      "0.9300015\n",
      "Training loss (for one batch) at step 610: 0.1509\n",
      "Seen so far: 39104 samples\n",
      "0.93006283\n",
      "Training loss (for one batch) at step 615: 0.2256\n",
      "Seen so far: 39424 samples\n",
      "0.93022573\n",
      "Training loss (for one batch) at step 620: 0.1194\n",
      "Seen so far: 39744 samples\n",
      "0.93040997\n",
      "Training loss (for one batch) at step 625: 0.0500\n",
      "Seen so far: 40064 samples\n",
      "0.93057036\n",
      "Training loss (for one batch) at step 630: 0.1210\n",
      "Seen so far: 40384 samples\n",
      "0.93066245\n",
      "Training loss (for one batch) at step 635: 0.0917\n",
      "Seen so far: 40704 samples\n",
      "0.9308208\n",
      "Training loss (for one batch) at step 640: 0.0667\n",
      "Seen so far: 41024 samples\n",
      "0.9309558\n",
      "Training loss (for one batch) at step 645: 0.0305\n",
      "Seen so far: 41344 samples\n",
      "0.9311675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 650: 0.0195\n",
      "Seen so far: 41664 samples\n",
      "0.9313224\n",
      "Training loss (for one batch) at step 655: 0.1153\n",
      "Seen so far: 41984 samples\n",
      "0.93153125\n",
      "Training loss (for one batch) at step 660: 0.1624\n",
      "Seen so far: 42304 samples\n",
      "0.93161803\n",
      "Training loss (for one batch) at step 665: 0.2814\n",
      "Seen so far: 42624 samples\n",
      "0.9317697\n",
      "Training loss (for one batch) at step 670: 0.0471\n",
      "Seen so far: 42944 samples\n",
      "0.9319313\n",
      "Training loss (for one batch) at step 675: 0.0425\n",
      "Seen so far: 43264 samples\n",
      "0.9320483\n",
      "Training loss (for one batch) at step 680: 0.1288\n",
      "Seen so far: 43584 samples\n",
      "0.9321537\n",
      "Training loss (for one batch) at step 685: 0.0101\n",
      "Seen so far: 43904 samples\n",
      "0.93230146\n",
      "Training loss (for one batch) at step 690: 0.0129\n",
      "Seen so far: 44224 samples\n",
      "0.9324697\n",
      "Training loss (for one batch) at step 695: 0.1276\n",
      "Seen so far: 44544 samples\n",
      "0.93260473\n",
      "Training loss (for one batch) at step 700: 0.2718\n",
      "Seen so far: 44864 samples\n",
      "0.93271744\n",
      "Training loss (for one batch) at step 705: 0.0232\n",
      "Seen so far: 45184 samples\n",
      "0.93287194\n",
      "Training loss (for one batch) at step 710: 0.1541\n",
      "Seen so far: 45504 samples\n",
      "0.93303597\n",
      "Training loss (for one batch) at step 715: 0.0274\n",
      "Seen so far: 45824 samples\n",
      "0.93317777\n",
      "Training loss (for one batch) at step 720: 0.0033\n",
      "Seen so far: 46144 samples\n",
      "0.93333966\n",
      "Training loss (for one batch) at step 725: 0.0455\n",
      "Seen so far: 46464 samples\n",
      "0.93349\n",
      "Training loss (for one batch) at step 730: 0.0274\n",
      "Seen so far: 46784 samples\n",
      "0.9336393\n",
      "Training loss (for one batch) at step 735: 0.0880\n",
      "Seen so far: 47104 samples\n",
      "0.93377715\n",
      "Training loss (for one batch) at step 740: 0.0309\n",
      "Seen so far: 47424 samples\n",
      "0.93392456\n",
      "Training loss (for one batch) at step 745: 0.0753\n",
      "Seen so far: 47744 samples\n",
      "0.93407094\n",
      "Training loss (for one batch) at step 750: 0.0065\n",
      "Seen so far: 48064 samples\n",
      "0.934237\n",
      "Training loss (for one batch) at step 755: 0.0172\n",
      "Seen so far: 48384 samples\n",
      "0.9343711\n",
      "Training loss (for one batch) at step 760: 0.0522\n",
      "Seen so far: 48704 samples\n",
      "0.9345146\n",
      "Training acc over epoch: 0.9346\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.1229\n",
      "Seen so far: 64 samples\n",
      "0.9346208\n",
      "Training loss (for one batch) at step 5: 0.2527\n",
      "Seen so far: 384 samples\n",
      "0.9347321\n",
      "Training loss (for one batch) at step 10: 0.0326\n",
      "Seen so far: 704 samples\n",
      "0.934863\n",
      "Training loss (for one batch) at step 15: 0.0806\n",
      "Seen so far: 1024 samples\n",
      "0.9350335\n",
      "Training loss (for one batch) at step 20: 0.0537\n",
      "Seen so far: 1344 samples\n",
      "0.9351928\n",
      "Training loss (for one batch) at step 25: 0.0903\n",
      "Seen so far: 1664 samples\n",
      "0.93535113\n",
      "Training loss (for one batch) at step 30: 0.0073\n",
      "Seen so far: 1984 samples\n",
      "0.9355185\n",
      "Training loss (for one batch) at step 35: 0.0162\n",
      "Seen so far: 2304 samples\n",
      "0.9356747\n",
      "Training loss (for one batch) at step 40: 0.1084\n",
      "Seen so far: 2624 samples\n",
      "0.9357901\n",
      "Training loss (for one batch) at step 45: 0.0452\n",
      "Seen so far: 2944 samples\n",
      "0.93595445\n",
      "Training loss (for one batch) at step 50: 0.0057\n",
      "Seen so far: 3264 samples\n",
      "0.93615735\n",
      "Training loss (for one batch) at step 55: 0.0660\n",
      "Seen so far: 3584 samples\n",
      "0.93630964\n",
      "Training loss (for one batch) at step 60: 0.0129\n",
      "Seen so far: 3904 samples\n",
      "0.9364806\n",
      "Training loss (for one batch) at step 65: 0.0240\n",
      "Seen so far: 4224 samples\n",
      "0.93664074\n",
      "Training loss (for one batch) at step 70: 0.1033\n",
      "Seen so far: 4544 samples\n",
      "0.9367607\n",
      "Training loss (for one batch) at step 75: 0.0705\n",
      "Seen so far: 4864 samples\n",
      "0.9369189\n",
      "Training loss (for one batch) at step 80: 0.0569\n",
      "Seen so far: 5184 samples\n",
      "0.93704706\n",
      "Training loss (for one batch) at step 85: 0.0729\n",
      "Seen so far: 5504 samples\n",
      "0.93721306\n",
      "Training loss (for one batch) at step 90: 0.1292\n",
      "Seen so far: 5824 samples\n",
      "0.9373588\n",
      "Training loss (for one batch) at step 95: 0.0321\n",
      "Seen so far: 6144 samples\n",
      "0.9374844\n",
      "Training loss (for one batch) at step 100: 0.0338\n",
      "Seen so far: 6464 samples\n",
      "0.9376283\n",
      "Training loss (for one batch) at step 105: 0.0839\n",
      "Seen so far: 6784 samples\n",
      "0.93774277\n",
      "Training loss (for one batch) at step 110: 0.0098\n",
      "Seen so far: 7104 samples\n",
      "0.9379041\n",
      "Training loss (for one batch) at step 115: 0.0401\n",
      "Seen so far: 7424 samples\n",
      "0.938017\n",
      "Training loss (for one batch) at step 120: 0.0271\n",
      "Seen so far: 7744 samples\n",
      "0.9381576\n",
      "Training loss (for one batch) at step 125: 0.0587\n",
      "Seen so far: 8064 samples\n",
      "0.9382785\n",
      "Training loss (for one batch) at step 130: 0.1164\n",
      "Seen so far: 8384 samples\n",
      "0.93832326\n",
      "Training loss (for one batch) at step 135: 0.0904\n",
      "Seen so far: 8704 samples\n",
      "0.93846166\n",
      "Training loss (for one batch) at step 140: 0.0359\n",
      "Seen so far: 9024 samples\n",
      "0.93862736\n",
      "Training loss (for one batch) at step 145: 0.0335\n",
      "Seen so far: 9344 samples\n",
      "0.9387267\n",
      "Training loss (for one batch) at step 150: 0.1294\n",
      "Seen so far: 9664 samples\n",
      "0.9388534\n",
      "Training loss (for one batch) at step 155: 0.0052\n",
      "Seen so far: 9984 samples\n",
      "0.93901646\n",
      "Training loss (for one batch) at step 160: 0.0668\n",
      "Seen so far: 10304 samples\n",
      "0.9391045\n",
      "Training loss (for one batch) at step 165: 0.0222\n",
      "Seen so far: 10624 samples\n",
      "0.93921053\n",
      "Training loss (for one batch) at step 170: 0.0700\n",
      "Seen so far: 10944 samples\n",
      "0.93931586\n",
      "Training loss (for one batch) at step 175: 0.0350\n",
      "Seen so far: 11264 samples\n",
      "0.93942064\n",
      "Training loss (for one batch) at step 180: 0.1179\n",
      "Seen so far: 11584 samples\n",
      "0.93947905\n",
      "Training loss (for one batch) at step 185: 0.0424\n",
      "Seen so far: 11904 samples\n",
      "0.9396192\n",
      "Training loss (for one batch) at step 190: 0.0186\n",
      "Seen so far: 12224 samples\n",
      "0.939713\n",
      "Training loss (for one batch) at step 195: 0.0242\n",
      "Seen so far: 12544 samples\n",
      "0.9398154\n",
      "Training loss (for one batch) at step 200: 0.0023\n",
      "Seen so far: 12864 samples\n",
      "0.9399262\n",
      "Training loss (for one batch) at step 205: 0.0108\n",
      "Seen so far: 13184 samples\n",
      "0.9400815\n",
      "Training loss (for one batch) at step 210: 0.0523\n",
      "Seen so far: 13504 samples\n",
      "0.9402089\n",
      "Training loss (for one batch) at step 215: 0.0939\n",
      "Seen so far: 13824 samples\n",
      "0.94031763\n",
      "Training loss (for one batch) at step 220: 0.0056\n",
      "Seen so far: 14144 samples\n",
      "0.9404526\n",
      "Training loss (for one batch) at step 225: 0.0779\n",
      "Seen so far: 14464 samples\n",
      "0.9405778\n",
      "Training loss (for one batch) at step 230: 0.0689\n",
      "Seen so far: 14784 samples\n",
      "0.94067574\n",
      "Training loss (for one batch) at step 235: 0.0068\n",
      "Seen so far: 15104 samples\n",
      "0.9407996\n",
      "Training loss (for one batch) at step 240: 0.2428\n",
      "Seen so far: 15424 samples\n",
      "0.940861\n",
      "Training loss (for one batch) at step 245: 0.0093\n",
      "Seen so far: 15744 samples\n",
      "0.9409484\n",
      "Training loss (for one batch) at step 250: 0.1892\n",
      "Seen so far: 16064 samples\n",
      "0.94104415\n",
      "Training loss (for one batch) at step 255: 0.0462\n",
      "Seen so far: 16384 samples\n",
      "0.9411656\n",
      "Training loss (for one batch) at step 260: 0.0116\n",
      "Seen so far: 16704 samples\n",
      "0.9412952\n",
      "Training loss (for one batch) at step 265: 0.0360\n",
      "Seen so far: 17024 samples\n",
      "0.94136304\n",
      "Training loss (for one batch) at step 270: 0.0265\n",
      "Seen so far: 17344 samples\n",
      "0.9414913\n",
      "Training loss (for one batch) at step 275: 0.0270\n",
      "Seen so far: 17664 samples\n",
      "0.94155824\n",
      "Training loss (for one batch) at step 280: 0.0294\n",
      "Seen so far: 17984 samples\n",
      "0.9416766\n",
      "Training loss (for one batch) at step 285: 0.0699\n",
      "Seen so far: 18304 samples\n",
      "0.9417771\n",
      "Training loss (for one batch) at step 290: 0.0257\n",
      "Seen so far: 18624 samples\n",
      "0.9419286\n",
      "Training loss (for one batch) at step 295: 0.0088\n",
      "Seen so far: 18944 samples\n",
      "0.94206214\n",
      "Training loss (for one batch) at step 300: 0.0149\n",
      "Seen so far: 19264 samples\n",
      "0.94217783\n",
      "Training loss (for one batch) at step 305: 0.0150\n",
      "Seen so far: 19584 samples\n",
      "0.9422929\n",
      "Training loss (for one batch) at step 310: 0.0429\n",
      "Seen so far: 19904 samples\n",
      "0.9423989\n",
      "Training loss (for one batch) at step 315: 0.0453\n",
      "Seen so far: 20224 samples\n",
      "0.94251275\n",
      "Training loss (for one batch) at step 320: 0.0447\n",
      "Seen so far: 20544 samples\n",
      "0.94263446\n",
      "Training loss (for one batch) at step 325: 0.0256\n",
      "Seen so far: 20864 samples\n",
      "0.9427218\n",
      "Training loss (for one batch) at step 330: 0.0722\n",
      "Seen so far: 21184 samples\n",
      "0.94282544\n",
      "Training loss (for one batch) at step 335: 0.0148\n",
      "Seen so far: 21504 samples\n",
      "0.94297045\n",
      "Training loss (for one batch) at step 340: 0.0064\n",
      "Seen so far: 21824 samples\n",
      "0.9430729\n",
      "Training loss (for one batch) at step 345: 0.1947\n",
      "Seen so far: 22144 samples\n",
      "0.9431331\n",
      "Training loss (for one batch) at step 350: 0.0419\n",
      "Seen so far: 22464 samples\n",
      "0.9432429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 355: 0.0136\n",
      "Seen so far: 22784 samples\n",
      "0.9433106\n",
      "Training loss (for one batch) at step 360: 0.1124\n",
      "Seen so far: 23104 samples\n",
      "0.9433697\n",
      "Training loss (for one batch) at step 365: 0.0169\n",
      "Seen so far: 23424 samples\n",
      "0.9434615\n",
      "Training loss (for one batch) at step 370: 0.0187\n",
      "Seen so far: 23744 samples\n",
      "0.94356924\n",
      "Training loss (for one batch) at step 375: 0.1118\n",
      "Seen so far: 24064 samples\n",
      "0.9436354\n",
      "Training loss (for one batch) at step 380: 0.0545\n",
      "Seen so far: 24384 samples\n",
      "0.9437421\n",
      "Training loss (for one batch) at step 385: 0.0609\n",
      "Seen so far: 24704 samples\n",
      "0.94376665\n",
      "Training loss (for one batch) at step 390: 0.1262\n",
      "Seen so far: 25024 samples\n",
      "0.9438481\n",
      "Training loss (for one batch) at step 395: 0.0319\n",
      "Seen so far: 25344 samples\n",
      "0.9439372\n",
      "Training loss (for one batch) at step 400: 0.0726\n",
      "Seen so far: 25664 samples\n",
      "0.944042\n",
      "Training loss (for one batch) at step 405: 0.0056\n",
      "Seen so far: 25984 samples\n",
      "0.9441221\n",
      "Training loss (for one batch) at step 410: 0.1811\n",
      "Seen so far: 26304 samples\n",
      "0.94416946\n",
      "Training loss (for one batch) at step 415: 0.1217\n",
      "Seen so far: 26624 samples\n",
      "0.9442086\n",
      "Training loss (for one batch) at step 420: 0.0916\n",
      "Seen so far: 26944 samples\n",
      "0.94430363\n",
      "Training loss (for one batch) at step 425: 0.0971\n",
      "Seen so far: 27264 samples\n",
      "0.94431823\n",
      "Training loss (for one batch) at step 430: 0.0549\n",
      "Seen so far: 27584 samples\n",
      "0.94438857\n",
      "Training loss (for one batch) at step 435: 0.0628\n",
      "Seen so far: 27904 samples\n",
      "0.9444586\n",
      "Training loss (for one batch) at step 440: 0.1775\n",
      "Seen so far: 28224 samples\n",
      "0.94451237\n",
      "Training loss (for one batch) at step 445: 0.1093\n",
      "Seen so far: 28544 samples\n",
      "0.9445817\n",
      "Training loss (for one batch) at step 450: 0.0649\n",
      "Seen so far: 28864 samples\n",
      "0.9446428\n",
      "Training loss (for one batch) at step 455: 0.1536\n",
      "Seen so far: 29184 samples\n",
      "0.9447508\n",
      "Training loss (for one batch) at step 460: 0.0656\n",
      "Seen so far: 29504 samples\n",
      "0.9447954\n",
      "Training loss (for one batch) at step 465: 0.0383\n",
      "Seen so far: 29824 samples\n",
      "0.9448634\n",
      "Training loss (for one batch) at step 470: 0.1299\n",
      "Seen so far: 30144 samples\n",
      "0.9449701\n",
      "Training loss (for one batch) at step 475: 0.0403\n",
      "Seen so far: 30464 samples\n",
      "0.945006\n",
      "Training loss (for one batch) at step 480: 0.0707\n",
      "Seen so far: 30784 samples\n",
      "0.94505733\n",
      "Training loss (for one batch) at step 485: 0.1199\n",
      "Seen so far: 31104 samples\n",
      "0.94513947\n",
      "Training loss (for one batch) at step 490: 0.0313\n",
      "Seen so far: 31424 samples\n",
      "0.9452212\n",
      "Training loss (for one batch) at step 495: 0.0941\n",
      "Seen so far: 31744 samples\n",
      "0.9452793\n",
      "Training loss (for one batch) at step 500: 0.0353\n",
      "Seen so far: 32064 samples\n",
      "0.9453372\n",
      "Training loss (for one batch) at step 505: 0.0170\n",
      "Seen so far: 32384 samples\n",
      "0.94540244\n",
      "Training loss (for one batch) at step 510: 0.0451\n",
      "Seen so far: 32704 samples\n",
      "0.94547504\n",
      "Training loss (for one batch) at step 515: 0.1637\n",
      "Seen so far: 33024 samples\n",
      "0.94552433\n",
      "Training loss (for one batch) at step 520: 0.0303\n",
      "Seen so far: 33344 samples\n",
      "0.94561154\n",
      "Training loss (for one batch) at step 525: 0.0427\n",
      "Seen so far: 33664 samples\n",
      "0.94572115\n",
      "Training loss (for one batch) at step 530: 0.0410\n",
      "Seen so far: 33984 samples\n",
      "0.9457847\n",
      "Training loss (for one batch) at step 535: 0.0150\n",
      "Seen so far: 34304 samples\n",
      "0.9458782\n",
      "Training loss (for one batch) at step 540: 0.0505\n",
      "Seen so far: 34624 samples\n",
      "0.94594103\n",
      "Training loss (for one batch) at step 545: 0.0527\n",
      "Seen so far: 34944 samples\n",
      "0.94601864\n",
      "Training loss (for one batch) at step 550: 0.1222\n",
      "Seen so far: 35264 samples\n",
      "0.9460959\n",
      "Training loss (for one batch) at step 555: 0.0189\n",
      "Seen so far: 35584 samples\n",
      "0.94621027\n",
      "Training loss (for one batch) at step 560: 0.0032\n",
      "Seen so far: 35904 samples\n",
      "0.9463166\n",
      "Training loss (for one batch) at step 565: 0.0557\n",
      "Seen so far: 36224 samples\n",
      "0.9463702\n",
      "Training loss (for one batch) at step 570: 0.0647\n",
      "Seen so far: 36544 samples\n",
      "0.94643843\n",
      "Training loss (for one batch) at step 575: 0.1175\n",
      "Seen so far: 36864 samples\n",
      "0.94652116\n",
      "Training loss (for one batch) at step 580: 0.1083\n",
      "Seen so far: 37184 samples\n",
      "0.9465813\n",
      "Training loss (for one batch) at step 585: 0.0895\n",
      "Seen so far: 37504 samples\n",
      "0.94664854\n",
      "Training loss (for one batch) at step 590: 0.0086\n",
      "Seen so far: 37824 samples\n",
      "0.9467376\n",
      "Training loss (for one batch) at step 595: 0.0487\n",
      "Seen so far: 38144 samples\n",
      "0.9468188\n",
      "Training loss (for one batch) at step 600: 0.0175\n",
      "Seen so far: 38464 samples\n",
      "0.94688505\n",
      "Training loss (for one batch) at step 605: 0.2106\n",
      "Seen so far: 38784 samples\n",
      "0.9469656\n",
      "Training loss (for one batch) at step 610: 0.0320\n",
      "Seen so far: 39104 samples\n",
      "0.94704574\n",
      "Training loss (for one batch) at step 615: 0.0708\n",
      "Seen so far: 39424 samples\n",
      "0.9471328\n",
      "Training loss (for one batch) at step 620: 0.0513\n",
      "Seen so far: 39744 samples\n",
      "0.94720495\n",
      "Training loss (for one batch) at step 625: 0.0209\n",
      "Seen so far: 40064 samples\n",
      "0.9472695\n",
      "Training loss (for one batch) at step 630: 0.0892\n",
      "Seen so far: 40384 samples\n",
      "0.94734097\n",
      "Training loss (for one batch) at step 635: 0.0478\n",
      "Seen so far: 40704 samples\n",
      "0.9474049\n",
      "Training loss (for one batch) at step 640: 0.0934\n",
      "Seen so far: 41024 samples\n",
      "0.94744694\n",
      "Training loss (for one batch) at step 645: 0.0632\n",
      "Seen so far: 41344 samples\n",
      "0.94752467\n",
      "Training loss (for one batch) at step 650: 0.0393\n",
      "Seen so far: 41664 samples\n",
      "0.9475878\n",
      "Training loss (for one batch) at step 655: 0.0085\n",
      "Seen so far: 41984 samples\n",
      "0.947672\n",
      "Training loss (for one batch) at step 660: 0.0047\n",
      "Seen so far: 42304 samples\n",
      "0.9477701\n",
      "Training loss (for one batch) at step 665: 0.0094\n",
      "Seen so far: 42624 samples\n",
      "0.9478393\n",
      "Training loss (for one batch) at step 670: 0.1663\n",
      "Seen so far: 42944 samples\n",
      "0.94785845\n",
      "Training loss (for one batch) at step 675: 0.1298\n",
      "Seen so far: 43264 samples\n",
      "0.9479272\n",
      "Training loss (for one batch) at step 680: 0.2395\n",
      "Seen so far: 43584 samples\n",
      "0.94798136\n",
      "Training loss (for one batch) at step 685: 0.0277\n",
      "Seen so far: 43904 samples\n",
      "0.9480495\n",
      "Training loss (for one batch) at step 690: 0.1146\n",
      "Seen so far: 44224 samples\n",
      "0.94808906\n",
      "Training loss (for one batch) at step 695: 0.0663\n",
      "Seen so far: 44544 samples\n",
      "0.9481637\n",
      "Training loss (for one batch) at step 700: 0.0896\n",
      "Seen so far: 44864 samples\n",
      "0.94821686\n",
      "Training loss (for one batch) at step 705: 0.0081\n",
      "Seen so far: 45184 samples\n",
      "0.94828385\n",
      "Training loss (for one batch) at step 710: 0.0201\n",
      "Seen so far: 45504 samples\n",
      "0.94831556\n",
      "Training loss (for one batch) at step 715: 0.0553\n",
      "Seen so far: 45824 samples\n",
      "0.94839597\n",
      "Training loss (for one batch) at step 720: 0.0369\n",
      "Seen so far: 46144 samples\n",
      "0.9484412\n",
      "Training loss (for one batch) at step 725: 0.0213\n",
      "Seen so far: 46464 samples\n",
      "0.94850016\n",
      "Training loss (for one batch) at step 730: 0.0567\n",
      "Seen so far: 46784 samples\n",
      "0.9485588\n",
      "Training loss (for one batch) at step 735: 0.0284\n",
      "Seen so far: 47104 samples\n",
      "0.94863796\n",
      "Training loss (for one batch) at step 740: 0.0838\n",
      "Seen so far: 47424 samples\n",
      "0.9487167\n",
      "Training loss (for one batch) at step 745: 0.0147\n",
      "Seen so far: 47744 samples\n",
      "0.9487883\n",
      "Training loss (for one batch) at step 750: 0.0697\n",
      "Seen so far: 48064 samples\n",
      "0.9488321\n",
      "Training loss (for one batch) at step 755: 0.1372\n",
      "Seen so far: 48384 samples\n",
      "0.94887567\n",
      "Training loss (for one batch) at step 760: 0.0495\n",
      "Seen so far: 48704 samples\n",
      "0.9489396\n",
      "Training acc over epoch: 0.9490\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.0544\n",
      "Seen so far: 64 samples\n",
      "0.94896686\n",
      "Training loss (for one batch) at step 5: 0.0572\n",
      "Seen so far: 384 samples\n",
      "0.94901675\n",
      "Training loss (for one batch) at step 10: 0.0557\n",
      "Seen so far: 704 samples\n",
      "0.9490935\n",
      "Training loss (for one batch) at step 15: 0.1349\n",
      "Seen so far: 1024 samples\n",
      "0.9490955\n",
      "Training loss (for one batch) at step 20: 0.0046\n",
      "Seen so far: 1344 samples\n",
      "0.9491718\n",
      "Training loss (for one batch) at step 25: 0.0475\n",
      "Seen so far: 1664 samples\n",
      "0.94923425\n",
      "Training loss (for one batch) at step 30: 0.0572\n",
      "Seen so far: 1984 samples\n",
      "0.9493032\n",
      "Training loss (for one batch) at step 35: 0.4458\n",
      "Seen so far: 2304 samples\n",
      "0.9493181\n",
      "Training loss (for one batch) at step 40: 0.0471\n",
      "Seen so far: 2624 samples\n",
      "0.9493866\n",
      "Training loss (for one batch) at step 45: 0.1119\n",
      "Seen so far: 2944 samples\n",
      "0.9494414\n",
      "Training loss (for one batch) at step 50: 0.1202\n",
      "Seen so far: 3264 samples\n",
      "0.94946927\n",
      "Training loss (for one batch) at step 55: 0.0643\n",
      "Seen so far: 3584 samples\n",
      "0.9495503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 60: 0.0141\n",
      "Seen so far: 3904 samples\n",
      "0.9496177\n",
      "Training loss (for one batch) at step 65: 0.0589\n",
      "Seen so far: 4224 samples\n",
      "0.94965166\n",
      "Training loss (for one batch) at step 70: 0.0110\n",
      "Seen so far: 4544 samples\n",
      "0.9497119\n",
      "Training loss (for one batch) at step 75: 0.1674\n",
      "Seen so far: 4864 samples\n",
      "0.94974554\n",
      "Training loss (for one batch) at step 80: 0.0470\n",
      "Seen so far: 5184 samples\n",
      "0.9497856\n",
      "Training loss (for one batch) at step 85: 0.0220\n",
      "Seen so far: 5504 samples\n",
      "0.9498452\n",
      "Training loss (for one batch) at step 90: 0.0080\n",
      "Seen so far: 5824 samples\n",
      "0.94987833\n",
      "Training loss (for one batch) at step 95: 0.1284\n",
      "Seen so far: 6144 samples\n",
      "0.94993097\n",
      "Training loss (for one batch) at step 100: 0.0114\n",
      "Seen so far: 6464 samples\n",
      "0.94998336\n",
      "Training loss (for one batch) at step 105: 0.0766\n",
      "Seen so far: 6784 samples\n",
      "0.95005506\n",
      "Training loss (for one batch) at step 110: 0.0509\n",
      "Seen so far: 7104 samples\n",
      "0.950094\n",
      "Training loss (for one batch) at step 115: 0.1212\n",
      "Seen so far: 7424 samples\n",
      "0.9501392\n",
      "Training loss (for one batch) at step 120: 0.0831\n",
      "Seen so far: 7744 samples\n",
      "0.95017785\n",
      "Training loss (for one batch) at step 125: 0.0425\n",
      "Seen so far: 8064 samples\n",
      "0.95022273\n",
      "Training loss (for one batch) at step 130: 0.0797\n",
      "Seen so far: 8384 samples\n",
      "0.95026094\n",
      "Training loss (for one batch) at step 135: 0.1014\n",
      "Seen so far: 8704 samples\n",
      "0.9503119\n",
      "Training loss (for one batch) at step 140: 0.0575\n",
      "Seen so far: 9024 samples\n",
      "0.9503627\n",
      "Training loss (for one batch) at step 145: 0.1424\n",
      "Seen so far: 9344 samples\n",
      "0.9504325\n",
      "Training loss (for one batch) at step 150: 0.0327\n",
      "Seen so far: 9664 samples\n",
      "0.95049554\n",
      "Training loss (for one batch) at step 155: 0.0201\n",
      "Seen so far: 9984 samples\n",
      "0.9505648\n",
      "Training loss (for one batch) at step 160: 0.0530\n",
      "Seen so far: 10304 samples\n",
      "0.95061463\n",
      "Training loss (for one batch) at step 165: 0.1240\n",
      "Seen so far: 10624 samples\n",
      "0.9506706\n",
      "Training loss (for one batch) at step 170: 0.1240\n",
      "Seen so far: 10944 samples\n",
      "0.95072\n",
      "Training loss (for one batch) at step 175: 0.1686\n",
      "Seen so far: 11264 samples\n",
      "0.95075655\n",
      "Training loss (for one batch) at step 180: 0.1174\n",
      "Seen so far: 11584 samples\n",
      "0.9507993\n",
      "Training loss (for one batch) at step 185: 0.0151\n",
      "Seen so far: 11904 samples\n",
      "0.9508481\n",
      "Training loss (for one batch) at step 190: 0.0960\n",
      "Seen so far: 12224 samples\n",
      "0.9509094\n",
      "Training loss (for one batch) at step 195: 0.0039\n",
      "Seen so far: 12544 samples\n",
      "0.9509766\n",
      "Training loss (for one batch) at step 200: 0.1430\n",
      "Seen so far: 12864 samples\n",
      "0.9510311\n",
      "Training loss (for one batch) at step 205: 0.1325\n",
      "Seen so far: 13184 samples\n",
      "0.95109785\n",
      "Training loss (for one batch) at step 210: 0.1523\n",
      "Seen so far: 13504 samples\n",
      "0.9511207\n",
      "Training loss (for one batch) at step 215: 0.0978\n",
      "Seen so far: 13824 samples\n",
      "0.9511683\n",
      "Training loss (for one batch) at step 220: 0.0040\n",
      "Seen so far: 14144 samples\n",
      "0.9512406\n",
      "Training loss (for one batch) at step 225: 0.0848\n",
      "Seen so far: 14464 samples\n",
      "0.9512816\n",
      "Training loss (for one batch) at step 230: 0.0187\n",
      "Seen so far: 14784 samples\n",
      "0.95134103\n",
      "Training loss (for one batch) at step 235: 0.0281\n",
      "Seen so far: 15104 samples\n",
      "0.951394\n",
      "Training loss (for one batch) at step 240: 0.1006\n",
      "Seen so far: 15424 samples\n",
      "0.951453\n",
      "Training loss (for one batch) at step 245: 0.0050\n",
      "Seen so far: 15744 samples\n",
      "0.9515178\n",
      "Training loss (for one batch) at step 250: 0.0686\n",
      "Seen so far: 16064 samples\n",
      "0.9515763\n",
      "Training loss (for one batch) at step 255: 0.1589\n",
      "Seen so far: 16384 samples\n",
      "0.95161\n",
      "Training loss (for one batch) at step 260: 0.0835\n",
      "Seen so far: 16704 samples\n",
      "0.9516497\n",
      "Training loss (for one batch) at step 265: 0.0130\n",
      "Seen so far: 17024 samples\n",
      "0.95167094\n",
      "Training loss (for one batch) at step 270: 0.0568\n",
      "Seen so far: 17344 samples\n",
      "0.9517287\n",
      "Training loss (for one batch) at step 275: 0.0425\n",
      "Seen so far: 17664 samples\n",
      "0.95176184\n",
      "Training loss (for one batch) at step 280: 0.0141\n",
      "Seen so far: 17984 samples\n",
      "0.95182526\n",
      "Training loss (for one batch) at step 285: 0.1788\n",
      "Seen so far: 18304 samples\n",
      "0.9518641\n",
      "Training loss (for one batch) at step 290: 0.0607\n",
      "Seen so far: 18624 samples\n",
      "0.95193315\n",
      "Training loss (for one batch) at step 295: 0.0727\n",
      "Seen so far: 18944 samples\n",
      "0.9519898\n",
      "Training loss (for one batch) at step 300: 0.0829\n",
      "Seen so far: 19264 samples\n",
      "0.9520463\n",
      "Training loss (for one batch) at step 305: 0.0155\n",
      "Seen so far: 19584 samples\n",
      "0.9521085\n",
      "Training loss (for one batch) at step 310: 0.0213\n",
      "Seen so far: 19904 samples\n",
      "0.9521585\n",
      "Training loss (for one batch) at step 315: 0.1168\n",
      "Seen so far: 20224 samples\n",
      "0.9522143\n",
      "Training loss (for one batch) at step 320: 0.0167\n",
      "Seen so far: 20544 samples\n",
      "0.9522758\n",
      "Training loss (for one batch) at step 325: 0.0127\n",
      "Seen so far: 20864 samples\n",
      "0.95234317\n",
      "Training loss (for one batch) at step 330: 0.0723\n",
      "Seen so far: 21184 samples\n",
      "0.95241016\n",
      "Training loss (for one batch) at step 335: 0.0896\n",
      "Seen so far: 21504 samples\n",
      "0.952471\n",
      "Training loss (for one batch) at step 340: 0.0059\n",
      "Seen so far: 21824 samples\n",
      "0.9525198\n",
      "Training loss (for one batch) at step 345: 0.0687\n",
      "Seen so far: 22144 samples\n",
      "0.95255053\n",
      "Training loss (for one batch) at step 350: 0.0014\n",
      "Seen so far: 22464 samples\n",
      "0.9525871\n",
      "Training loss (for one batch) at step 355: 0.0093\n",
      "Seen so far: 22784 samples\n",
      "0.95264125\n",
      "Training loss (for one batch) at step 360: 0.0726\n",
      "Seen so far: 23104 samples\n",
      "0.9526893\n",
      "Training loss (for one batch) at step 365: 0.0074\n",
      "Seen so far: 23424 samples\n",
      "0.9527548\n",
      "Training loss (for one batch) at step 370: 0.1520\n",
      "Seen so far: 23744 samples\n",
      "0.95282006\n",
      "Training loss (for one batch) at step 375: 0.1597\n",
      "Seen so far: 24064 samples\n",
      "0.95286167\n",
      "Training loss (for one batch) at step 380: 0.0081\n",
      "Seen so far: 24384 samples\n",
      "0.9529323\n",
      "Training loss (for one batch) at step 385: 0.0573\n",
      "Seen so far: 24704 samples\n",
      "0.9529677\n",
      "Training loss (for one batch) at step 390: 0.0827\n",
      "Seen so far: 25024 samples\n",
      "0.9530088\n",
      "Training loss (for one batch) at step 395: 0.0671\n",
      "Seen so far: 25344 samples\n",
      "0.9530439\n",
      "Training loss (for one batch) at step 400: 0.0390\n",
      "Seen so far: 25664 samples\n",
      "0.9531137\n",
      "Training loss (for one batch) at step 405: 0.0187\n",
      "Seen so far: 25984 samples\n",
      "0.95318323\n",
      "Training loss (for one batch) at step 410: 0.1265\n",
      "Seen so far: 26304 samples\n",
      "0.95324093\n",
      "Training loss (for one batch) at step 415: 0.3512\n",
      "Seen so far: 26624 samples\n",
      "0.9532696\n",
      "Training loss (for one batch) at step 420: 0.0303\n",
      "Seen so far: 26944 samples\n",
      "0.95333844\n",
      "Training loss (for one batch) at step 425: 0.0186\n",
      "Seen so far: 27264 samples\n",
      "0.9533783\n",
      "Training loss (for one batch) at step 430: 0.0331\n",
      "Seen so far: 27584 samples\n",
      "0.9534065\n",
      "Training loss (for one batch) at step 435: 0.0127\n",
      "Seen so far: 27904 samples\n",
      "0.95346904\n",
      "Training loss (for one batch) at step 440: 0.0666\n",
      "Seen so far: 28224 samples\n",
      "0.9535027\n",
      "Training loss (for one batch) at step 445: 0.2396\n",
      "Seen so far: 28544 samples\n",
      "0.9535363\n",
      "Training loss (for one batch) at step 450: 0.0333\n",
      "Seen so far: 28864 samples\n",
      "0.95359254\n",
      "Training loss (for one batch) at step 455: 0.1073\n",
      "Seen so far: 29184 samples\n",
      "0.9535917\n",
      "Training loss (for one batch) at step 460: 0.0830\n",
      "Seen so far: 29504 samples\n",
      "0.95363057\n",
      "Training loss (for one batch) at step 465: 0.0665\n",
      "Seen so far: 29824 samples\n",
      "0.95366365\n",
      "Training loss (for one batch) at step 470: 0.0736\n",
      "Seen so far: 30144 samples\n",
      "0.9536966\n",
      "Training loss (for one batch) at step 475: 0.0149\n",
      "Seen so far: 30464 samples\n",
      "0.9537577\n",
      "Training loss (for one batch) at step 480: 0.1089\n",
      "Seen so far: 30784 samples\n",
      "0.95379037\n",
      "Training loss (for one batch) at step 485: 0.0292\n",
      "Seen so far: 31104 samples\n",
      "0.95383424\n",
      "Training loss (for one batch) at step 490: 0.1397\n",
      "Seen so far: 31424 samples\n",
      "0.95388347\n",
      "Training loss (for one batch) at step 495: 0.0024\n",
      "Seen so far: 31744 samples\n",
      "0.9539326\n",
      "Training loss (for one batch) at step 500: 0.0240\n",
      "Seen so far: 32064 samples\n",
      "0.95399266\n",
      "Training loss (for one batch) at step 505: 0.1504\n",
      "Seen so far: 32384 samples\n",
      "0.9540358\n",
      "Training loss (for one batch) at step 510: 0.0595\n",
      "Seen so far: 32704 samples\n",
      "0.9541067\n",
      "Training loss (for one batch) at step 515: 0.1463\n",
      "Seen so far: 33024 samples\n",
      "0.9541495\n",
      "Training loss (for one batch) at step 520: 0.0121\n",
      "Seen so far: 33344 samples\n",
      "0.954181\n",
      "Training loss (for one batch) at step 525: 0.3643\n",
      "Seen so far: 33664 samples\n",
      "0.9542124\n",
      "Training loss (for one batch) at step 530: 0.0085\n",
      "Seen so far: 33984 samples\n",
      "0.9542714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 535: 0.0851\n",
      "Seen so far: 34304 samples\n",
      "0.9543246\n",
      "Training loss (for one batch) at step 540: 0.0423\n",
      "Seen so far: 34624 samples\n",
      "0.9543225\n",
      "Training loss (for one batch) at step 545: 0.1783\n",
      "Seen so far: 34944 samples\n",
      "0.95435894\n",
      "Training loss (for one batch) at step 550: 0.0021\n",
      "Seen so far: 35264 samples\n",
      "0.95439523\n",
      "Training loss (for one batch) at step 555: 0.0245\n",
      "Seen so far: 35584 samples\n",
      "0.9544589\n",
      "Training loss (for one batch) at step 560: 0.0128\n",
      "Seen so far: 35904 samples\n",
      "0.95446754\n",
      "Training loss (for one batch) at step 565: 0.0731\n",
      "Seen so far: 36224 samples\n",
      "0.9545144\n",
      "Training loss (for one batch) at step 570: 0.1408\n",
      "Seen so far: 36544 samples\n",
      "0.95452285\n",
      "Training loss (for one batch) at step 575: 0.0045\n",
      "Seen so far: 36864 samples\n",
      "0.95457494\n",
      "Training loss (for one batch) at step 580: 0.1767\n",
      "Seen so far: 37184 samples\n",
      "0.9545887\n",
      "Training loss (for one batch) at step 585: 0.1247\n",
      "Seen so far: 37504 samples\n",
      "0.95461875\n",
      "Training loss (for one batch) at step 590: 0.1199\n",
      "Seen so far: 37824 samples\n",
      "0.9546758\n",
      "Training loss (for one batch) at step 595: 0.0628\n",
      "Seen so far: 38144 samples\n",
      "0.95472723\n",
      "Training loss (for one batch) at step 600: 0.0826\n",
      "Seen so far: 38464 samples\n",
      "0.9547569\n",
      "Training loss (for one batch) at step 605: 0.3022\n",
      "Seen so far: 38784 samples\n",
      "0.9547864\n",
      "Training loss (for one batch) at step 610: 0.1678\n",
      "Seen so far: 39104 samples\n",
      "0.95481586\n",
      "Training loss (for one batch) at step 615: 0.0251\n",
      "Seen so far: 39424 samples\n",
      "0.9548667\n",
      "Training loss (for one batch) at step 620: 0.0526\n",
      "Seen so far: 39744 samples\n",
      "0.9549174\n",
      "Training loss (for one batch) at step 625: 0.0304\n",
      "Seen so far: 40064 samples\n",
      "0.95498395\n",
      "Training loss (for one batch) at step 630: 0.0738\n",
      "Seen so far: 40384 samples\n",
      "0.9550022\n",
      "Training loss (for one batch) at step 635: 0.0296\n",
      "Seen so far: 40704 samples\n",
      "0.9550523\n",
      "Training loss (for one batch) at step 640: 0.0066\n",
      "Seen so far: 41024 samples\n",
      "0.95511836\n",
      "Training loss (for one batch) at step 645: 0.0412\n",
      "Seen so far: 41344 samples\n",
      "0.9551788\n",
      "Training loss (for one batch) at step 650: 0.0401\n",
      "Seen so far: 41664 samples\n",
      "0.955239\n",
      "Training loss (for one batch) at step 655: 0.0334\n",
      "Seen so far: 41984 samples\n",
      "0.95527786\n",
      "Training loss (for one batch) at step 660: 0.0432\n",
      "Seen so far: 42304 samples\n",
      "0.9553377\n",
      "Training loss (for one batch) at step 665: 0.0136\n",
      "Seen so far: 42624 samples\n",
      "0.9553868\n",
      "Training loss (for one batch) at step 670: 0.0655\n",
      "Seen so far: 42944 samples\n",
      "0.95543575\n",
      "Training loss (for one batch) at step 675: 0.0880\n",
      "Seen so far: 43264 samples\n",
      "0.95549506\n",
      "Training loss (for one batch) at step 680: 0.0018\n",
      "Seen so far: 43584 samples\n",
      "0.9555489\n",
      "Training loss (for one batch) at step 685: 0.1327\n",
      "Seen so far: 43904 samples\n",
      "0.95557106\n",
      "Training loss (for one batch) at step 690: 0.0497\n",
      "Seen so far: 44224 samples\n",
      "0.9556351\n",
      "Training loss (for one batch) at step 695: 0.0064\n",
      "Seen so far: 44544 samples\n",
      "0.9556884\n",
      "Training loss (for one batch) at step 700: 0.0111\n",
      "Seen so far: 44864 samples\n",
      "0.9557416\n",
      "Training loss (for one batch) at step 705: 0.0145\n",
      "Seen so far: 45184 samples\n",
      "0.955805\n",
      "Training loss (for one batch) at step 710: 0.0958\n",
      "Seen so far: 45504 samples\n",
      "0.95587337\n",
      "Training loss (for one batch) at step 715: 0.0971\n",
      "Seen so far: 45824 samples\n",
      "0.9559312\n",
      "Training loss (for one batch) at step 720: 0.1201\n",
      "Seen so far: 46144 samples\n",
      "0.95596284\n",
      "Training loss (for one batch) at step 725: 0.0711\n",
      "Seen so far: 46464 samples\n",
      "0.95599437\n",
      "Training loss (for one batch) at step 730: 0.0689\n",
      "Seen so far: 46784 samples\n",
      "0.95604134\n",
      "Training loss (for one batch) at step 735: 0.0050\n",
      "Seen so far: 47104 samples\n",
      "0.9560881\n",
      "Training loss (for one batch) at step 740: 0.0819\n",
      "Seen so far: 47424 samples\n",
      "0.9561245\n",
      "Training loss (for one batch) at step 745: 0.0679\n",
      "Seen so far: 47744 samples\n",
      "0.956135\n",
      "Training loss (for one batch) at step 750: 0.0138\n",
      "Seen so far: 48064 samples\n",
      "0.9561968\n",
      "Training loss (for one batch) at step 755: 0.0622\n",
      "Seen so far: 48384 samples\n",
      "0.9562379\n",
      "Training loss (for one batch) at step 760: 0.0346\n",
      "Seen so far: 48704 samples\n",
      "0.9562789\n",
      "Training acc over epoch: 0.9563\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.0702\n",
      "Seen so far: 64 samples\n",
      "0.95630586\n",
      "Training loss (for one batch) at step 5: 0.0109\n",
      "Seen so far: 384 samples\n",
      "0.95636195\n",
      "Training loss (for one batch) at step 10: 0.0077\n",
      "Seen so far: 704 samples\n",
      "0.9564076\n",
      "Training loss (for one batch) at step 15: 0.0705\n",
      "Seen so far: 1024 samples\n",
      "0.9564583\n",
      "Training loss (for one batch) at step 20: 0.0301\n",
      "Seen so far: 1344 samples\n",
      "0.9564884\n",
      "Training loss (for one batch) at step 25: 0.0826\n",
      "Seen so far: 1664 samples\n",
      "0.9565286\n",
      "Training loss (for one batch) at step 30: 0.0594\n",
      "Seen so far: 1984 samples\n",
      "0.95657873\n",
      "Training loss (for one batch) at step 35: 0.0370\n",
      "Seen so far: 2304 samples\n",
      "0.9566288\n",
      "Training loss (for one batch) at step 40: 0.0143\n",
      "Seen so far: 2624 samples\n",
      "0.9566736\n",
      "Training loss (for one batch) at step 45: 0.0314\n",
      "Seen so far: 2944 samples\n",
      "0.9567031\n",
      "Training loss (for one batch) at step 50: 0.0781\n",
      "Seen so far: 3264 samples\n",
      "0.95674264\n",
      "Training loss (for one batch) at step 55: 0.0262\n",
      "Seen so far: 3584 samples\n",
      "0.95677704\n",
      "Training loss (for one batch) at step 60: 0.0021\n",
      "Seen so far: 3904 samples\n",
      "0.95683134\n",
      "Training loss (for one batch) at step 65: 0.0047\n",
      "Seen so far: 4224 samples\n",
      "0.9568805\n",
      "Training loss (for one batch) at step 70: 0.0589\n",
      "Seen so far: 4544 samples\n",
      "0.9569145\n",
      "Training loss (for one batch) at step 75: 0.0085\n",
      "Seen so far: 4864 samples\n",
      "0.9569733\n",
      "Training loss (for one batch) at step 80: 0.0027\n",
      "Seen so far: 5184 samples\n",
      "0.95702696\n",
      "Training loss (for one batch) at step 85: 0.0477\n",
      "Seen so far: 5504 samples\n",
      "0.9570755\n",
      "Training loss (for one batch) at step 90: 0.0689\n",
      "Seen so far: 5824 samples\n",
      "0.9571139\n",
      "Training loss (for one batch) at step 95: 0.0899\n",
      "Seen so far: 6144 samples\n",
      "0.9571423\n",
      "Training loss (for one batch) at step 100: 0.0208\n",
      "Seen so far: 6464 samples\n",
      "0.95718545\n",
      "Training loss (for one batch) at step 105: 0.0230\n",
      "Seen so far: 6784 samples\n",
      "0.95722353\n",
      "Training loss (for one batch) at step 110: 0.0065\n",
      "Seen so far: 7104 samples\n",
      "0.9572516\n",
      "Training loss (for one batch) at step 115: 0.0284\n",
      "Seen so far: 7424 samples\n",
      "0.95728946\n",
      "Training loss (for one batch) at step 120: 0.0875\n",
      "Seen so far: 7744 samples\n",
      "0.9573271\n",
      "Training loss (for one batch) at step 125: 0.0143\n",
      "Seen so far: 8064 samples\n",
      "0.9573795\n",
      "Training loss (for one batch) at step 130: 0.2980\n",
      "Seen so far: 8384 samples\n",
      "0.95741695\n",
      "Training loss (for one batch) at step 135: 0.0183\n",
      "Seen so far: 8704 samples\n",
      "0.957469\n",
      "Training loss (for one batch) at step 140: 0.1980\n",
      "Seen so far: 9024 samples\n",
      "0.9575111\n",
      "Training loss (for one batch) at step 145: 0.2174\n",
      "Seen so far: 9344 samples\n",
      "0.9575628\n",
      "Training loss (for one batch) at step 150: 0.0068\n",
      "Seen so far: 9664 samples\n",
      "0.9576144\n",
      "Training loss (for one batch) at step 155: 0.0091\n",
      "Seen so far: 9984 samples\n",
      "0.9576658\n",
      "Training loss (for one batch) at step 160: 0.0478\n",
      "Seen so far: 10304 samples\n",
      "0.95770735\n",
      "Training loss (for one batch) at step 165: 0.0407\n",
      "Seen so far: 10624 samples\n",
      "0.9577633\n",
      "Training loss (for one batch) at step 170: 0.0178\n",
      "Seen so far: 10944 samples\n",
      "0.9578094\n",
      "Training loss (for one batch) at step 175: 0.0349\n",
      "Seen so far: 11264 samples\n",
      "0.9578602\n",
      "Training loss (for one batch) at step 180: 0.0036\n",
      "Seen so far: 11584 samples\n",
      "0.9579108\n",
      "Training loss (for one batch) at step 185: 0.0095\n",
      "Seen so far: 11904 samples\n",
      "0.95794684\n",
      "Training loss (for one batch) at step 190: 0.0157\n",
      "Seen so far: 12224 samples\n",
      "0.95801157\n",
      "Training loss (for one batch) at step 195: 0.0036\n",
      "Seen so far: 12544 samples\n",
      "0.95805216\n",
      "Training loss (for one batch) at step 200: 0.1088\n",
      "Seen so far: 12864 samples\n",
      "0.9580926\n",
      "Training loss (for one batch) at step 205: 0.0133\n",
      "Seen so far: 13184 samples\n",
      "0.95813286\n",
      "Training loss (for one batch) at step 210: 0.0156\n",
      "Seen so far: 13504 samples\n",
      "0.95818263\n",
      "Training loss (for one batch) at step 215: 0.0432\n",
      "Seen so far: 13824 samples\n",
      "0.9582227\n",
      "Training loss (for one batch) at step 220: 0.0584\n",
      "Seen so far: 14144 samples\n",
      "0.95828164\n",
      "Training loss (for one batch) at step 225: 0.0028\n",
      "Seen so far: 14464 samples\n",
      "0.95830715\n",
      "Training loss (for one batch) at step 230: 0.0086\n",
      "Seen so far: 14784 samples\n",
      "0.95835155\n",
      "Training loss (for one batch) at step 235: 0.0022\n",
      "Seen so far: 15104 samples\n",
      "0.9584006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 240: 0.0036\n",
      "Seen so far: 15424 samples\n",
      "0.95845896\n",
      "Training loss (for one batch) at step 245: 0.0099\n",
      "Seen so far: 15744 samples\n",
      "0.95849824\n",
      "Training loss (for one batch) at step 250: 0.1091\n",
      "Seen so far: 16064 samples\n",
      "0.95853263\n",
      "Training loss (for one batch) at step 255: 0.0505\n",
      "Seen so far: 16384 samples\n",
      "0.9585811\n",
      "Training loss (for one batch) at step 260: 0.0088\n",
      "Seen so far: 16704 samples\n",
      "0.9586247\n",
      "Training loss (for one batch) at step 265: 0.0453\n",
      "Seen so far: 17024 samples\n",
      "0.9586494\n",
      "Training loss (for one batch) at step 270: 0.1728\n",
      "Seen so far: 17344 samples\n",
      "0.95869744\n",
      "Training loss (for one batch) at step 275: 0.0450\n",
      "Seen so far: 17664 samples\n",
      "0.95874536\n",
      "Training loss (for one batch) at step 280: 0.0467\n",
      "Seen so far: 17984 samples\n",
      "0.9587838\n",
      "Training loss (for one batch) at step 285: 0.0222\n",
      "Seen so far: 18304 samples\n",
      "0.95883614\n",
      "Training loss (for one batch) at step 290: 0.0074\n",
      "Seen so far: 18624 samples\n",
      "0.958879\n",
      "Training loss (for one batch) at step 295: 0.0271\n",
      "Seen so far: 18944 samples\n",
      "0.9589263\n",
      "Training loss (for one batch) at step 300: 0.0675\n",
      "Seen so far: 19264 samples\n",
      "0.95896894\n",
      "Training loss (for one batch) at step 305: 0.0169\n",
      "Seen so far: 19584 samples\n",
      "0.9590067\n",
      "Training loss (for one batch) at step 310: 0.0604\n",
      "Seen so far: 19904 samples\n",
      "0.95904905\n",
      "Training loss (for one batch) at step 315: 0.0225\n",
      "Seen so far: 20224 samples\n",
      "0.95909125\n",
      "Training loss (for one batch) at step 320: 0.0042\n",
      "Seen so far: 20544 samples\n",
      "0.95914257\n",
      "Training loss (for one batch) at step 325: 0.0723\n",
      "Seen so far: 20864 samples\n",
      "0.9591845\n",
      "Training loss (for one batch) at step 330: 0.0491\n",
      "Seen so far: 21184 samples\n",
      "0.9592263\n",
      "Training loss (for one batch) at step 335: 0.0748\n",
      "Seen so far: 21504 samples\n",
      "0.9592726\n",
      "Training loss (for one batch) at step 340: 0.0009\n",
      "Seen so far: 21824 samples\n",
      "0.9593188\n",
      "Training loss (for one batch) at step 345: 0.0219\n",
      "Seen so far: 22144 samples\n",
      "0.95935106\n",
      "Training loss (for one batch) at step 350: 0.0076\n",
      "Seen so far: 22464 samples\n",
      "0.95940614\n",
      "Training loss (for one batch) at step 355: 0.0505\n",
      "Seen so far: 22784 samples\n",
      "0.9594473\n",
      "Training loss (for one batch) at step 360: 0.1043\n",
      "Seen so far: 23104 samples\n",
      "0.9594655\n",
      "Training loss (for one batch) at step 365: 0.0193\n",
      "Seen so far: 23424 samples\n",
      "0.95952475\n",
      "Training loss (for one batch) at step 370: 0.0643\n",
      "Seen so far: 23744 samples\n",
      "0.9595656\n",
      "Training loss (for one batch) at step 375: 0.0191\n",
      "Seen so far: 24064 samples\n",
      "0.9596154\n",
      "Training loss (for one batch) at step 380: 0.0076\n",
      "Seen so far: 24384 samples\n",
      "0.9596651\n",
      "Training loss (for one batch) at step 385: 0.0033\n",
      "Seen so far: 24704 samples\n",
      "0.95969194\n",
      "Training loss (for one batch) at step 390: 0.0579\n",
      "Seen so far: 25024 samples\n",
      "0.9597141\n",
      "Training loss (for one batch) at step 395: 0.0394\n",
      "Seen so far: 25344 samples\n",
      "0.9597499\n",
      "Training loss (for one batch) at step 400: 0.0379\n",
      "Seen so far: 25664 samples\n",
      "0.9597855\n",
      "Training loss (for one batch) at step 405: 0.0294\n",
      "Seen so far: 25984 samples\n",
      "0.9598255\n",
      "Training loss (for one batch) at step 410: 0.1507\n",
      "Seen so far: 26304 samples\n",
      "0.95985645\n",
      "Training loss (for one batch) at step 415: 0.0026\n",
      "Seen so far: 26624 samples\n",
      "0.95987374\n",
      "Training loss (for one batch) at step 420: 0.2299\n",
      "Seen so far: 26944 samples\n",
      "0.95988655\n",
      "Training loss (for one batch) at step 425: 0.0053\n",
      "Seen so far: 27264 samples\n",
      "0.9599307\n",
      "Training loss (for one batch) at step 430: 0.1319\n",
      "Seen so far: 27584 samples\n",
      "0.9599389\n",
      "Training loss (for one batch) at step 435: 0.1322\n",
      "Seen so far: 27904 samples\n",
      "0.95997834\n",
      "Training loss (for one batch) at step 440: 0.0273\n",
      "Seen so far: 28224 samples\n",
      "0.9599998\n",
      "Training loss (for one batch) at step 445: 0.0071\n",
      "Seen so far: 28544 samples\n",
      "0.9600168\n",
      "Training loss (for one batch) at step 450: 0.0454\n",
      "Seen so far: 28864 samples\n",
      "0.96005154\n",
      "Training loss (for one batch) at step 455: 0.0727\n",
      "Seen so far: 29184 samples\n",
      "0.96006835\n",
      "Training loss (for one batch) at step 460: 0.0381\n",
      "Seen so far: 29504 samples\n",
      "0.9601074\n",
      "Training loss (for one batch) at step 465: 0.0180\n",
      "Seen so far: 29824 samples\n",
      "0.9601374\n",
      "Training loss (for one batch) at step 470: 0.1307\n",
      "Seen so far: 30144 samples\n",
      "0.96016294\n",
      "Training loss (for one batch) at step 475: 0.0698\n",
      "Seen so far: 30464 samples\n",
      "0.96020603\n",
      "Training loss (for one batch) at step 480: 0.1471\n",
      "Seen so far: 30784 samples\n",
      "0.96022695\n",
      "Training loss (for one batch) at step 485: 0.0044\n",
      "Seen so far: 31104 samples\n",
      "0.96026987\n",
      "Training loss (for one batch) at step 490: 0.0667\n",
      "Seen so far: 31424 samples\n",
      "0.9603083\n",
      "Training loss (for one batch) at step 495: 0.0279\n",
      "Seen so far: 31744 samples\n",
      "0.96033776\n",
      "Training loss (for one batch) at step 500: 0.0122\n",
      "Seen so far: 32064 samples\n",
      "0.9603628\n",
      "Training loss (for one batch) at step 505: 0.0323\n",
      "Seen so far: 32384 samples\n",
      "0.9603965\n",
      "Training loss (for one batch) at step 510: 0.0582\n",
      "Seen so far: 32704 samples\n",
      "0.9603907\n",
      "Training loss (for one batch) at step 515: 0.0013\n",
      "Seen so far: 33024 samples\n",
      "0.96042866\n",
      "Training loss (for one batch) at step 520: 0.0124\n",
      "Seen so far: 33344 samples\n",
      "0.96044904\n",
      "Training loss (for one batch) at step 525: 0.0545\n",
      "Seen so far: 33664 samples\n",
      "0.96047807\n",
      "Training loss (for one batch) at step 530: 0.1029\n",
      "Seen so far: 33984 samples\n",
      "0.9605027\n",
      "Training loss (for one batch) at step 535: 0.0497\n",
      "Seen so far: 34304 samples\n",
      "0.9605403\n",
      "Training loss (for one batch) at step 540: 0.1360\n",
      "Seen so far: 34624 samples\n",
      "0.96055603\n",
      "Training loss (for one batch) at step 545: 0.0036\n",
      "Seen so far: 34944 samples\n",
      "0.96059346\n",
      "Training loss (for one batch) at step 550: 0.0705\n",
      "Seen so far: 35264 samples\n",
      "0.9606264\n",
      "Training loss (for one batch) at step 555: 0.1246\n",
      "Seen so far: 35584 samples\n",
      "0.9606593\n",
      "Training loss (for one batch) at step 560: 0.0093\n",
      "Seen so far: 35904 samples\n",
      "0.9607094\n",
      "Training loss (for one batch) at step 565: 0.0082\n",
      "Seen so far: 36224 samples\n",
      "0.9607464\n",
      "Training loss (for one batch) at step 570: 0.0521\n",
      "Seen so far: 36544 samples\n",
      "0.9607661\n",
      "Training loss (for one batch) at step 575: 0.0233\n",
      "Seen so far: 36864 samples\n",
      "0.96079856\n",
      "Training loss (for one batch) at step 580: 0.1146\n",
      "Seen so far: 37184 samples\n",
      "0.9608138\n",
      "Training loss (for one batch) at step 585: 0.0032\n",
      "Seen so far: 37504 samples\n",
      "0.96082044\n",
      "Training loss (for one batch) at step 590: 0.0849\n",
      "Seen so far: 37824 samples\n",
      "0.96084416\n",
      "Training loss (for one batch) at step 595: 0.0269\n",
      "Seen so far: 38144 samples\n",
      "0.96086353\n",
      "Training loss (for one batch) at step 600: 0.0078\n",
      "Seen so far: 38464 samples\n",
      "0.96089995\n",
      "Training loss (for one batch) at step 605: 0.0217\n",
      "Seen so far: 38784 samples\n",
      "0.9609192\n",
      "Training loss (for one batch) at step 610: 0.0699\n",
      "Seen so far: 39104 samples\n",
      "0.96092993\n",
      "Training loss (for one batch) at step 615: 0.0901\n",
      "Seen so far: 39424 samples\n",
      "0.96095335\n",
      "Training loss (for one batch) at step 620: 0.0700\n",
      "Seen so far: 39744 samples\n",
      "0.9609512\n",
      "Training loss (for one batch) at step 625: 0.0646\n",
      "Seen so far: 40064 samples\n",
      "0.9609915\n",
      "Training loss (for one batch) at step 630: 0.1438\n",
      "Seen so far: 40384 samples\n",
      "0.96102744\n",
      "Training loss (for one batch) at step 635: 0.0956\n",
      "Seen so far: 40704 samples\n",
      "0.96104217\n",
      "Training loss (for one batch) at step 640: 0.1136\n",
      "Seen so far: 41024 samples\n",
      "0.9610737\n",
      "Training loss (for one batch) at step 645: 0.1423\n",
      "Seen so far: 41344 samples\n",
      "0.9610883\n",
      "Training loss (for one batch) at step 650: 0.0343\n",
      "Seen so far: 41664 samples\n",
      "0.9610818\n",
      "Training loss (for one batch) at step 655: 0.0486\n",
      "Seen so far: 41984 samples\n",
      "0.9611005\n",
      "Training loss (for one batch) at step 660: 0.0044\n",
      "Seen so far: 42304 samples\n",
      "0.96112764\n",
      "Training loss (for one batch) at step 665: 0.1662\n",
      "Seen so far: 42624 samples\n",
      "0.9611463\n",
      "Training loss (for one batch) at step 670: 0.0298\n",
      "Seen so far: 42944 samples\n",
      "0.9611733\n",
      "Training loss (for one batch) at step 675: 0.0055\n",
      "Seen so far: 43264 samples\n",
      "0.9612169\n",
      "Training loss (for one batch) at step 680: 0.0840\n",
      "Seen so far: 43584 samples\n",
      "0.9612521\n",
      "Training loss (for one batch) at step 685: 0.0206\n",
      "Seen so far: 43904 samples\n",
      "0.9612914\n",
      "Training loss (for one batch) at step 690: 0.0273\n",
      "Seen so far: 44224 samples\n",
      "0.961318\n",
      "Training loss (for one batch) at step 695: 0.0467\n",
      "Seen so far: 44544 samples\n",
      "0.9613404\n",
      "Training loss (for one batch) at step 700: 0.0083\n",
      "Seen so far: 44864 samples\n",
      "0.96138775\n",
      "Training loss (for one batch) at step 705: 0.0285\n",
      "Seen so far: 45184 samples\n",
      "0.9614266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 710: 0.1714\n",
      "Seen so far: 45504 samples\n",
      "0.9614446\n",
      "Training loss (for one batch) at step 715: 0.0138\n",
      "Seen so far: 45824 samples\n",
      "0.9614792\n",
      "Training loss (for one batch) at step 720: 0.0392\n",
      "Seen so far: 46144 samples\n",
      "0.96150124\n",
      "Training loss (for one batch) at step 725: 0.0217\n",
      "Seen so far: 46464 samples\n",
      "0.96153975\n",
      "Training loss (for one batch) at step 730: 0.0034\n",
      "Seen so far: 46784 samples\n",
      "0.9615658\n",
      "Training loss (for one batch) at step 735: 0.0271\n",
      "Seen so far: 47104 samples\n",
      "0.9616041\n",
      "Training loss (for one batch) at step 740: 0.0152\n",
      "Seen so far: 47424 samples\n",
      "0.96161354\n",
      "Training loss (for one batch) at step 745: 0.0468\n",
      "Seen so far: 47744 samples\n",
      "0.96163934\n",
      "Training loss (for one batch) at step 750: 0.1859\n",
      "Seen so far: 48064 samples\n",
      "0.9616733\n",
      "Training loss (for one batch) at step 755: 0.0574\n",
      "Seen so far: 48384 samples\n",
      "0.9616908\n",
      "Training loss (for one batch) at step 760: 0.0043\n",
      "Seen so far: 48704 samples\n",
      "0.96172464\n",
      "Training acc over epoch: 0.9617\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.0904\n",
      "Seen so far: 64 samples\n",
      "0.961741\n",
      "Training loss (for one batch) at step 5: 0.0091\n",
      "Seen so far: 384 samples\n",
      "0.9617787\n",
      "Training loss (for one batch) at step 10: 0.2040\n",
      "Seen so far: 704 samples\n",
      "0.9618123\n",
      "Training loss (for one batch) at step 15: 0.0875\n",
      "Seen so far: 1024 samples\n",
      "0.96184176\n",
      "Training loss (for one batch) at step 20: 0.0160\n",
      "Seen so far: 1344 samples\n",
      "0.9618792\n",
      "Training loss (for one batch) at step 25: 0.0100\n",
      "Seen so far: 1664 samples\n",
      "0.96188\n",
      "Training loss (for one batch) at step 30: 0.0107\n",
      "Seen so far: 1984 samples\n",
      "0.96191734\n",
      "Training loss (for one batch) at step 35: 0.1836\n",
      "Seen so far: 2304 samples\n",
      "0.9619343\n",
      "Training loss (for one batch) at step 40: 0.2538\n",
      "Seen so far: 2624 samples\n",
      "0.9619391\n",
      "Training loss (for one batch) at step 45: 0.0025\n",
      "Seen so far: 2944 samples\n",
      "0.9619601\n",
      "Training loss (for one batch) at step 50: 0.1231\n",
      "Seen so far: 3264 samples\n",
      "0.96196884\n",
      "Training loss (for one batch) at step 55: 0.0973\n",
      "Seen so far: 3584 samples\n",
      "0.9619655\n",
      "Training loss (for one batch) at step 60: 0.0719\n",
      "Seen so far: 3904 samples\n",
      "0.96199036\n",
      "Training loss (for one batch) at step 65: 0.0898\n",
      "Seen so far: 4224 samples\n",
      "0.961995\n",
      "Training loss (for one batch) at step 70: 0.0386\n",
      "Seen so far: 4544 samples\n",
      "0.9620278\n",
      "Training loss (for one batch) at step 75: 0.2559\n",
      "Seen so far: 4864 samples\n",
      "0.96203643\n",
      "Training loss (for one batch) at step 80: 0.1934\n",
      "Seen so far: 5184 samples\n",
      "0.962037\n",
      "Training loss (for one batch) at step 85: 0.0558\n",
      "Seen so far: 5504 samples\n",
      "0.96206564\n",
      "Training loss (for one batch) at step 90: 0.3378\n",
      "Seen so far: 5824 samples\n",
      "0.9620582\n",
      "Training loss (for one batch) at step 95: 0.0830\n",
      "Seen so far: 6144 samples\n",
      "0.96207076\n",
      "Training loss (for one batch) at step 100: 0.0844\n",
      "Seen so far: 6464 samples\n",
      "0.9620673\n",
      "Training loss (for one batch) at step 105: 0.0085\n",
      "Seen so far: 6784 samples\n",
      "0.96208775\n",
      "Training loss (for one batch) at step 110: 0.1259\n",
      "Seen so far: 7104 samples\n",
      "0.9621082\n",
      "Training loss (for one batch) at step 115: 0.4785\n",
      "Seen so far: 7424 samples\n",
      "0.96213645\n",
      "Training loss (for one batch) at step 120: 0.0357\n",
      "Seen so far: 7744 samples\n",
      "0.9621568\n",
      "Training loss (for one batch) at step 125: 0.0513\n",
      "Seen so far: 8064 samples\n",
      "0.9621612\n",
      "Training loss (for one batch) at step 130: 0.1861\n",
      "Seen so far: 8384 samples\n",
      "0.9621814\n",
      "Training loss (for one batch) at step 135: 0.0270\n",
      "Seen so far: 8704 samples\n",
      "0.96220547\n",
      "Training loss (for one batch) at step 140: 0.0371\n",
      "Seen so far: 9024 samples\n",
      "0.9622216\n",
      "Training loss (for one batch) at step 145: 0.0909\n",
      "Seen so far: 9344 samples\n",
      "0.9622338\n",
      "Training loss (for one batch) at step 150: 0.0114\n",
      "Seen so far: 9664 samples\n",
      "0.9622538\n",
      "Training loss (for one batch) at step 155: 0.0938\n",
      "Seen so far: 9984 samples\n",
      "0.9622777\n",
      "Training loss (for one batch) at step 160: 0.0320\n",
      "Seen so far: 10304 samples\n",
      "0.96231335\n",
      "Training loss (for one batch) at step 165: 0.1524\n",
      "Seen so far: 10624 samples\n",
      "0.96233714\n",
      "Training loss (for one batch) at step 170: 0.0179\n",
      "Seen so far: 10944 samples\n",
      "0.9623608\n",
      "Training loss (for one batch) at step 175: 0.0937\n",
      "Seen so far: 11264 samples\n",
      "0.96238446\n",
      "Training loss (for one batch) at step 180: 0.0528\n",
      "Seen so far: 11584 samples\n",
      "0.9623963\n",
      "Training loss (for one batch) at step 185: 0.0234\n",
      "Seen so far: 11904 samples\n",
      "0.96240425\n",
      "Training loss (for one batch) at step 190: 0.0635\n",
      "Seen so far: 12224 samples\n",
      "0.96240824\n",
      "Training loss (for one batch) at step 195: 0.1952\n",
      "Seen so far: 12544 samples\n",
      "0.96238893\n",
      "Training loss (for one batch) at step 200: 0.1898\n",
      "Seen so far: 12864 samples\n",
      "0.9623929\n",
      "Training loss (for one batch) at step 205: 0.1506\n",
      "Seen so far: 13184 samples\n",
      "0.9623931\n",
      "Training loss (for one batch) at step 210: 0.0545\n",
      "Seen so far: 13504 samples\n",
      "0.962401\n",
      "Training loss (for one batch) at step 215: 0.2674\n",
      "Seen so far: 13824 samples\n",
      "0.96239334\n",
      "Training loss (for one batch) at step 220: 0.2206\n",
      "Seen so far: 14144 samples\n",
      "0.9623703\n",
      "Training loss (for one batch) at step 225: 0.0228\n",
      "Seen so far: 14464 samples\n",
      "0.96237427\n",
      "Training loss (for one batch) at step 230: 0.1964\n",
      "Seen so far: 14784 samples\n",
      "0.96235514\n",
      "Training loss (for one batch) at step 235: 0.1781\n",
      "Seen so far: 15104 samples\n",
      "0.96233994\n",
      "Training loss (for one batch) at step 240: 0.1888\n",
      "Seen so far: 15424 samples\n",
      "0.96232474\n",
      "Training loss (for one batch) at step 245: 0.2465\n",
      "Seen so far: 15744 samples\n",
      "0.9623172\n",
      "Training loss (for one batch) at step 250: 0.0884\n",
      "Seen so far: 16064 samples\n",
      "0.96231747\n",
      "Training loss (for one batch) at step 255: 0.1774\n",
      "Seen so far: 16384 samples\n",
      "0.9623139\n",
      "Training loss (for one batch) at step 260: 0.1033\n",
      "Seen so far: 16704 samples\n",
      "0.96231407\n",
      "Training loss (for one batch) at step 265: 0.1224\n",
      "Seen so far: 17024 samples\n",
      "0.9623181\n",
      "Training loss (for one batch) at step 270: 0.0869\n",
      "Seen so far: 17344 samples\n",
      "0.9623222\n",
      "Training loss (for one batch) at step 275: 0.0393\n",
      "Seen so far: 17664 samples\n",
      "0.9623377\n",
      "Training loss (for one batch) at step 280: 0.1079\n",
      "Seen so far: 17984 samples\n",
      "0.96236074\n",
      "Training loss (for one batch) at step 285: 0.1512\n",
      "Seen so far: 18304 samples\n",
      "0.9623723\n",
      "Training loss (for one batch) at step 290: 0.0613\n",
      "Seen so far: 18624 samples\n",
      "0.9623915\n",
      "Training loss (for one batch) at step 295: 0.0173\n",
      "Seen so far: 18944 samples\n",
      "0.9624182\n",
      "Training loss (for one batch) at step 300: 0.0209\n",
      "Seen so far: 19264 samples\n",
      "0.9624259\n",
      "Training loss (for one batch) at step 305: 0.0245\n",
      "Seen so far: 19584 samples\n",
      "0.9624449\n",
      "Training loss (for one batch) at step 310: 0.0430\n",
      "Seen so far: 19904 samples\n",
      "0.9624639\n",
      "Training loss (for one batch) at step 315: 0.0256\n",
      "Seen so far: 20224 samples\n",
      "0.9624753\n",
      "Training loss (for one batch) at step 320: 0.0040\n",
      "Seen so far: 20544 samples\n",
      "0.96249795\n",
      "Training loss (for one batch) at step 325: 0.0765\n",
      "Seen so far: 20864 samples\n",
      "0.96251684\n",
      "Training loss (for one batch) at step 330: 0.1029\n",
      "Seen so far: 21184 samples\n",
      "0.96253186\n",
      "Training loss (for one batch) at step 335: 0.0820\n",
      "Seen so far: 21504 samples\n",
      "0.9625619\n",
      "Training loss (for one batch) at step 340: 0.1847\n",
      "Seen so far: 21824 samples\n",
      "0.9625806\n",
      "Training loss (for one batch) at step 345: 0.0201\n",
      "Seen so far: 22144 samples\n",
      "0.96261054\n",
      "Training loss (for one batch) at step 350: 0.0913\n",
      "Seen so far: 22464 samples\n",
      "0.96262914\n",
      "Training loss (for one batch) at step 355: 0.0375\n",
      "Seen so far: 22784 samples\n",
      "0.96265894\n",
      "Training loss (for one batch) at step 360: 0.0408\n",
      "Seen so far: 23104 samples\n",
      "0.9626887\n",
      "Training loss (for one batch) at step 365: 0.0404\n",
      "Seen so far: 23424 samples\n",
      "0.96272206\n",
      "Training loss (for one batch) at step 370: 0.0617\n",
      "Seen so far: 23744 samples\n",
      "0.9627442\n",
      "Training loss (for one batch) at step 375: 0.0472\n",
      "Seen so far: 24064 samples\n",
      "0.96278113\n",
      "Training loss (for one batch) at step 380: 0.0747\n",
      "Seen so far: 24384 samples\n",
      "0.9628106\n",
      "Training loss (for one batch) at step 385: 0.1085\n",
      "Seen so far: 24704 samples\n",
      "0.96282506\n",
      "Training loss (for one batch) at step 390: 0.0251\n",
      "Seen so far: 25024 samples\n",
      "0.9628581\n",
      "Training loss (for one batch) at step 395: 0.0147\n",
      "Seen so far: 25344 samples\n",
      "0.9628836\n",
      "Training loss (for one batch) at step 400: 0.0533\n",
      "Seen so far: 25664 samples\n",
      "0.96290904\n",
      "Training loss (for one batch) at step 405: 0.0421\n",
      "Seen so far: 25984 samples\n",
      "0.9629382\n",
      "Training loss (for one batch) at step 410: 0.0426\n",
      "Seen so far: 26304 samples\n",
      "0.9629598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 415: 0.0553\n",
      "Seen so far: 26624 samples\n",
      "0.9629777\n",
      "Training loss (for one batch) at step 420: 0.0006\n",
      "Seen so far: 26944 samples\n",
      "0.963003\n",
      "Training loss (for one batch) at step 425: 0.1195\n",
      "Seen so far: 27264 samples\n",
      "0.9630171\n",
      "Training loss (for one batch) at step 430: 0.1199\n",
      "Seen so far: 27584 samples\n",
      "0.9630459\n",
      "Training loss (for one batch) at step 435: 0.1418\n",
      "Seen so far: 27904 samples\n",
      "0.9630636\n",
      "Training loss (for one batch) at step 440: 0.2072\n",
      "Seen so far: 28224 samples\n",
      "0.9630813\n",
      "Training loss (for one batch) at step 445: 0.0094\n",
      "Seen so far: 28544 samples\n",
      "0.9631099\n",
      "Training loss (for one batch) at step 450: 0.0205\n",
      "Seen so far: 28864 samples\n",
      "0.9631312\n",
      "Training loss (for one batch) at step 455: 0.0509\n",
      "Seen so far: 29184 samples\n",
      "0.9631597\n",
      "Training loss (for one batch) at step 460: 0.0513\n",
      "Seen so far: 29504 samples\n",
      "0.96317714\n",
      "Training loss (for one batch) at step 465: 0.0835\n",
      "Seen so far: 29824 samples\n",
      "0.9631946\n",
      "Training loss (for one batch) at step 470: 0.0840\n",
      "Seen so far: 30144 samples\n",
      "0.9632084\n",
      "Training loss (for one batch) at step 475: 0.0081\n",
      "Seen so far: 30464 samples\n",
      "0.96323663\n",
      "Training loss (for one batch) at step 480: 0.0409\n",
      "Seen so far: 30784 samples\n",
      "0.9632576\n",
      "Training loss (for one batch) at step 485: 0.0033\n",
      "Seen so far: 31104 samples\n",
      "0.96328574\n",
      "Training loss (for one batch) at step 490: 0.0724\n",
      "Seen so far: 31424 samples\n",
      "0.9633139\n",
      "Training loss (for one batch) at step 495: 0.0461\n",
      "Seen so far: 31744 samples\n",
      "0.9633346\n",
      "Training loss (for one batch) at step 500: 0.0890\n",
      "Seen so far: 32064 samples\n",
      "0.96335536\n",
      "Training loss (for one batch) at step 505: 0.0646\n",
      "Seen so far: 32384 samples\n",
      "0.9633761\n",
      "Training loss (for one batch) at step 510: 0.0095\n",
      "Seen so far: 32704 samples\n",
      "0.9634076\n",
      "Training loss (for one batch) at step 515: 0.0918\n",
      "Seen so far: 33024 samples\n",
      "0.96343535\n",
      "Training loss (for one batch) at step 520: 0.0066\n",
      "Seen so far: 33344 samples\n",
      "0.96344864\n",
      "Training loss (for one batch) at step 525: 0.0202\n",
      "Seen so far: 33664 samples\n",
      "0.96346915\n",
      "Training loss (for one batch) at step 530: 0.0029\n",
      "Seen so far: 33984 samples\n",
      "0.9634968\n",
      "Training loss (for one batch) at step 535: 0.0291\n",
      "Seen so far: 34304 samples\n",
      "0.96352077\n",
      "Training loss (for one batch) at step 540: 0.0164\n",
      "Seen so far: 34624 samples\n",
      "0.96354467\n",
      "Training loss (for one batch) at step 545: 0.0723\n",
      "Seen so far: 34944 samples\n",
      "0.9635829\n",
      "Training loss (for one batch) at step 550: 0.0028\n",
      "Seen so far: 35264 samples\n",
      "0.9636174\n",
      "Training loss (for one batch) at step 555: 0.0959\n",
      "Seen so far: 35584 samples\n",
      "0.9636411\n",
      "Training loss (for one batch) at step 560: 0.0023\n",
      "Seen so far: 35904 samples\n",
      "0.9636719\n",
      "Training loss (for one batch) at step 565: 0.0022\n",
      "Seen so far: 36224 samples\n",
      "0.9637098\n",
      "Training loss (for one batch) at step 570: 0.0526\n",
      "Seen so far: 36544 samples\n",
      "0.9637404\n",
      "Training loss (for one batch) at step 575: 0.1196\n",
      "Seen so far: 36864 samples\n",
      "0.96376747\n",
      "Training loss (for one batch) at step 580: 0.0300\n",
      "Seen so far: 37184 samples\n",
      "0.963798\n",
      "Training loss (for one batch) at step 585: 0.0116\n",
      "Seen so far: 37504 samples\n",
      "0.96382844\n",
      "Training loss (for one batch) at step 590: 0.0078\n",
      "Seen so far: 37824 samples\n",
      "0.96386594\n",
      "Training loss (for one batch) at step 595: 0.2173\n",
      "Seen so far: 38144 samples\n",
      "0.9638821\n",
      "Training loss (for one batch) at step 600: 0.0098\n",
      "Seen so far: 38464 samples\n",
      "0.9639159\n",
      "Training loss (for one batch) at step 605: 0.0090\n",
      "Seen so far: 38784 samples\n",
      "0.96395665\n",
      "Training loss (for one batch) at step 610: 0.1090\n",
      "Seen so far: 39104 samples\n",
      "0.9639691\n",
      "Training loss (for one batch) at step 615: 0.0191\n",
      "Seen so far: 39424 samples\n",
      "0.9639851\n",
      "Training loss (for one batch) at step 620: 0.0024\n",
      "Seen so far: 39744 samples\n",
      "0.96401507\n",
      "Training loss (for one batch) at step 625: 0.0048\n",
      "Seen so far: 40064 samples\n",
      "0.964045\n",
      "Training loss (for one batch) at step 630: 0.0249\n",
      "Seen so far: 40384 samples\n",
      "0.9640819\n",
      "Training loss (for one batch) at step 635: 0.0760\n",
      "Seen so far: 40704 samples\n",
      "0.9640977\n",
      "Training loss (for one batch) at step 640: 0.0035\n",
      "Seen so far: 41024 samples\n",
      "0.9641274\n",
      "Training loss (for one batch) at step 645: 0.0087\n",
      "Seen so far: 41344 samples\n",
      "0.9641536\n",
      "Training loss (for one batch) at step 650: 0.0975\n",
      "Seen so far: 41664 samples\n",
      "0.9641727\n",
      "Training loss (for one batch) at step 655: 0.0088\n",
      "Seen so far: 41984 samples\n",
      "0.9642023\n",
      "Training loss (for one batch) at step 660: 0.0825\n",
      "Seen so far: 42304 samples\n",
      "0.96421784\n",
      "Training loss (for one batch) at step 665: 0.0045\n",
      "Seen so far: 42624 samples\n",
      "0.9642403\n",
      "Training loss (for one batch) at step 670: 0.0228\n",
      "Seen so far: 42944 samples\n",
      "0.96425927\n",
      "Training loss (for one batch) at step 675: 0.0021\n",
      "Seen so far: 43264 samples\n",
      "0.96429205\n",
      "Training loss (for one batch) at step 680: 0.0718\n",
      "Seen so far: 43584 samples\n",
      "0.9643213\n",
      "Training loss (for one batch) at step 685: 0.0019\n",
      "Seen so far: 43904 samples\n",
      "0.964354\n",
      "Training loss (for one batch) at step 690: 0.0028\n",
      "Seen so far: 44224 samples\n",
      "0.9643831\n",
      "Training loss (for one batch) at step 695: 0.1481\n",
      "Seen so far: 44544 samples\n",
      "0.96440524\n",
      "Training loss (for one batch) at step 700: 0.0189\n",
      "Seen so far: 44864 samples\n",
      "0.96444464\n",
      "Training loss (for one batch) at step 705: 0.0034\n",
      "Seen so far: 45184 samples\n",
      "0.96447355\n",
      "Training loss (for one batch) at step 710: 0.0029\n",
      "Seen so far: 45504 samples\n",
      "0.9645093\n",
      "Training loss (for one batch) at step 715: 0.0278\n",
      "Seen so far: 45824 samples\n",
      "0.96453124\n",
      "Training loss (for one batch) at step 720: 0.0078\n",
      "Seen so far: 46144 samples\n",
      "0.9645703\n",
      "Training loss (for one batch) at step 725: 0.0009\n",
      "Seen so far: 46464 samples\n",
      "0.9645921\n",
      "Training loss (for one batch) at step 730: 0.1314\n",
      "Seen so far: 46784 samples\n",
      "0.9646104\n",
      "Training loss (for one batch) at step 735: 0.0015\n",
      "Seen so far: 47104 samples\n",
      "0.96463555\n",
      "Training loss (for one batch) at step 740: 0.0119\n",
      "Seen so far: 47424 samples\n",
      "0.9646709\n",
      "Training loss (for one batch) at step 745: 0.0032\n",
      "Seen so far: 47744 samples\n",
      "0.9647027\n",
      "Training loss (for one batch) at step 750: 0.0118\n",
      "Seen so far: 48064 samples\n",
      "0.96473455\n",
      "Training loss (for one batch) at step 755: 0.0871\n",
      "Seen so far: 48384 samples\n",
      "0.9647628\n",
      "Training loss (for one batch) at step 760: 0.0182\n",
      "Seen so far: 48704 samples\n",
      "0.9647979\n",
      "Training acc over epoch: 0.9648\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.0011\n",
      "Seen so far: 64 samples\n",
      "0.96481246\n",
      "Training loss (for one batch) at step 5: 0.1413\n",
      "Seen so far: 384 samples\n",
      "0.96483034\n",
      "Training loss (for one batch) at step 10: 0.0242\n",
      "Seen so far: 704 samples\n",
      "0.96486187\n",
      "Training loss (for one batch) at step 15: 0.0651\n",
      "Seen so far: 1024 samples\n",
      "0.9648899\n",
      "Training loss (for one batch) at step 20: 0.0073\n",
      "Seen so far: 1344 samples\n",
      "0.96491784\n",
      "Training loss (for one batch) at step 25: 0.0065\n",
      "Seen so far: 1664 samples\n",
      "0.96493554\n",
      "Training loss (for one batch) at step 30: 0.0317\n",
      "Seen so far: 1984 samples\n",
      "0.96493965\n",
      "Training loss (for one batch) at step 35: 0.1882\n",
      "Seen so far: 2304 samples\n",
      "0.9649607\n",
      "Training loss (for one batch) at step 40: 0.0223\n",
      "Seen so far: 2624 samples\n",
      "0.9649851\n",
      "Training loss (for one batch) at step 45: 0.0008\n",
      "Seen so far: 2944 samples\n",
      "0.9650229\n",
      "Training loss (for one batch) at step 50: 0.0783\n",
      "Seen so far: 3264 samples\n",
      "0.9650472\n",
      "Training loss (for one batch) at step 55: 0.0039\n",
      "Seen so far: 3584 samples\n",
      "0.96506804\n",
      "Training loss (for one batch) at step 60: 0.0549\n",
      "Seen so far: 3904 samples\n",
      "0.9650787\n",
      "Training loss (for one batch) at step 65: 0.0258\n",
      "Seen so far: 4224 samples\n",
      "0.96510285\n",
      "Training loss (for one batch) at step 70: 0.0023\n",
      "Seen so far: 4544 samples\n",
      "0.9651336\n",
      "Training loss (for one batch) at step 75: 0.0322\n",
      "Seen so far: 4864 samples\n",
      "0.96516097\n",
      "Training loss (for one batch) at step 80: 0.0521\n",
      "Seen so far: 5184 samples\n",
      "0.96519166\n",
      "Training loss (for one batch) at step 85: 0.0032\n",
      "Seen so far: 5504 samples\n",
      "0.9652256\n",
      "Training loss (for one batch) at step 90: 0.0021\n",
      "Seen so far: 5824 samples\n",
      "0.9652628\n",
      "Training loss (for one batch) at step 95: 0.0099\n",
      "Seen so far: 6144 samples\n",
      "0.96529657\n",
      "Training loss (for one batch) at step 100: 0.0082\n",
      "Seen so far: 6464 samples\n",
      "0.96531695\n",
      "Training loss (for one batch) at step 105: 0.0001\n",
      "Seen so far: 6784 samples\n",
      "0.9653406\n",
      "Training loss (for one batch) at step 110: 0.0128\n",
      "Seen so far: 7104 samples\n",
      "0.9653742\n",
      "Training loss (for one batch) at step 115: 0.0348\n",
      "Seen so far: 7424 samples\n",
      "0.96540105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 120: 0.1325\n",
      "Seen so far: 7744 samples\n",
      "0.96543455\n",
      "Training loss (for one batch) at step 125: 0.0176\n",
      "Seen so far: 8064 samples\n",
      "0.96546793\n",
      "Training loss (for one batch) at step 130: 0.0342\n",
      "Seen so far: 8384 samples\n",
      "0.96550125\n",
      "Training loss (for one batch) at step 135: 0.0304\n",
      "Seen so far: 8704 samples\n",
      "0.96552783\n",
      "Training loss (for one batch) at step 140: 0.0005\n",
      "Seen so far: 9024 samples\n",
      "0.9655544\n",
      "Training loss (for one batch) at step 145: 0.0282\n",
      "Seen so far: 9344 samples\n",
      "0.9655842\n",
      "Training loss (for one batch) at step 150: 0.1669\n",
      "Seen so far: 9664 samples\n",
      "0.9655942\n",
      "Training loss (for one batch) at step 155: 0.0486\n",
      "Seen so far: 9984 samples\n",
      "0.9656239\n",
      "Training loss (for one batch) at step 160: 0.0258\n",
      "Seen so far: 10304 samples\n",
      "0.96565354\n",
      "Training loss (for one batch) at step 165: 0.0072\n",
      "Seen so far: 10624 samples\n",
      "0.96568644\n",
      "Training loss (for one batch) at step 170: 0.0049\n",
      "Seen so far: 10944 samples\n",
      "0.96571267\n",
      "Training loss (for one batch) at step 175: 0.0275\n",
      "Seen so far: 11264 samples\n",
      "0.9657454\n",
      "Training loss (for one batch) at step 180: 0.0721\n",
      "Seen so far: 11584 samples\n",
      "0.965765\n",
      "Training loss (for one batch) at step 185: 0.0039\n",
      "Seen so far: 11904 samples\n",
      "0.9657976\n",
      "Training loss (for one batch) at step 190: 0.0055\n",
      "Seen so far: 12224 samples\n",
      "0.9658334\n",
      "Training loss (for one batch) at step 195: 0.0120\n",
      "Seen so far: 12544 samples\n",
      "0.96585935\n",
      "Training loss (for one batch) at step 200: 0.0430\n",
      "Seen so far: 12864 samples\n",
      "0.9658853\n",
      "Training loss (for one batch) at step 205: 0.0032\n",
      "Seen so far: 13184 samples\n",
      "0.96592087\n",
      "Training loss (for one batch) at step 210: 0.0007\n",
      "Seen so far: 13504 samples\n",
      "0.9659467\n",
      "Training loss (for one batch) at step 215: 0.0656\n",
      "Seen so far: 13824 samples\n",
      "0.96597236\n",
      "Training loss (for one batch) at step 220: 0.0002\n",
      "Seen so far: 14144 samples\n",
      "0.9660013\n",
      "Training loss (for one batch) at step 225: 0.0012\n",
      "Seen so far: 14464 samples\n",
      "0.9660269\n",
      "Training loss (for one batch) at step 230: 0.0355\n",
      "Seen so far: 14784 samples\n",
      "0.9660525\n",
      "Training loss (for one batch) at step 235: 0.0403\n",
      "Seen so far: 15104 samples\n",
      "0.9660779\n",
      "Training loss (for one batch) at step 240: 0.0356\n",
      "Seen so far: 15424 samples\n",
      "0.96610665\n",
      "Training loss (for one batch) at step 245: 0.0018\n",
      "Seen so far: 15744 samples\n",
      "0.9661385\n",
      "Training loss (for one batch) at step 250: 0.0078\n",
      "Seen so far: 16064 samples\n",
      "0.9661671\n",
      "Training loss (for one batch) at step 255: 0.0023\n",
      "Seen so far: 16384 samples\n",
      "0.9661988\n",
      "Training loss (for one batch) at step 260: 0.0319\n",
      "Seen so far: 16704 samples\n",
      "0.96621436\n",
      "Training loss (for one batch) at step 265: 0.0014\n",
      "Seen so far: 17024 samples\n",
      "0.9662331\n",
      "Training loss (for one batch) at step 270: 0.0171\n",
      "Seen so far: 17344 samples\n",
      "0.9662582\n",
      "Training loss (for one batch) at step 275: 0.0014\n",
      "Seen so far: 17664 samples\n",
      "0.9662897\n",
      "Training loss (for one batch) at step 280: 0.0045\n",
      "Seen so far: 17984 samples\n",
      "0.9663083\n",
      "Training loss (for one batch) at step 285: 0.0049\n",
      "Seen so far: 18304 samples\n",
      "0.96633005\n",
      "Training loss (for one batch) at step 290: 0.0542\n",
      "Seen so far: 18624 samples\n",
      "0.9663582\n",
      "Training loss (for one batch) at step 295: 0.0007\n",
      "Seen so far: 18944 samples\n",
      "0.9663927\n",
      "Training loss (for one batch) at step 300: 0.0271\n",
      "Seen so far: 19264 samples\n",
      "0.96641433\n",
      "Training loss (for one batch) at step 305: 0.0019\n",
      "Seen so far: 19584 samples\n",
      "0.9664423\n",
      "Training loss (for one batch) at step 310: 0.0104\n",
      "Seen so far: 19904 samples\n",
      "0.96647656\n",
      "Training loss (for one batch) at step 315: 0.0073\n",
      "Seen so far: 20224 samples\n",
      "0.9665076\n",
      "Training loss (for one batch) at step 320: 0.0006\n",
      "Seen so far: 20544 samples\n",
      "0.96653855\n",
      "Training loss (for one batch) at step 325: 0.0010\n",
      "Seen so far: 20864 samples\n",
      "0.9665567\n",
      "Training loss (for one batch) at step 330: 0.0345\n",
      "Seen so far: 21184 samples\n",
      "0.9665812\n",
      "Training loss (for one batch) at step 335: 0.2736\n",
      "Seen so far: 21504 samples\n",
      "0.9665993\n",
      "Training loss (for one batch) at step 340: 0.0394\n",
      "Seen so far: 21824 samples\n",
      "0.96663004\n",
      "Training loss (for one batch) at step 345: 0.1001\n",
      "Seen so far: 22144 samples\n",
      "0.96665126\n",
      "Training loss (for one batch) at step 350: 0.0805\n",
      "Seen so far: 22464 samples\n",
      "0.96666604\n",
      "Training loss (for one batch) at step 355: 0.0027\n",
      "Seen so far: 22784 samples\n",
      "0.96669346\n",
      "Training loss (for one batch) at step 360: 0.0003\n",
      "Seen so far: 23104 samples\n",
      "0.9667145\n",
      "Training loss (for one batch) at step 365: 0.0056\n",
      "Seen so far: 23424 samples\n",
      "0.9667418\n",
      "Training loss (for one batch) at step 370: 0.0619\n",
      "Seen so far: 23744 samples\n",
      "0.96676594\n",
      "Training loss (for one batch) at step 375: 0.0066\n",
      "Seen so far: 24064 samples\n",
      "0.9667931\n",
      "Training loss (for one batch) at step 380: 0.0056\n",
      "Seen so far: 24384 samples\n",
      "0.966814\n",
      "Training loss (for one batch) at step 385: 0.1493\n",
      "Seen so far: 24704 samples\n",
      "0.9668191\n",
      "Training loss (for one batch) at step 390: 0.0045\n",
      "Seen so far: 25024 samples\n",
      "0.96684617\n",
      "Training loss (for one batch) at step 395: 0.0014\n",
      "Seen so far: 25344 samples\n",
      "0.9668763\n",
      "Training loss (for one batch) at step 400: 0.0033\n",
      "Seen so far: 25664 samples\n",
      "0.966897\n",
      "Training loss (for one batch) at step 405: 0.0315\n",
      "Seen so far: 25984 samples\n",
      "0.96691453\n",
      "Training loss (for one batch) at step 410: 0.0352\n",
      "Seen so far: 26304 samples\n",
      "0.9669414\n",
      "Training loss (for one batch) at step 415: 0.0394\n",
      "Seen so far: 26624 samples\n",
      "0.9669589\n",
      "Training loss (for one batch) at step 420: 0.0215\n",
      "Seen so far: 26944 samples\n",
      "0.96698564\n",
      "Training loss (for one batch) at step 425: 0.0043\n",
      "Seen so far: 27264 samples\n",
      "0.96700615\n",
      "Training loss (for one batch) at step 430: 0.0478\n",
      "Seen so far: 27584 samples\n",
      "0.9670266\n",
      "Training loss (for one batch) at step 435: 0.0362\n",
      "Seen so far: 27904 samples\n",
      "0.9670439\n",
      "Training loss (for one batch) at step 440: 0.0003\n",
      "Seen so far: 28224 samples\n",
      "0.96707356\n",
      "Training loss (for one batch) at step 445: 0.3294\n",
      "Seen so far: 28544 samples\n",
      "0.9670938\n",
      "Training loss (for one batch) at step 450: 0.0172\n",
      "Seen so far: 28864 samples\n",
      "0.96711725\n",
      "Training loss (for one batch) at step 455: 0.0092\n",
      "Seen so far: 29184 samples\n",
      "0.96712816\n",
      "Training loss (for one batch) at step 460: 0.0195\n",
      "Seen so far: 29504 samples\n",
      "0.96714836\n",
      "Training loss (for one batch) at step 465: 0.0531\n",
      "Seen so far: 29824 samples\n",
      "0.9671716\n",
      "Training loss (for one batch) at step 470: 0.0471\n",
      "Seen so far: 30144 samples\n",
      "0.96718866\n",
      "Training loss (for one batch) at step 475: 0.0151\n",
      "Seen so far: 30464 samples\n",
      "0.9672118\n",
      "Training loss (for one batch) at step 480: 0.2048\n",
      "Seen so far: 30784 samples\n",
      "0.96721333\n",
      "Training loss (for one batch) at step 485: 0.0323\n",
      "Seen so far: 31104 samples\n",
      "0.96723336\n",
      "Training loss (for one batch) at step 490: 0.0542\n",
      "Seen so far: 31424 samples\n",
      "0.9672533\n",
      "Training loss (for one batch) at step 495: 0.0803\n",
      "Seen so far: 31744 samples\n",
      "0.9672794\n",
      "Training loss (for one batch) at step 500: 0.0273\n",
      "Seen so far: 32064 samples\n",
      "0.9673024\n",
      "Training loss (for one batch) at step 505: 0.1007\n",
      "Seen so far: 32384 samples\n",
      "0.9673007\n",
      "Training loss (for one batch) at step 510: 0.0434\n",
      "Seen so far: 32704 samples\n",
      "0.96730214\n",
      "Training loss (for one batch) at step 515: 0.0825\n",
      "Seen so far: 33024 samples\n",
      "0.9673158\n",
      "Training loss (for one batch) at step 520: 0.0295\n",
      "Seen so far: 33344 samples\n",
      "0.9673264\n",
      "Training loss (for one batch) at step 525: 0.0346\n",
      "Seen so far: 33664 samples\n",
      "0.96734613\n",
      "Training loss (for one batch) at step 530: 0.0663\n",
      "Seen so far: 33984 samples\n",
      "0.9673689\n",
      "Training loss (for one batch) at step 535: 0.0156\n",
      "Seen so far: 34304 samples\n",
      "0.96738553\n",
      "Training loss (for one batch) at step 540: 0.0014\n",
      "Seen so far: 34624 samples\n",
      "0.96740824\n",
      "Training loss (for one batch) at step 545: 0.0040\n",
      "Seen so far: 34944 samples\n",
      "0.9674278\n",
      "Training loss (for one batch) at step 550: 0.0721\n",
      "Seen so far: 35264 samples\n",
      "0.9674443\n",
      "Training loss (for one batch) at step 555: 0.0061\n",
      "Seen so far: 35584 samples\n",
      "0.9674669\n",
      "Training loss (for one batch) at step 560: 0.1739\n",
      "Seen so far: 35904 samples\n",
      "0.9674863\n",
      "Training loss (for one batch) at step 565: 0.0488\n",
      "Seen so far: 36224 samples\n",
      "0.9675028\n",
      "Training loss (for one batch) at step 570: 0.0487\n",
      "Seen so far: 36544 samples\n",
      "0.9675191\n",
      "Training loss (for one batch) at step 575: 0.0129\n",
      "Seen so far: 36864 samples\n",
      "0.9675506\n",
      "Training loss (for one batch) at step 580: 0.0166\n",
      "Seen so far: 37184 samples\n",
      "0.9675669\n",
      "Training loss (for one batch) at step 585: 0.0011\n",
      "Seen so far: 37504 samples\n",
      "0.96759224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 590: 0.0020\n",
      "Seen so far: 37824 samples\n",
      "0.9676115\n",
      "Training loss (for one batch) at step 595: 0.0818\n",
      "Seen so far: 38144 samples\n",
      "0.96762466\n",
      "Training loss (for one batch) at step 600: 0.0013\n",
      "Seen so far: 38464 samples\n",
      "0.9676559\n",
      "Training loss (for one batch) at step 605: 0.0098\n",
      "Seen so far: 38784 samples\n",
      "0.967675\n",
      "Training loss (for one batch) at step 610: 0.1085\n",
      "Seen so far: 39104 samples\n",
      "0.96768206\n",
      "Training loss (for one batch) at step 615: 0.0052\n",
      "Seen so far: 39424 samples\n",
      "0.9677041\n",
      "Training loss (for one batch) at step 620: 0.0644\n",
      "Seen so far: 39744 samples\n",
      "0.9677171\n",
      "Training loss (for one batch) at step 625: 0.0239\n",
      "Seen so far: 40064 samples\n",
      "0.9677361\n",
      "Training loss (for one batch) at step 630: 0.0045\n",
      "Seen so far: 40384 samples\n",
      "0.9677521\n",
      "Training loss (for one batch) at step 635: 0.1873\n",
      "Seen so far: 40704 samples\n",
      "0.967759\n",
      "Training loss (for one batch) at step 640: 0.2221\n",
      "Seen so far: 41024 samples\n",
      "0.96775997\n",
      "Training loss (for one batch) at step 645: 0.0478\n",
      "Seen so far: 41344 samples\n",
      "0.9677848\n",
      "Training loss (for one batch) at step 650: 0.0219\n",
      "Seen so far: 41664 samples\n",
      "0.9677947\n",
      "Training loss (for one batch) at step 655: 0.0195\n",
      "Seen so far: 41984 samples\n",
      "0.9678076\n",
      "Training loss (for one batch) at step 660: 0.0195\n",
      "Seen so far: 42304 samples\n",
      "0.96782935\n",
      "Training loss (for one batch) at step 665: 0.1389\n",
      "Seen so far: 42624 samples\n",
      "0.9678451\n",
      "Training loss (for one batch) at step 670: 0.0066\n",
      "Seen so far: 42944 samples\n",
      "0.9678608\n",
      "Training loss (for one batch) at step 675: 0.0040\n",
      "Seen so far: 43264 samples\n",
      "0.9678765\n",
      "Training loss (for one batch) at step 680: 0.0215\n",
      "Seen so far: 43584 samples\n",
      "0.9679041\n",
      "Training loss (for one batch) at step 685: 0.0229\n",
      "Seen so far: 43904 samples\n",
      "0.9679286\n",
      "Training loss (for one batch) at step 690: 0.0107\n",
      "Seen so far: 44224 samples\n",
      "0.9679501\n",
      "Training loss (for one batch) at step 695: 0.0514\n",
      "Seen so far: 44544 samples\n",
      "0.96795976\n",
      "Training loss (for one batch) at step 700: 0.0084\n",
      "Seen so far: 44864 samples\n",
      "0.9679812\n",
      "Training loss (for one batch) at step 705: 0.0001\n",
      "Seen so far: 45184 samples\n",
      "0.9680056\n",
      "Training loss (for one batch) at step 710: 0.0055\n",
      "Seen so far: 45504 samples\n",
      "0.96803284\n",
      "Training loss (for one batch) at step 715: 0.0819\n",
      "Seen so far: 45824 samples\n",
      "0.9680571\n",
      "Training loss (for one batch) at step 720: 0.0010\n",
      "Seen so far: 46144 samples\n",
      "0.96808726\n",
      "Training loss (for one batch) at step 725: 0.0289\n",
      "Seen so far: 46464 samples\n",
      "0.9681114\n",
      "Training loss (for one batch) at step 730: 0.0057\n",
      "Seen so far: 46784 samples\n",
      "0.96812963\n",
      "Training loss (for one batch) at step 735: 0.0002\n",
      "Seen so far: 47104 samples\n",
      "0.9681538\n",
      "Training loss (for one batch) at step 740: 0.0379\n",
      "Seen so far: 47424 samples\n",
      "0.9681749\n",
      "Training loss (for one batch) at step 745: 0.2374\n",
      "Seen so far: 47744 samples\n",
      "0.9681871\n",
      "Training loss (for one batch) at step 750: 0.0016\n",
      "Seen so far: 48064 samples\n",
      "0.96820813\n",
      "Training loss (for one batch) at step 755: 0.0168\n",
      "Seen so far: 48384 samples\n",
      "0.9682292\n",
      "Training loss (for one batch) at step 760: 0.0113\n",
      "Seen so far: 48704 samples\n",
      "0.968253\n",
      "Training acc over epoch: 0.9683\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.0785\n",
      "Seen so far: 64 samples\n",
      "0.9682719\n",
      "Training loss (for one batch) at step 5: 0.0237\n",
      "Seen so far: 384 samples\n",
      "0.9682899\n",
      "Training loss (for one batch) at step 10: 0.0175\n",
      "Seen so far: 704 samples\n",
      "0.9683049\n",
      "Training loss (for one batch) at step 15: 0.0298\n",
      "Seen so far: 1024 samples\n",
      "0.9683315\n",
      "Training loss (for one batch) at step 20: 0.0265\n",
      "Seen so far: 1344 samples\n",
      "0.9683465\n",
      "Training loss (for one batch) at step 25: 0.0891\n",
      "Seen so far: 1664 samples\n",
      "0.9683672\n",
      "Training loss (for one batch) at step 30: 0.0420\n",
      "Seen so far: 1984 samples\n",
      "0.9683879\n",
      "Training loss (for one batch) at step 35: 0.0063\n",
      "Seen so far: 2304 samples\n",
      "0.96840566\n",
      "Training loss (for one batch) at step 40: 0.0646\n",
      "Seen so far: 2624 samples\n",
      "0.9684176\n",
      "Training loss (for one batch) at step 45: 0.0038\n",
      "Seen so far: 2944 samples\n",
      "0.9684266\n",
      "Training loss (for one batch) at step 50: 0.0050\n",
      "Seen so far: 3264 samples\n",
      "0.9684269\n",
      "Training loss (for one batch) at step 55: 0.1508\n",
      "Seen so far: 3584 samples\n",
      "0.9684446\n",
      "Training loss (for one batch) at step 60: 0.0249\n",
      "Seen so far: 3904 samples\n",
      "0.9684651\n",
      "Training loss (for one batch) at step 65: 0.0374\n",
      "Seen so far: 4224 samples\n",
      "0.9684827\n",
      "Training loss (for one batch) at step 70: 0.0150\n",
      "Seen so far: 4544 samples\n",
      "0.9684944\n",
      "Training loss (for one batch) at step 75: 0.0861\n",
      "Seen so far: 4864 samples\n",
      "0.96851486\n",
      "Training loss (for one batch) at step 80: 0.0140\n",
      "Seen so far: 5184 samples\n",
      "0.96852946\n",
      "Training loss (for one batch) at step 85: 0.0330\n",
      "Seen so far: 5504 samples\n",
      "0.9685469\n",
      "Training loss (for one batch) at step 90: 0.0097\n",
      "Seen so far: 5824 samples\n",
      "0.9685701\n",
      "Training loss (for one batch) at step 95: 0.0630\n",
      "Seen so far: 6144 samples\n",
      "0.9685904\n",
      "Training loss (for one batch) at step 100: 0.0850\n",
      "Seen so far: 6464 samples\n",
      "0.9686106\n",
      "Training loss (for one batch) at step 105: 0.1508\n",
      "Seen so far: 6784 samples\n",
      "0.96862507\n",
      "Training loss (for one batch) at step 110: 0.0672\n",
      "Seen so far: 7104 samples\n",
      "0.96864235\n",
      "Training loss (for one batch) at step 115: 0.0235\n",
      "Seen so far: 7424 samples\n",
      "0.9686568\n",
      "Training loss (for one batch) at step 120: 0.0376\n",
      "Seen so far: 7744 samples\n",
      "0.9686654\n",
      "Training loss (for one batch) at step 125: 0.0684\n",
      "Seen so far: 8064 samples\n",
      "0.9686769\n",
      "Training loss (for one batch) at step 130: 0.0095\n",
      "Seen so far: 8384 samples\n",
      "0.96869695\n",
      "Training loss (for one batch) at step 135: 0.0111\n",
      "Seen so far: 8704 samples\n",
      "0.96872264\n",
      "Training loss (for one batch) at step 140: 0.0654\n",
      "Seen so far: 9024 samples\n",
      "0.96874547\n",
      "Training loss (for one batch) at step 145: 0.0046\n",
      "Seen so far: 9344 samples\n",
      "0.9687597\n",
      "Training loss (for one batch) at step 150: 0.0048\n",
      "Seen so far: 9664 samples\n",
      "0.9687853\n",
      "Training loss (for one batch) at step 155: 0.0424\n",
      "Seen so far: 9984 samples\n",
      "0.9687966\n",
      "Training loss (for one batch) at step 160: 0.1446\n",
      "Seen so far: 10304 samples\n",
      "0.9688022\n",
      "Training loss (for one batch) at step 165: 0.0064\n",
      "Seen so far: 10624 samples\n",
      "0.9688107\n",
      "Training loss (for one batch) at step 170: 0.0328\n",
      "Seen so far: 10944 samples\n",
      "0.9688361\n",
      "Training loss (for one batch) at step 175: 0.1458\n",
      "Seen so far: 11264 samples\n",
      "0.96885586\n",
      "Training loss (for one batch) at step 180: 0.0049\n",
      "Seen so far: 11584 samples\n",
      "0.9688755\n",
      "Training loss (for one batch) at step 185: 0.0137\n",
      "Seen so far: 11904 samples\n",
      "0.9688924\n",
      "Training loss (for one batch) at step 190: 0.0856\n",
      "Seen so far: 12224 samples\n",
      "0.96890634\n",
      "Training loss (for one batch) at step 195: 0.0639\n",
      "Seen so far: 12544 samples\n",
      "0.9689147\n",
      "Training loss (for one batch) at step 200: 0.0173\n",
      "Seen so far: 12864 samples\n",
      "0.96893144\n",
      "Training loss (for one batch) at step 205: 0.0015\n",
      "Seen so far: 13184 samples\n",
      "0.9689397\n",
      "Training loss (for one batch) at step 210: 0.0837\n",
      "Seen so far: 13504 samples\n",
      "0.96894515\n",
      "Training loss (for one batch) at step 215: 0.0228\n",
      "Seen so far: 13824 samples\n",
      "0.96896183\n",
      "Training loss (for one batch) at step 220: 0.0601\n",
      "Seen so far: 14144 samples\n",
      "0.96897566\n",
      "Training loss (for one batch) at step 225: 0.0118\n",
      "Seen so far: 14464 samples\n",
      "0.9689755\n",
      "Training loss (for one batch) at step 230: 0.1371\n",
      "Seen so far: 14784 samples\n",
      "0.9689809\n",
      "Training loss (for one batch) at step 235: 0.0250\n",
      "Seen so far: 15104 samples\n",
      "0.9689975\n",
      "Training loss (for one batch) at step 240: 0.0027\n",
      "Seen so far: 15424 samples\n",
      "0.96900845\n",
      "Training loss (for one batch) at step 245: 0.0416\n",
      "Seen so far: 15744 samples\n",
      "0.9690138\n",
      "Training loss (for one batch) at step 250: 0.0099\n",
      "Seen so far: 16064 samples\n",
      "0.9690303\n",
      "Training loss (for one batch) at step 255: 0.0327\n",
      "Seen so far: 16384 samples\n",
      "0.96904683\n",
      "Training loss (for one batch) at step 260: 0.0030\n",
      "Seen so far: 16704 samples\n",
      "0.9690577\n",
      "Training loss (for one batch) at step 265: 0.0525\n",
      "Seen so far: 17024 samples\n",
      "0.9690685\n",
      "Training loss (for one batch) at step 270: 0.0078\n",
      "Seen so far: 17344 samples\n",
      "0.9690794\n",
      "Training loss (for one batch) at step 275: 0.0742\n",
      "Seen so far: 17664 samples\n",
      "0.96909857\n",
      "Training loss (for one batch) at step 280: 0.0348\n",
      "Seen so far: 17984 samples\n",
      "0.96910655\n",
      "Training loss (for one batch) at step 285: 0.0008\n",
      "Seen so far: 18304 samples\n",
      "0.9691229\n",
      "Training loss (for one batch) at step 290: 0.0041\n",
      "Seen so far: 18624 samples\n",
      "0.96914476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 295: 0.0609\n",
      "Seen so far: 18944 samples\n",
      "0.9691638\n",
      "Training loss (for one batch) at step 300: 0.0087\n",
      "Seen so far: 19264 samples\n",
      "0.96917725\n",
      "Training loss (for one batch) at step 305: 0.0237\n",
      "Seen so far: 19584 samples\n",
      "0.96917963\n",
      "Training loss (for one batch) at step 310: 0.0606\n",
      "Seen so far: 19904 samples\n",
      "0.96919584\n",
      "Training loss (for one batch) at step 315: 0.0066\n",
      "Seen so far: 20224 samples\n",
      "0.9692065\n",
      "Training loss (for one batch) at step 320: 0.0718\n",
      "Seen so far: 20544 samples\n",
      "0.96921986\n",
      "Training loss (for one batch) at step 325: 0.0512\n",
      "Seen so far: 20864 samples\n",
      "0.9692415\n",
      "Training loss (for one batch) at step 330: 0.1156\n",
      "Seen so far: 21184 samples\n",
      "0.9692493\n",
      "Training loss (for one batch) at step 335: 0.0418\n",
      "Seen so far: 21504 samples\n",
      "0.9692654\n",
      "Training loss (for one batch) at step 340: 0.0466\n",
      "Seen so far: 21824 samples\n",
      "0.9692759\n",
      "Training loss (for one batch) at step 345: 0.0050\n",
      "Seen so far: 22144 samples\n",
      "0.9692974\n",
      "Training loss (for one batch) at step 350: 0.0755\n",
      "Seen so far: 22464 samples\n",
      "0.9693161\n",
      "Training loss (for one batch) at step 355: 0.0270\n",
      "Seen so far: 22784 samples\n",
      "0.9693266\n",
      "Training loss (for one batch) at step 360: 0.0723\n",
      "Seen so far: 23104 samples\n",
      "0.9693398\n",
      "Training loss (for one batch) at step 365: 0.0023\n",
      "Seen so far: 23424 samples\n",
      "0.96935844\n",
      "Training loss (for one batch) at step 370: 0.0755\n",
      "Seen so far: 23744 samples\n",
      "0.9693743\n",
      "Training loss (for one batch) at step 375: 0.4329\n",
      "Seen so far: 24064 samples\n",
      "0.9693792\n",
      "Training loss (for one batch) at step 380: 0.0035\n",
      "Seen so far: 24384 samples\n",
      "0.9693814\n",
      "Training loss (for one batch) at step 385: 0.0015\n",
      "Seen so far: 24704 samples\n",
      "0.9693999\n",
      "Training loss (for one batch) at step 390: 0.0313\n",
      "Seen so far: 25024 samples\n",
      "0.9694184\n",
      "Training loss (for one batch) at step 395: 0.3691\n",
      "Seen so far: 25344 samples\n",
      "0.96940696\n",
      "Training loss (for one batch) at step 400: 0.0246\n",
      "Seen so far: 25664 samples\n",
      "0.9694173\n",
      "Training loss (for one batch) at step 405: 0.1333\n",
      "Seen so far: 25984 samples\n",
      "0.96941394\n",
      "Training loss (for one batch) at step 410: 0.0128\n",
      "Seen so far: 26304 samples\n",
      "0.9694188\n",
      "Training loss (for one batch) at step 415: 0.0255\n",
      "Seen so far: 26624 samples\n",
      "0.96943176\n",
      "Training loss (for one batch) at step 420: 0.1281\n",
      "Seen so far: 26944 samples\n",
      "0.9694366\n",
      "Training loss (for one batch) at step 425: 0.0284\n",
      "Seen so far: 27264 samples\n",
      "0.9694496\n",
      "Training loss (for one batch) at step 430: 0.0639\n",
      "Seen so far: 27584 samples\n",
      "0.96945167\n",
      "Training loss (for one batch) at step 435: 0.0078\n",
      "Seen so far: 27904 samples\n",
      "0.9694754\n",
      "Training loss (for one batch) at step 440: 0.0080\n",
      "Seen so far: 28224 samples\n",
      "0.96948284\n",
      "Training loss (for one batch) at step 445: 0.0018\n",
      "Seen so far: 28544 samples\n",
      "0.96950376\n",
      "Training loss (for one batch) at step 450: 0.0339\n",
      "Seen so far: 28864 samples\n",
      "0.96951663\n",
      "Training loss (for one batch) at step 455: 0.0417\n",
      "Seen so far: 29184 samples\n",
      "0.9695348\n",
      "Training loss (for one batch) at step 460: 0.2284\n",
      "Seen so far: 29504 samples\n",
      "0.96954757\n",
      "Training loss (for one batch) at step 465: 0.0197\n",
      "Seen so far: 29824 samples\n",
      "0.96956575\n",
      "Training loss (for one batch) at step 470: 0.0289\n",
      "Seen so far: 30144 samples\n",
      "0.96957844\n",
      "Training loss (for one batch) at step 475: 0.0087\n",
      "Seen so far: 30464 samples\n",
      "0.9695992\n",
      "Training loss (for one batch) at step 480: 0.0452\n",
      "Seen so far: 30784 samples\n",
      "0.9696119\n",
      "Training loss (for one batch) at step 485: 0.0426\n",
      "Seen so far: 31104 samples\n",
      "0.96963525\n",
      "Training loss (for one batch) at step 490: 0.0060\n",
      "Seen so far: 31424 samples\n",
      "0.9696479\n",
      "Training loss (for one batch) at step 495: 0.0018\n",
      "Seen so far: 31744 samples\n",
      "0.9696685\n",
      "Training loss (for one batch) at step 500: 0.0022\n",
      "Seen so far: 32064 samples\n",
      "0.96969444\n",
      "Training loss (for one batch) at step 505: 0.2499\n",
      "Seen so far: 32384 samples\n",
      "0.969707\n",
      "Training loss (for one batch) at step 510: 0.0008\n",
      "Seen so far: 32704 samples\n",
      "0.96972483\n",
      "Training loss (for one batch) at step 515: 0.0025\n",
      "Seen so far: 33024 samples\n",
      "0.969748\n",
      "Training loss (for one batch) at step 520: 0.0111\n",
      "Seen so far: 33344 samples\n",
      "0.96977115\n",
      "Training loss (for one batch) at step 525: 0.0117\n",
      "Seen so far: 33664 samples\n",
      "0.96979153\n",
      "Training loss (for one batch) at step 530: 0.0033\n",
      "Seen so far: 33984 samples\n",
      "0.9698146\n",
      "Training loss (for one batch) at step 535: 0.0801\n",
      "Seen so far: 34304 samples\n",
      "0.969827\n",
      "Training loss (for one batch) at step 540: 0.0036\n",
      "Seen so far: 34624 samples\n",
      "0.9698473\n",
      "Training loss (for one batch) at step 545: 0.0128\n",
      "Seen so far: 34944 samples\n",
      "0.9698676\n",
      "Training loss (for one batch) at step 550: 0.0012\n",
      "Seen so far: 35264 samples\n",
      "0.9698905\n",
      "Training loss (for one batch) at step 555: 0.1329\n",
      "Seen so far: 35584 samples\n",
      "0.96990013\n",
      "Training loss (for one batch) at step 560: 0.0137\n",
      "Seen so far: 35904 samples\n",
      "0.96991765\n",
      "Training loss (for one batch) at step 565: 0.0053\n",
      "Seen so far: 36224 samples\n",
      "0.9699299\n",
      "Training loss (for one batch) at step 570: 0.0023\n",
      "Seen so far: 36544 samples\n",
      "0.9699395\n",
      "Training loss (for one batch) at step 575: 0.0062\n",
      "Seen so far: 36864 samples\n",
      "0.96995956\n",
      "Training loss (for one batch) at step 580: 0.0300\n",
      "Seen so far: 37184 samples\n",
      "0.96997434\n",
      "Training loss (for one batch) at step 585: 0.0027\n",
      "Seen so far: 37504 samples\n",
      "0.9699812\n",
      "Training loss (for one batch) at step 590: 0.0622\n",
      "Seen so far: 37824 samples\n",
      "0.96999335\n",
      "Training loss (for one batch) at step 595: 0.0090\n",
      "Seen so far: 38144 samples\n",
      "0.97001857\n",
      "Training loss (for one batch) at step 600: 0.0186\n",
      "Seen so far: 38464 samples\n",
      "0.97003853\n",
      "Training loss (for one batch) at step 605: 0.0981\n",
      "Seen so far: 38784 samples\n",
      "0.9700453\n",
      "Training loss (for one batch) at step 610: 0.0037\n",
      "Seen so far: 39104 samples\n",
      "0.9700626\n",
      "Training loss (for one batch) at step 615: 0.0007\n",
      "Seen so far: 39424 samples\n",
      "0.97008246\n",
      "Training loss (for one batch) at step 620: 0.0020\n",
      "Seen so far: 39744 samples\n",
      "0.97009706\n",
      "Training loss (for one batch) at step 625: 0.0298\n",
      "Seen so far: 40064 samples\n",
      "0.97011685\n",
      "Training loss (for one batch) at step 630: 0.0010\n",
      "Seen so far: 40384 samples\n",
      "0.97013927\n",
      "Training loss (for one batch) at step 635: 0.0197\n",
      "Seen so far: 40704 samples\n",
      "0.97015375\n",
      "Training loss (for one batch) at step 640: 0.0088\n",
      "Seen so far: 41024 samples\n",
      "0.97017086\n",
      "Training loss (for one batch) at step 645: 0.0041\n",
      "Seen so far: 41344 samples\n",
      "0.9701958\n",
      "Training loss (for one batch) at step 650: 0.0134\n",
      "Seen so far: 41664 samples\n",
      "0.9702128\n",
      "Training loss (for one batch) at step 655: 0.0078\n",
      "Seen so far: 41984 samples\n",
      "0.9702298\n",
      "Training loss (for one batch) at step 660: 0.0359\n",
      "Seen so far: 42304 samples\n",
      "0.970252\n",
      "Training loss (for one batch) at step 665: 0.0084\n",
      "Seen so far: 42624 samples\n",
      "0.9702715\n",
      "Training loss (for one batch) at step 670: 0.0157\n",
      "Seen so far: 42944 samples\n",
      "0.97028583\n",
      "Training loss (for one batch) at step 675: 0.0002\n",
      "Seen so far: 43264 samples\n",
      "0.9703053\n",
      "Training loss (for one batch) at step 680: 0.0109\n",
      "Seen so far: 43584 samples\n",
      "0.9703274\n",
      "Training loss (for one batch) at step 685: 0.0015\n",
      "Seen so far: 43904 samples\n",
      "0.9703416\n",
      "Training loss (for one batch) at step 690: 0.0625\n",
      "Seen so far: 44224 samples\n",
      "0.970361\n",
      "Training loss (for one batch) at step 695: 0.0253\n",
      "Seen so far: 44544 samples\n",
      "0.97038037\n",
      "Training loss (for one batch) at step 700: 0.0182\n",
      "Seen so far: 44864 samples\n",
      "0.9703971\n",
      "Training loss (for one batch) at step 705: 0.0076\n",
      "Seen so far: 45184 samples\n",
      "0.97041637\n",
      "Training loss (for one batch) at step 710: 0.0094\n",
      "Seen so far: 45504 samples\n",
      "0.9704305\n",
      "Training loss (for one batch) at step 715: 0.0005\n",
      "Seen so far: 45824 samples\n",
      "0.9704523\n",
      "Training loss (for one batch) at step 720: 0.0103\n",
      "Seen so far: 46144 samples\n",
      "0.97047406\n",
      "Training loss (for one batch) at step 725: 0.0007\n",
      "Seen so far: 46464 samples\n",
      "0.9704907\n",
      "Training loss (for one batch) at step 730: 0.0657\n",
      "Seen so far: 46784 samples\n",
      "0.97050726\n",
      "Training loss (for one batch) at step 735: 0.0581\n",
      "Seen so far: 47104 samples\n",
      "0.97052634\n",
      "Training loss (for one batch) at step 740: 0.0982\n",
      "Seen so far: 47424 samples\n",
      "0.9705403\n",
      "Training loss (for one batch) at step 745: 0.0028\n",
      "Seen so far: 47744 samples\n",
      "0.97055423\n",
      "Training loss (for one batch) at step 750: 0.0197\n",
      "Seen so far: 48064 samples\n",
      "0.97057325\n",
      "Training loss (for one batch) at step 755: 0.0024\n",
      "Seen so far: 48384 samples\n",
      "0.97059476\n",
      "Training loss (for one batch) at step 760: 0.0201\n",
      "Seen so far: 48704 samples\n",
      "0.9706112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9706\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.0035\n",
      "Seen so far: 64 samples\n",
      "0.9706186\n",
      "Training loss (for one batch) at step 5: 0.0004\n",
      "Seen so far: 384 samples\n",
      "0.97064006\n",
      "Training loss (for one batch) at step 10: 0.0033\n",
      "Seen so far: 704 samples\n",
      "0.97065896\n",
      "Training loss (for one batch) at step 15: 0.0008\n",
      "Seen so far: 1024 samples\n",
      "0.9706778\n",
      "Training loss (for one batch) at step 20: 0.0012\n",
      "Seen so far: 1344 samples\n",
      "0.9706992\n",
      "Training loss (for one batch) at step 25: 0.0008\n",
      "Seen so far: 1664 samples\n",
      "0.9707205\n",
      "Training loss (for one batch) at step 30: 0.0123\n",
      "Seen so far: 1984 samples\n",
      "0.97073674\n",
      "Training loss (for one batch) at step 35: 0.0107\n",
      "Seen so far: 2304 samples\n",
      "0.97075796\n",
      "Training loss (for one batch) at step 40: 0.0077\n",
      "Seen so far: 2624 samples\n",
      "0.9707716\n",
      "Training loss (for one batch) at step 45: 0.0016\n",
      "Seen so far: 2944 samples\n",
      "0.97079027\n",
      "Training loss (for one batch) at step 50: 0.0408\n",
      "Seen so far: 3264 samples\n",
      "0.9708089\n",
      "Training loss (for one batch) at step 55: 0.0002\n",
      "Seen so far: 3584 samples\n",
      "0.9708326\n",
      "Training loss (for one batch) at step 60: 0.0234\n",
      "Seen so far: 3904 samples\n",
      "0.9708511\n",
      "Training loss (for one batch) at step 65: 0.0085\n",
      "Seen so far: 4224 samples\n",
      "0.9708747\n",
      "Training loss (for one batch) at step 70: 0.0146\n",
      "Seen so far: 4544 samples\n",
      "0.9708882\n",
      "Training loss (for one batch) at step 75: 0.0018\n",
      "Seen so far: 4864 samples\n",
      "0.9709092\n",
      "Training loss (for one batch) at step 80: 0.0021\n",
      "Seen so far: 5184 samples\n",
      "0.97093016\n",
      "Training loss (for one batch) at step 85: 0.0355\n",
      "Seen so far: 5504 samples\n",
      "0.970936\n",
      "Training loss (for one batch) at step 90: 0.0053\n",
      "Seen so far: 5824 samples\n",
      "0.97094935\n",
      "Training loss (for one batch) at step 95: 0.0046\n",
      "Seen so far: 6144 samples\n",
      "0.9709652\n",
      "Training loss (for one batch) at step 100: 0.0198\n",
      "Seen so far: 6464 samples\n",
      "0.970981\n",
      "Training loss (for one batch) at step 105: 0.0055\n",
      "Seen so far: 6784 samples\n",
      "0.9709968\n",
      "Training loss (for one batch) at step 110: 0.0092\n",
      "Seen so far: 7104 samples\n",
      "0.9710126\n",
      "Training loss (for one batch) at step 115: 0.0414\n",
      "Seen so far: 7424 samples\n",
      "0.9710283\n",
      "Training loss (for one batch) at step 120: 0.0011\n",
      "Seen so far: 7744 samples\n",
      "0.97104406\n",
      "Training loss (for one batch) at step 125: 0.0274\n",
      "Seen so far: 8064 samples\n",
      "0.9710598\n",
      "Training loss (for one batch) at step 130: 0.0336\n",
      "Seen so far: 8384 samples\n",
      "0.9710755\n",
      "Training loss (for one batch) at step 135: 0.0151\n",
      "Seen so far: 8704 samples\n",
      "0.9710786\n",
      "Training loss (for one batch) at step 140: 0.0267\n",
      "Seen so far: 9024 samples\n",
      "0.97109175\n",
      "Training loss (for one batch) at step 145: 0.0008\n",
      "Seen so far: 9344 samples\n",
      "0.97110486\n",
      "Training loss (for one batch) at step 150: 0.0055\n",
      "Seen so far: 9664 samples\n",
      "0.9711204\n",
      "Training loss (for one batch) at step 155: 0.0073\n",
      "Seen so far: 9984 samples\n",
      "0.971141\n",
      "Training loss (for one batch) at step 160: 0.0307\n",
      "Seen so far: 10304 samples\n",
      "0.971149\n",
      "Training loss (for one batch) at step 165: 0.1341\n",
      "Seen so far: 10624 samples\n",
      "0.9711646\n",
      "Training loss (for one batch) at step 170: 0.0228\n",
      "Seen so far: 10944 samples\n",
      "0.97117263\n",
      "Training loss (for one batch) at step 175: 0.1371\n",
      "Seen so far: 11264 samples\n",
      "0.9711831\n",
      "Training loss (for one batch) at step 180: 0.0018\n",
      "Seen so far: 11584 samples\n",
      "0.97119606\n",
      "Training loss (for one batch) at step 185: 0.0035\n",
      "Seen so far: 11904 samples\n",
      "0.9712115\n",
      "Training loss (for one batch) at step 190: 0.0484\n",
      "Seen so far: 12224 samples\n",
      "0.97121453\n",
      "Training loss (for one batch) at step 195: 0.0104\n",
      "Seen so far: 12544 samples\n",
      "0.9712274\n",
      "Training loss (for one batch) at step 200: 0.0001\n",
      "Seen so far: 12864 samples\n",
      "0.97123784\n",
      "Training loss (for one batch) at step 205: 0.0818\n",
      "Seen so far: 13184 samples\n",
      "0.97124827\n",
      "Training loss (for one batch) at step 210: 0.0006\n",
      "Seen so far: 13504 samples\n",
      "0.97126853\n",
      "Training loss (for one batch) at step 215: 0.0015\n",
      "Seen so far: 13824 samples\n",
      "0.971269\n",
      "Training loss (for one batch) at step 220: 0.0156\n",
      "Seen so far: 14144 samples\n",
      "0.9712769\n",
      "Training loss (for one batch) at step 225: 0.0170\n",
      "Seen so far: 14464 samples\n",
      "0.9712897\n",
      "Training loss (for one batch) at step 230: 0.0443\n",
      "Seen so far: 14784 samples\n",
      "0.9712926\n",
      "Training loss (for one batch) at step 235: 0.0009\n",
      "Seen so far: 15104 samples\n",
      "0.9713054\n",
      "Training loss (for one batch) at step 240: 0.1068\n",
      "Seen so far: 15424 samples\n",
      "0.97131324\n",
      "Training loss (for one batch) at step 245: 0.0818\n",
      "Seen so far: 15744 samples\n",
      "0.9713235\n",
      "Training loss (for one batch) at step 250: 0.0530\n",
      "Seen so far: 16064 samples\n",
      "0.97133374\n",
      "Training loss (for one batch) at step 255: 0.0093\n",
      "Seen so far: 16384 samples\n",
      "0.9713391\n",
      "Training loss (for one batch) at step 260: 0.0194\n",
      "Seen so far: 16704 samples\n",
      "0.97135174\n",
      "Training loss (for one batch) at step 265: 0.0034\n",
      "Seen so far: 17024 samples\n",
      "0.9713669\n",
      "Training loss (for one batch) at step 270: 0.0188\n",
      "Seen so far: 17344 samples\n",
      "0.97136974\n",
      "Training loss (for one batch) at step 275: 0.0016\n",
      "Seen so far: 17664 samples\n",
      "0.97138727\n",
      "Training loss (for one batch) at step 280: 0.0018\n",
      "Seen so far: 17984 samples\n",
      "0.97140473\n",
      "Training loss (for one batch) at step 285: 0.0210\n",
      "Seen so far: 18304 samples\n",
      "0.9714222\n",
      "Training loss (for one batch) at step 290: 0.0044\n",
      "Seen so far: 18624 samples\n",
      "0.9714372\n",
      "Training loss (for one batch) at step 295: 0.0265\n",
      "Seen so far: 18944 samples\n",
      "0.9714522\n",
      "Training loss (for one batch) at step 300: 0.0630\n",
      "Seen so far: 19264 samples\n",
      "0.9714647\n",
      "Training loss (for one batch) at step 305: 0.0415\n",
      "Seen so far: 19584 samples\n",
      "0.9714772\n",
      "Training loss (for one batch) at step 310: 0.0032\n",
      "Seen so far: 19904 samples\n",
      "0.97149456\n",
      "Training loss (for one batch) at step 315: 0.0004\n",
      "Seen so far: 20224 samples\n",
      "0.9715119\n",
      "Training loss (for one batch) at step 320: 0.0018\n",
      "Seen so far: 20544 samples\n",
      "0.97152674\n",
      "Training loss (for one batch) at step 325: 0.0002\n",
      "Seen so far: 20864 samples\n",
      "0.971544\n",
      "Training loss (for one batch) at step 330: 0.0416\n",
      "Seen so far: 21184 samples\n",
      "0.97155637\n",
      "Training loss (for one batch) at step 335: 0.0116\n",
      "Seen so far: 21504 samples\n",
      "0.97157604\n",
      "Training loss (for one batch) at step 340: 0.0484\n",
      "Seen so far: 21824 samples\n",
      "0.9715932\n",
      "Training loss (for one batch) at step 345: 0.0415\n",
      "Seen so far: 22144 samples\n",
      "0.97160554\n",
      "Training loss (for one batch) at step 350: 0.1155\n",
      "Seen so far: 22464 samples\n",
      "0.97160816\n",
      "Training loss (for one batch) at step 355: 0.0552\n",
      "Seen so far: 22784 samples\n",
      "0.9716229\n",
      "Training loss (for one batch) at step 360: 0.0106\n",
      "Seen so far: 23104 samples\n",
      "0.97163755\n",
      "Training loss (for one batch) at step 365: 0.0003\n",
      "Seen so far: 23424 samples\n",
      "0.9716498\n",
      "Training loss (for one batch) at step 370: 0.0552\n",
      "Seen so far: 23744 samples\n",
      "0.97166204\n",
      "Training loss (for one batch) at step 375: 0.1508\n",
      "Seen so far: 24064 samples\n",
      "0.971667\n",
      "Training loss (for one batch) at step 380: 0.0062\n",
      "Seen so far: 24384 samples\n",
      "0.97168404\n",
      "Training loss (for one batch) at step 385: 0.0470\n",
      "Seen so far: 24704 samples\n",
      "0.97169864\n",
      "Training loss (for one batch) at step 390: 0.0748\n",
      "Seen so far: 25024 samples\n",
      "0.9716963\n",
      "Training loss (for one batch) at step 395: 0.0007\n",
      "Seen so far: 25344 samples\n",
      "0.9717157\n",
      "Training loss (for one batch) at step 400: 0.0368\n",
      "Seen so far: 25664 samples\n",
      "0.971723\n",
      "Training loss (for one batch) at step 405: 0.1000\n",
      "Seen so far: 25984 samples\n",
      "0.97173035\n",
      "Training loss (for one batch) at step 410: 0.0459\n",
      "Seen so far: 26304 samples\n",
      "0.97174484\n",
      "Training loss (for one batch) at step 415: 0.0081\n",
      "Seen so far: 26624 samples\n",
      "0.9717641\n",
      "Training loss (for one batch) at step 420: 0.0207\n",
      "Seen so far: 26944 samples\n",
      "0.9717785\n",
      "Training loss (for one batch) at step 425: 0.1024\n",
      "Seen so far: 27264 samples\n",
      "0.9717786\n",
      "Training loss (for one batch) at step 430: 0.0188\n",
      "Seen so far: 27584 samples\n",
      "0.971793\n",
      "Training loss (for one batch) at step 435: 0.0127\n",
      "Seen so far: 27904 samples\n",
      "0.97180974\n",
      "Training loss (for one batch) at step 440: 0.2932\n",
      "Seen so far: 28224 samples\n",
      "0.9718098\n",
      "Training loss (for one batch) at step 445: 0.0344\n",
      "Seen so far: 28544 samples\n",
      "0.97182417\n",
      "Training loss (for one batch) at step 450: 0.0028\n",
      "Seen so far: 28864 samples\n",
      "0.971829\n",
      "Training loss (for one batch) at step 455: 0.1087\n",
      "Seen so far: 29184 samples\n",
      "0.9718409\n",
      "Training loss (for one batch) at step 460: 0.0179\n",
      "Seen so far: 29504 samples\n",
      "0.9718552\n",
      "Training loss (for one batch) at step 465: 0.0216\n",
      "Seen so far: 29824 samples\n",
      "0.97187424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 470: 0.0050\n",
      "Seen so far: 30144 samples\n",
      "0.97189325\n",
      "Training loss (for one batch) at step 475: 0.1107\n",
      "Seen so far: 30464 samples\n",
      "0.97190505\n",
      "Training loss (for one batch) at step 480: 0.0038\n",
      "Seen so far: 30784 samples\n",
      "0.9719193\n",
      "Training loss (for one batch) at step 485: 0.0445\n",
      "Seen so far: 31104 samples\n",
      "0.9719335\n",
      "Training loss (for one batch) at step 490: 0.1314\n",
      "Seen so far: 31424 samples\n",
      "0.9719524\n",
      "Training loss (for one batch) at step 495: 0.0141\n",
      "Seen so far: 31744 samples\n",
      "0.9719665\n",
      "Training loss (for one batch) at step 500: 0.0018\n",
      "Seen so far: 32064 samples\n",
      "0.97197115\n",
      "Training loss (for one batch) at step 505: 0.0389\n",
      "Seen so far: 32384 samples\n",
      "0.9719758\n",
      "Training loss (for one batch) at step 510: 0.0337\n",
      "Seen so far: 32704 samples\n",
      "0.97199225\n",
      "Training loss (for one batch) at step 515: 0.0694\n",
      "Seen so far: 33024 samples\n",
      "0.97200394\n",
      "Training loss (for one batch) at step 520: 0.0082\n",
      "Seen so far: 33344 samples\n",
      "0.9720133\n",
      "Training loss (for one batch) at step 525: 0.0854\n",
      "Seen so far: 33664 samples\n",
      "0.9720179\n",
      "Training loss (for one batch) at step 530: 0.0153\n",
      "Seen so far: 33984 samples\n",
      "0.9720342\n",
      "Training loss (for one batch) at step 535: 0.0634\n",
      "Seen so far: 34304 samples\n",
      "0.9720365\n",
      "Training loss (for one batch) at step 540: 0.0244\n",
      "Seen so far: 34624 samples\n",
      "0.9720457\n",
      "Training loss (for one batch) at step 545: 0.0301\n",
      "Seen so far: 34944 samples\n",
      "0.9720527\n",
      "Training loss (for one batch) at step 550: 0.0011\n",
      "Seen so far: 35264 samples\n",
      "0.9720666\n",
      "Training loss (for one batch) at step 555: 0.0085\n",
      "Seen so far: 35584 samples\n",
      "0.9720712\n",
      "Training loss (for one batch) at step 560: 0.0741\n",
      "Seen so far: 35904 samples\n",
      "0.972078\n",
      "Training loss (for one batch) at step 565: 0.0319\n",
      "Seen so far: 36224 samples\n",
      "0.97208023\n",
      "Training loss (for one batch) at step 570: 0.0059\n",
      "Seen so far: 36544 samples\n",
      "0.97209173\n",
      "Training loss (for one batch) at step 575: 0.0016\n",
      "Seen so far: 36864 samples\n",
      "0.97209394\n",
      "Training loss (for one batch) at step 580: 0.1785\n",
      "Seen so far: 37184 samples\n",
      "0.97209847\n",
      "Training loss (for one batch) at step 585: 0.0557\n",
      "Seen so far: 37504 samples\n",
      "0.97210526\n",
      "Training loss (for one batch) at step 590: 0.0018\n",
      "Seen so far: 37824 samples\n",
      "0.9721191\n",
      "Training loss (for one batch) at step 595: 0.0876\n",
      "Seen so far: 38144 samples\n",
      "0.97212356\n",
      "Training loss (for one batch) at step 600: 0.0012\n",
      "Seen so far: 38464 samples\n",
      "0.9721397\n",
      "Training loss (for one batch) at step 605: 0.0153\n",
      "Seen so far: 38784 samples\n",
      "0.9721534\n",
      "Training loss (for one batch) at step 610: 0.0239\n",
      "Seen so far: 39104 samples\n",
      "0.9721672\n",
      "Training loss (for one batch) at step 615: 0.0479\n",
      "Seen so far: 39424 samples\n",
      "0.9721739\n",
      "Training loss (for one batch) at step 620: 0.0479\n",
      "Seen so far: 39744 samples\n",
      "0.97218066\n",
      "Training loss (for one batch) at step 625: 0.0035\n",
      "Seen so far: 40064 samples\n",
      "0.97219205\n",
      "Training loss (for one batch) at step 630: 0.0011\n",
      "Seen so far: 40384 samples\n",
      "0.97220576\n",
      "Training loss (for one batch) at step 635: 0.0255\n",
      "Seen so far: 40704 samples\n",
      "0.97222173\n",
      "Training loss (for one batch) at step 640: 0.1289\n",
      "Seen so far: 41024 samples\n",
      "0.97223073\n",
      "Training loss (for one batch) at step 645: 0.0260\n",
      "Seen so far: 41344 samples\n",
      "0.9722443\n",
      "Training loss (for one batch) at step 650: 0.1030\n",
      "Seen so far: 41664 samples\n",
      "0.9722533\n",
      "Training loss (for one batch) at step 655: 0.0187\n",
      "Seen so far: 41984 samples\n",
      "0.9722692\n",
      "Training loss (for one batch) at step 660: 0.0054\n",
      "Seen so far: 42304 samples\n",
      "0.97228044\n",
      "Training loss (for one batch) at step 665: 0.0135\n",
      "Seen so far: 42624 samples\n",
      "0.9722963\n",
      "Training loss (for one batch) at step 670: 0.0271\n",
      "Seen so far: 42944 samples\n",
      "0.9723121\n",
      "Training loss (for one batch) at step 675: 0.0024\n",
      "Seen so far: 43264 samples\n",
      "0.9723233\n",
      "Training loss (for one batch) at step 680: 0.0032\n",
      "Seen so far: 43584 samples\n",
      "0.97233677\n",
      "Training loss (for one batch) at step 685: 0.0124\n",
      "Seen so far: 43904 samples\n",
      "0.9723571\n",
      "Training loss (for one batch) at step 690: 0.0060\n",
      "Seen so far: 44224 samples\n",
      "0.97236365\n",
      "Training loss (for one batch) at step 695: 0.1387\n",
      "Seen so far: 44544 samples\n",
      "0.9723633\n",
      "Training loss (for one batch) at step 700: 0.0031\n",
      "Seen so far: 44864 samples\n",
      "0.9723675\n",
      "Training loss (for one batch) at step 705: 0.0811\n",
      "Seen so far: 45184 samples\n",
      "0.9723786\n",
      "Training loss (for one batch) at step 710: 0.0172\n",
      "Seen so far: 45504 samples\n",
      "0.9723897\n",
      "Training loss (for one batch) at step 715: 0.0057\n",
      "Seen so far: 45824 samples\n",
      "0.9724054\n",
      "Training loss (for one batch) at step 720: 0.0255\n",
      "Seen so far: 46144 samples\n",
      "0.9724164\n",
      "Training loss (for one batch) at step 725: 0.1179\n",
      "Seen so far: 46464 samples\n",
      "0.97242975\n",
      "Training loss (for one batch) at step 730: 0.0011\n",
      "Seen so far: 46784 samples\n",
      "0.9724407\n",
      "Training loss (for one batch) at step 735: 0.0030\n",
      "Seen so far: 47104 samples\n",
      "0.97245634\n",
      "Training loss (for one batch) at step 740: 0.1241\n",
      "Seen so far: 47424 samples\n",
      "0.9724673\n",
      "Training loss (for one batch) at step 745: 0.0222\n",
      "Seen so far: 47744 samples\n",
      "0.97248507\n",
      "Training loss (for one batch) at step 750: 0.0138\n",
      "Seen so far: 48064 samples\n",
      "0.9725029\n",
      "Training loss (for one batch) at step 755: 0.0657\n",
      "Seen so far: 48384 samples\n",
      "0.9725183\n",
      "Training loss (for one batch) at step 760: 0.0777\n",
      "Seen so far: 48704 samples\n",
      "0.9725247\n",
      "Training acc over epoch: 0.9725\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one batch) at step 0: 0.0132\n",
      "Seen so far: 64 samples\n",
      "0.9725303\n",
      "Training loss (for one batch) at step 5: 0.0229\n",
      "Seen so far: 384 samples\n",
      "0.9725457\n",
      "Training loss (for one batch) at step 10: 0.0285\n",
      "Seen so far: 704 samples\n",
      "0.97254974\n",
      "Training loss (for one batch) at step 15: 0.1830\n",
      "Seen so far: 1024 samples\n",
      "0.9725538\n",
      "Training loss (for one batch) at step 20: 0.0360\n",
      "Seen so far: 1344 samples\n",
      "0.9725624\n",
      "Training loss (for one batch) at step 25: 0.0026\n",
      "Seen so far: 1664 samples\n",
      "0.97257775\n",
      "Training loss (for one batch) at step 30: 0.1006\n",
      "Seen so far: 1984 samples\n",
      "0.972584\n",
      "Training loss (for one batch) at step 35: 0.0066\n",
      "Seen so far: 2304 samples\n",
      "0.9726016\n",
      "Training loss (for one batch) at step 40: 0.0026\n",
      "Seen so far: 2624 samples\n",
      "0.97261465\n",
      "Training loss (for one batch) at step 45: 0.0184\n",
      "Seen so far: 2944 samples\n",
      "0.9726254\n",
      "Training loss (for one batch) at step 50: 0.0632\n",
      "Seen so far: 3264 samples\n",
      "0.9726339\n",
      "Training loss (for one batch) at step 55: 0.1484\n",
      "Seen so far: 3584 samples\n",
      "0.97263557\n",
      "Training loss (for one batch) at step 60: 0.0433\n",
      "Seen so far: 3904 samples\n",
      "0.97264177\n",
      "Training loss (for one batch) at step 65: 0.1335\n",
      "Seen so far: 4224 samples\n",
      "0.97265023\n",
      "Training loss (for one batch) at step 70: 0.0016\n",
      "Seen so far: 4544 samples\n",
      "0.9726654\n",
      "Training loss (for one batch) at step 75: 0.0183\n",
      "Seen so far: 4864 samples\n",
      "0.97267383\n",
      "Training loss (for one batch) at step 80: 0.0147\n",
      "Seen so far: 5184 samples\n",
      "0.97268003\n",
      "Training loss (for one batch) at step 85: 0.0469\n",
      "Seen so far: 5504 samples\n",
      "0.9726862\n",
      "Training loss (for one batch) at step 90: 0.0055\n",
      "Seen so far: 5824 samples\n",
      "0.9727058\n",
      "Training loss (for one batch) at step 95: 0.0600\n",
      "Seen so far: 6144 samples\n",
      "0.9727119\n",
      "Training loss (for one batch) at step 100: 0.0289\n",
      "Seen so far: 6464 samples\n",
      "0.97272253\n",
      "Training loss (for one batch) at step 105: 0.0487\n",
      "Seen so far: 6784 samples\n",
      "0.97273535\n",
      "Training loss (for one batch) at step 110: 0.0003\n",
      "Seen so far: 7104 samples\n",
      "0.9727459\n",
      "Training loss (for one batch) at step 115: 0.0023\n",
      "Seen so far: 7424 samples\n",
      "0.9727587\n",
      "Training loss (for one batch) at step 120: 0.0040\n",
      "Seen so far: 7744 samples\n",
      "0.97276926\n",
      "Training loss (for one batch) at step 125: 0.1286\n",
      "Seen so far: 8064 samples\n",
      "0.972782\n",
      "Training loss (for one batch) at step 130: 0.1500\n",
      "Seen so far: 8384 samples\n",
      "0.9727925\n",
      "Training loss (for one batch) at step 135: 0.0009\n",
      "Seen so far: 8704 samples\n",
      "0.972803\n",
      "Training loss (for one batch) at step 140: 0.0307\n",
      "Seen so far: 9024 samples\n",
      "0.97282016\n",
      "Training loss (for one batch) at step 145: 0.0105\n",
      "Seen so far: 9344 samples\n",
      "0.97283506\n",
      "Training loss (for one batch) at step 150: 0.0017\n",
      "Seen so far: 9664 samples\n",
      "0.9728522\n",
      "Training loss (for one batch) at step 155: 0.0072\n",
      "Seen so far: 9984 samples\n",
      "0.9728671\n",
      "Training loss (for one batch) at step 160: 0.0735\n",
      "Seen so far: 10304 samples\n",
      "0.97287744\n",
      "Training loss (for one batch) at step 165: 0.0034\n",
      "Seen so far: 10624 samples\n",
      "0.9728901\n",
      "Training loss (for one batch) at step 170: 0.0295\n",
      "Seen so far: 10944 samples\n",
      "0.97290486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 175: 0.0019\n",
      "Seen so far: 11264 samples\n",
      "0.97291523\n",
      "Training loss (for one batch) at step 180: 0.1556\n",
      "Seen so far: 11584 samples\n",
      "0.97292334\n",
      "Training loss (for one batch) at step 185: 0.0002\n",
      "Seen so far: 11904 samples\n",
      "0.9729403\n",
      "Training loss (for one batch) at step 190: 0.0094\n",
      "Seen so far: 12224 samples\n",
      "0.97295284\n",
      "Training loss (for one batch) at step 195: 0.0112\n",
      "Seen so far: 12544 samples\n",
      "0.97296757\n",
      "Training loss (for one batch) at step 200: 0.0996\n",
      "Seen so far: 12864 samples\n",
      "0.9729778\n",
      "Training loss (for one batch) at step 205: 0.0164\n",
      "Seen so far: 13184 samples\n",
      "0.97298366\n",
      "Training loss (for one batch) at step 210: 0.0903\n",
      "Seen so far: 13504 samples\n",
      "0.9729983\n",
      "Training loss (for one batch) at step 215: 0.0862\n",
      "Seen so far: 13824 samples\n",
      "0.9730107\n",
      "Training loss (for one batch) at step 220: 0.0010\n",
      "Seen so far: 14144 samples\n",
      "0.9730232\n",
      "Training loss (for one batch) at step 225: 0.0072\n",
      "Seen so far: 14464 samples\n",
      "0.9730378\n",
      "Training loss (for one batch) at step 230: 0.0002\n",
      "Seen so far: 14784 samples\n",
      "0.9730479\n",
      "Training loss (for one batch) at step 235: 0.0021\n",
      "Seen so far: 15104 samples\n",
      "0.9730625\n",
      "Training loss (for one batch) at step 240: 0.0760\n",
      "Seen so far: 15424 samples\n",
      "0.97307044\n",
      "Training loss (for one batch) at step 245: 0.0555\n",
      "Seen so far: 15744 samples\n",
      "0.9730828\n",
      "Training loss (for one batch) at step 250: 0.0018\n",
      "Seen so far: 16064 samples\n",
      "0.97309506\n",
      "Training loss (for one batch) at step 255: 0.0024\n",
      "Seen so far: 16384 samples\n",
      "0.97310954\n",
      "Training loss (for one batch) at step 260: 0.0070\n",
      "Seen so far: 16704 samples\n",
      "0.9731218\n",
      "Training loss (for one batch) at step 265: 0.0007\n",
      "Seen so far: 17024 samples\n",
      "0.9731319\n",
      "Training loss (for one batch) at step 270: 0.0522\n",
      "Seen so far: 17344 samples\n",
      "0.97313976\n",
      "Training loss (for one batch) at step 275: 0.0271\n",
      "Seen so far: 17664 samples\n",
      "0.9731542\n",
      "Training loss (for one batch) at step 280: 0.0011\n",
      "Seen so far: 17984 samples\n",
      "0.97317296\n",
      "Training loss (for one batch) at step 285: 0.0040\n",
      "Seen so far: 18304 samples\n",
      "0.9731852\n",
      "Training loss (for one batch) at step 290: 0.0100\n",
      "Seen so far: 18624 samples\n",
      "0.97319734\n",
      "Training loss (for one batch) at step 295: 0.0044\n",
      "Seen so far: 18944 samples\n",
      "0.973216\n",
      "Training loss (for one batch) at step 300: 0.0462\n",
      "Seen so far: 19264 samples\n",
      "0.97322595\n",
      "Training loss (for one batch) at step 305: 0.0041\n",
      "Seen so far: 19584 samples\n",
      "0.97324246\n",
      "Training loss (for one batch) at step 310: 0.0028\n",
      "Seen so far: 19904 samples\n",
      "0.9732589\n",
      "Training loss (for one batch) at step 315: 0.0021\n",
      "Seen so far: 20224 samples\n",
      "0.9732688\n",
      "Training loss (for one batch) at step 320: 0.0485\n",
      "Seen so far: 20544 samples\n",
      "0.97328085\n",
      "Training loss (for one batch) at step 325: 0.0123\n",
      "Seen so far: 20864 samples\n",
      "0.97329944\n",
      "Training loss (for one batch) at step 330: 0.0423\n",
      "Seen so far: 21184 samples\n",
      "0.9733093\n",
      "Training loss (for one batch) at step 335: 0.0147\n",
      "Seen so far: 21504 samples\n",
      "0.9733256\n",
      "Training loss (for one batch) at step 340: 0.0137\n",
      "Seen so far: 21824 samples\n",
      "0.9733376\n",
      "Training loss (for one batch) at step 345: 0.0614\n",
      "Seen so far: 22144 samples\n",
      "0.9733474\n",
      "Training loss (for one batch) at step 350: 0.0229\n",
      "Seen so far: 22464 samples\n",
      "0.97335505\n",
      "Training loss (for one batch) at step 355: 0.0209\n",
      "Seen so far: 22784 samples\n",
      "0.9733713\n",
      "Training loss (for one batch) at step 360: 0.0164\n",
      "Seen so far: 23104 samples\n",
      "0.97338325\n",
      "Training loss (for one batch) at step 365: 0.0005\n",
      "Seen so far: 23424 samples\n",
      "0.9733887\n",
      "Training loss (for one batch) at step 370: 0.0104\n",
      "Seen so far: 23744 samples\n",
      "0.97340274\n",
      "Training loss (for one batch) at step 375: 0.0141\n",
      "Seen so far: 24064 samples\n",
      "0.97341245\n",
      "Training loss (for one batch) at step 380: 0.0007\n",
      "Seen so far: 24384 samples\n",
      "0.97343075\n",
      "Training loss (for one batch) at step 385: 0.0355\n",
      "Seen so far: 24704 samples\n",
      "0.97344047\n",
      "Training loss (for one batch) at step 390: 0.0187\n",
      "Seen so far: 25024 samples\n",
      "0.9734501\n",
      "Training loss (for one batch) at step 395: 0.0009\n",
      "Seen so far: 25344 samples\n",
      "0.9734663\n",
      "Training loss (for one batch) at step 400: 0.0013\n",
      "Seen so far: 25664 samples\n",
      "0.9734802\n",
      "Training loss (for one batch) at step 405: 0.0139\n",
      "Seen so far: 25984 samples\n",
      "0.97347695\n",
      "Training loss (for one batch) at step 410: 0.0395\n",
      "Seen so far: 26304 samples\n",
      "0.9734909\n",
      "Training loss (for one batch) at step 415: 0.0231\n",
      "Seen so far: 26624 samples\n",
      "0.9735048\n",
      "Training loss (for one batch) at step 420: 0.0306\n",
      "Seen so far: 26944 samples\n",
      "0.9735101\n",
      "Training loss (for one batch) at step 425: 0.1122\n",
      "Seen so far: 27264 samples\n",
      "0.9735218\n",
      "Training loss (for one batch) at step 430: 0.0076\n",
      "Seen so far: 27584 samples\n",
      "0.9735335\n",
      "Training loss (for one batch) at step 435: 0.0011\n",
      "Seen so far: 27904 samples\n",
      "0.9735452\n",
      "Training loss (for one batch) at step 440: 0.0947\n",
      "Seen so far: 28224 samples\n",
      "0.97354835\n",
      "Training loss (for one batch) at step 445: 0.0790\n",
      "Seen so far: 28544 samples\n",
      "0.97356\n",
      "Training loss (for one batch) at step 450: 0.0034\n",
      "Seen so far: 28864 samples\n",
      "0.9735759\n",
      "Training loss (for one batch) at step 455: 0.0635\n",
      "Seen so far: 29184 samples\n",
      "0.9735833\n",
      "Training loss (for one batch) at step 460: 0.0340\n",
      "Seen so far: 29504 samples\n",
      "0.97358423\n",
      "Training loss (for one batch) at step 465: 0.0060\n",
      "Seen so far: 29824 samples\n",
      "0.9735937\n",
      "Training loss (for one batch) at step 470: 0.0311\n",
      "Seen so far: 30144 samples\n",
      "0.97359896\n",
      "Training loss (for one batch) at step 475: 0.0821\n",
      "Seen so far: 30464 samples\n",
      "0.9736084\n",
      "Training loss (for one batch) at step 480: 0.0055\n",
      "Seen so far: 30784 samples\n",
      "0.97361994\n",
      "Training loss (for one batch) at step 485: 0.0182\n",
      "Seen so far: 31104 samples\n",
      "0.97362727\n",
      "Training loss (for one batch) at step 490: 0.0012\n",
      "Seen so far: 31424 samples\n",
      "0.9736346\n",
      "Training loss (for one batch) at step 495: 0.1220\n",
      "Seen so far: 31744 samples\n",
      "0.9736419\n",
      "Training loss (for one batch) at step 500: 0.0704\n",
      "Seen so far: 32064 samples\n",
      "0.97365123\n",
      "Training loss (for one batch) at step 505: 0.0041\n",
      "Seen so far: 32384 samples\n",
      "0.9736564\n",
      "Training loss (for one batch) at step 510: 0.0614\n",
      "Seen so far: 32704 samples\n",
      "0.97366154\n",
      "Training loss (for one batch) at step 515: 0.0003\n",
      "Seen so far: 33024 samples\n",
      "0.97367513\n",
      "Training loss (for one batch) at step 520: 0.0426\n",
      "Seen so far: 33344 samples\n",
      "0.9736866\n",
      "Training loss (for one batch) at step 525: 0.0107\n",
      "Seen so far: 33664 samples\n",
      "0.973698\n",
      "Training loss (for one batch) at step 530: 0.0003\n",
      "Seen so far: 33984 samples\n",
      "0.9737116\n",
      "Training loss (for one batch) at step 535: 0.0184\n",
      "Seen so far: 34304 samples\n",
      "0.97371876\n",
      "Training loss (for one batch) at step 540: 0.0153\n",
      "Seen so far: 34624 samples\n",
      "0.9737302\n",
      "Training loss (for one batch) at step 545: 0.0497\n",
      "Seen so far: 34944 samples\n",
      "0.9737331\n",
      "Training loss (for one batch) at step 550: 0.0219\n",
      "Seen so far: 35264 samples\n",
      "0.97374034\n",
      "Training loss (for one batch) at step 555: 0.0565\n",
      "Seen so far: 35584 samples\n",
      "0.9737391\n",
      "Training loss (for one batch) at step 560: 0.0137\n",
      "Seen so far: 35904 samples\n",
      "0.97375464\n",
      "Training loss (for one batch) at step 565: 0.1326\n",
      "Seen so far: 36224 samples\n",
      "0.97376806\n",
      "Training loss (for one batch) at step 570: 0.0452\n",
      "Seen so far: 36544 samples\n",
      "0.9737773\n",
      "Training loss (for one batch) at step 575: 0.0176\n",
      "Seen so far: 36864 samples\n",
      "0.9737844\n",
      "Training loss (for one batch) at step 580: 0.0987\n",
      "Seen so far: 37184 samples\n",
      "0.9737957\n",
      "Training loss (for one batch) at step 585: 0.0109\n",
      "Seen so far: 37504 samples\n",
      "0.97381324\n",
      "Training loss (for one batch) at step 590: 0.0051\n",
      "Seen so far: 37824 samples\n",
      "0.97381824\n",
      "Training loss (for one batch) at step 595: 0.0004\n",
      "Seen so far: 38144 samples\n",
      "0.9738232\n",
      "Training loss (for one batch) at step 600: 0.0104\n",
      "Seen so far: 38464 samples\n",
      "0.97383446\n",
      "Training loss (for one batch) at step 605: 0.0330\n",
      "Seen so far: 38784 samples\n",
      "0.9738436\n",
      "Training loss (for one batch) at step 610: 0.0603\n",
      "Seen so far: 39104 samples\n",
      "0.9738506\n",
      "Training loss (for one batch) at step 615: 0.0913\n",
      "Seen so far: 39424 samples\n",
      "0.9738618\n",
      "Training loss (for one batch) at step 620: 0.0109\n",
      "Seen so far: 39744 samples\n",
      "0.973873\n",
      "Training loss (for one batch) at step 625: 0.0865\n",
      "Seen so far: 40064 samples\n",
      "0.97388417\n",
      "Training loss (for one batch) at step 630: 0.1499\n",
      "Seen so far: 40384 samples\n",
      "0.9738912\n",
      "Training loss (for one batch) at step 635: 0.2736\n",
      "Seen so far: 40704 samples\n",
      "0.9738961\n",
      "Training loss (for one batch) at step 640: 0.0370\n",
      "Seen so far: 41024 samples\n",
      "0.9738968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 645: 0.0974\n",
      "Seen so far: 41344 samples\n",
      "0.9738975\n",
      "Training loss (for one batch) at step 650: 0.1526\n",
      "Seen so far: 41664 samples\n",
      "0.9739024\n",
      "Training loss (for one batch) at step 655: 0.0030\n",
      "Seen so far: 41984 samples\n",
      "0.97391975\n",
      "Training loss (for one batch) at step 660: 0.2030\n",
      "Seen so far: 42304 samples\n",
      "0.97393084\n",
      "Training loss (for one batch) at step 665: 0.0196\n",
      "Seen so far: 42624 samples\n",
      "0.97393984\n",
      "Training loss (for one batch) at step 670: 0.1173\n",
      "Seen so far: 42944 samples\n",
      "0.9739364\n",
      "Training loss (for one batch) at step 675: 0.0068\n",
      "Seen so far: 43264 samples\n",
      "0.97394747\n",
      "Training loss (for one batch) at step 680: 0.1078\n",
      "Seen so far: 43584 samples\n",
      "0.9739482\n",
      "Training loss (for one batch) at step 685: 0.0317\n",
      "Seen so far: 43904 samples\n",
      "0.9739571\n",
      "Training loss (for one batch) at step 690: 0.0222\n",
      "Seen so far: 44224 samples\n",
      "0.97395575\n",
      "Training loss (for one batch) at step 695: 0.0751\n",
      "Seen so far: 44544 samples\n",
      "0.9739606\n",
      "Training loss (for one batch) at step 700: 0.0035\n",
      "Seen so far: 44864 samples\n",
      "0.9739695\n",
      "Training loss (for one batch) at step 705: 0.1352\n",
      "Seen so far: 45184 samples\n",
      "0.97397226\n",
      "Training loss (for one batch) at step 710: 0.0923\n",
      "Seen so far: 45504 samples\n",
      "0.9739791\n",
      "Training loss (for one batch) at step 715: 0.0491\n",
      "Seen so far: 45824 samples\n",
      "0.9739942\n",
      "Training loss (for one batch) at step 720: 0.0152\n",
      "Seen so far: 46144 samples\n",
      "0.97399896\n",
      "Training loss (for one batch) at step 725: 0.0089\n",
      "Seen so far: 46464 samples\n",
      "0.97400784\n",
      "Training loss (for one batch) at step 730: 0.1098\n",
      "Seen so far: 46784 samples\n",
      "0.9740003\n",
      "Training loss (for one batch) at step 735: 0.0443\n",
      "Seen so far: 47104 samples\n",
      "0.97400093\n",
      "Training loss (for one batch) at step 740: 0.0197\n",
      "Seen so far: 47424 samples\n",
      "0.9740036\n",
      "Training loss (for one batch) at step 745: 0.0020\n",
      "Seen so far: 47744 samples\n",
      "0.9740084\n",
      "Training loss (for one batch) at step 750: 0.0068\n",
      "Seen so far: 48064 samples\n",
      "0.9740111\n",
      "Training loss (for one batch) at step 755: 0.0696\n",
      "Seen so far: 48384 samples\n",
      "0.974022\n",
      "Training loss (for one batch) at step 760: 0.1453\n",
      "Seen so far: 48704 samples\n",
      "0.97402674\n",
      "Training acc over epoch: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 코드\n",
    "\n",
    "train_path = \"/aiffel/aiffel/model-fit/data/30vnfoods/Train\"\n",
    "\n",
    "epoch = 10\n",
    "batch = 64\n",
    "\n",
    "model = Model(num_classes=10)\n",
    "dataset = load_data(data_path=train_path, batch_size=batch)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "trainer = Trainer(model=model,\n",
    "                epochs=epoch,\n",
    "                batch=batch,\n",
    "                ds_length=train_length,\n",
    "                loss_fn=loss_function,\n",
    "                optimizer=optimizer)\n",
    "\n",
    "trainer.train(train_dataset=dataset,\n",
    "            train_metric=train_acc_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddf6694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/32\n",
      "26/32\n",
      "28/32\n",
      "30/32\n",
      "27/32\n",
      "29/32\n",
      "30/32\n",
      "27/32\n",
      "28/32\n",
      "27/32\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트 코드\n",
    "\n",
    "test_ds = load_data(data_path=test_path)\n",
    "\n",
    "for step_train, (x_batch_train, y_batch_train) in enumerate(test_ds.take(10)):\n",
    "    prediction = model(x_batch_train)\n",
    "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd933270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
